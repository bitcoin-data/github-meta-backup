{
  "type": "pull",
  "pull": {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831",
    "id": 178368690,
    "node_id": "MDExOlB1bGxSZXF1ZXN0MTc4MzY4Njkw",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/12831",
    "diff_url": "https://github.com/bitcoin/bitcoin/pull/12831.diff",
    "patch_url": "https://github.com/bitcoin/bitcoin/pull/12831.patch",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831",
    "commits_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831/commits",
    "review_comments_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831/comments",
    "review_comment_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments%7B/number%7D",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831/comments",
    "statuses_url": "https://api.github.com/repos/bitcoin/bitcoin/statuses/7785663d6f9960ffd38bec6c40fad7efbd8141fd",
    "number": 12831,
    "state": "closed",
    "locked": true,
    "maintainer_can_modify": false,
    "title": "[WIP] Run unit tests in parallel",
    "user": {
      "login": "MarcoFalke",
      "id": 6399679,
      "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/MarcoFalke",
      "html_url": "https://github.com/MarcoFalke",
      "followers_url": "https://api.github.com/users/MarcoFalke/followers",
      "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
      "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
      "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
      "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
      "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
      "repos_url": "https://api.github.com/users/MarcoFalke/repos",
      "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
      "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "Unit tests can be run in parallel on systems with more than one cpu and thus run faster.\r\n\r\nSince each test case is run separately from all others, test cases will no longer share the same global variables.",
    "labels": [
      {
        "id": 62963516,
        "node_id": "MDU6TGFiZWw2Mjk2MzUxNg==",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/labels/Tests",
        "name": "Tests",
        "color": "d4c5f9",
        "default": false
      }
    ],
    "active_lock_reason": "resolved",
    "created_at": "2018-03-29T15:47:37Z",
    "updated_at": "2021-09-08T11:52:54Z",
    "closed_at": "2018-04-10T16:08:56Z",
    "mergeable_state": "unknown",
    "merge_commit_sha": "ccfdf1622cf94861f2088acf1484a4f77a9c8330",
    "assignees": [],
    "requested_reviewers": [],
    "requested_teams": [],
    "head": {
      "label": "MarcoFalke:Mf1803-qaUnitParallel",
      "ref": "Mf1803-qaUnitParallel",
      "sha": "7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "user": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "repo": {
        "id": 40046254,
        "node_id": "MDEwOlJlcG9zaXRvcnk0MDA0NjI1NA==",
        "name": "b-c",
        "full_name": "MarcoFalke/b-c",
        "owner": {
          "login": "MarcoFalke",
          "id": 6399679,
          "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
          "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/MarcoFalke",
          "html_url": "https://github.com/MarcoFalke",
          "followers_url": "https://api.github.com/users/MarcoFalke/followers",
          "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
          "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
          "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
          "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
          "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
          "repos_url": "https://api.github.com/users/MarcoFalke/repos",
          "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
          "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
          "type": "User",
          "site_admin": false
        },
        "private": false,
        "html_url": "https://github.com/MarcoFalke/b-c",
        "fork": true,
        "url": "https://api.github.com/repos/MarcoFalke/b-c",
        "archive_url": "https://api.github.com/repos/MarcoFalke/b-c/%7Barchive_format%7D%7B/ref%7D",
        "assignees_url": "https://api.github.com/repos/MarcoFalke/b-c/assignees%7B/user%7D",
        "blobs_url": "https://api.github.com/repos/MarcoFalke/b-c/git/blobs%7B/sha%7D",
        "branches_url": "https://api.github.com/repos/MarcoFalke/b-c/branches%7B/branch%7D",
        "collaborators_url": "https://api.github.com/repos/MarcoFalke/b-c/collaborators%7B/collaborator%7D",
        "comments_url": "https://api.github.com/repos/MarcoFalke/b-c/comments%7B/number%7D",
        "commits_url": "https://api.github.com/repos/MarcoFalke/b-c/commits%7B/sha%7D",
        "compare_url": "https://api.github.com/repos/MarcoFalke/b-c/compare/%7Bbase%7D...%7Bhead%7D",
        "contents_url": "https://api.github.com/repos/MarcoFalke/b-c/contents/%7B+path%7D",
        "contributors_url": "https://api.github.com/repos/MarcoFalke/b-c/contributors",
        "deployments_url": "https://api.github.com/repos/MarcoFalke/b-c/deployments",
        "downloads_url": "https://api.github.com/repos/MarcoFalke/b-c/downloads",
        "events_url": "https://api.github.com/repos/MarcoFalke/b-c/events",
        "forks_url": "https://api.github.com/repos/MarcoFalke/b-c/forks",
        "git_commits_url": "https://api.github.com/repos/MarcoFalke/b-c/git/commits%7B/sha%7D",
        "git_refs_url": "https://api.github.com/repos/MarcoFalke/b-c/git/refs%7B/sha%7D",
        "git_tags_url": "https://api.github.com/repos/MarcoFalke/b-c/git/tags%7B/sha%7D",
        "git_url": "git://github.com/MarcoFalke/b-c.git",
        "issue_comment_url": "https://api.github.com/repos/MarcoFalke/b-c/issues/comments%7B/number%7D",
        "issue_events_url": "https://api.github.com/repos/MarcoFalke/b-c/issues/events%7B/number%7D",
        "issues_url": "https://api.github.com/repos/MarcoFalke/b-c/issues%7B/number%7D",
        "keys_url": "https://api.github.com/repos/MarcoFalke/b-c/keys%7B/key_id%7D",
        "labels_url": "https://api.github.com/repos/MarcoFalke/b-c/labels%7B/name%7D",
        "languages_url": "https://api.github.com/repos/MarcoFalke/b-c/languages",
        "merges_url": "https://api.github.com/repos/MarcoFalke/b-c/merges",
        "milestones_url": "https://api.github.com/repos/MarcoFalke/b-c/milestones%7B/number%7D",
        "notifications_url": "https://api.github.com/repos/MarcoFalke/b-c/notifications%7B?since,all,participating}",
        "pulls_url": "https://api.github.com/repos/MarcoFalke/b-c/pulls%7B/number%7D",
        "releases_url": "https://api.github.com/repos/MarcoFalke/b-c/releases%7B/id%7D",
        "ssh_url": "git@github.com:MarcoFalke/b-c.git",
        "stargazers_url": "https://api.github.com/repos/MarcoFalke/b-c/stargazers",
        "statuses_url": "https://api.github.com/repos/MarcoFalke/b-c/statuses/%7Bsha%7D",
        "subscribers_url": "https://api.github.com/repos/MarcoFalke/b-c/subscribers",
        "subscription_url": "https://api.github.com/repos/MarcoFalke/b-c/subscription",
        "tags_url": "https://api.github.com/repos/MarcoFalke/b-c/tags",
        "teams_url": "https://api.github.com/repos/MarcoFalke/b-c/teams",
        "trees_url": "https://api.github.com/repos/MarcoFalke/b-c/git/trees%7B/sha%7D",
        "clone_url": "https://github.com/MarcoFalke/b-c.git",
        "hooks_url": "https://api.github.com/repos/MarcoFalke/b-c/hooks",
        "svn_url": "https://github.com/MarcoFalke/b-c",
        "homepage": "",
        "language": "C++",
        "forks_count": 12,
        "stargazers_count": 25,
        "watchers_count": 25,
        "size": 205775,
        "default_branch": "master",
        "open_issues_count": 25,
        "is_template": false,
        "topics": [],
        "has_issues": true,
        "has_projects": true,
        "has_wiki": false,
        "has_pages": false,
        "has_downloads": false,
        "archived": false,
        "disabled": false,
        "visibility": "public",
        "pushed_at": "2023-06-06T19:05:17Z",
        "created_at": "2015-08-01T12:42:47Z",
        "updated_at": "2023-05-28T20:12:34Z",
        "license": {
          "key": "mit",
          "name": "MIT License",
          "node_id": "MDc6TGljZW5zZTEz",
          "spdx_id": "MIT",
          "url": "https://api.github.com/licenses/mit",
          "html_url": null,
          "description": null,
          "implementation": null,
          "permissions": null,
          "conditions": null,
          "limitations": null,
          "body": null,
          "featured": null
        }
      }
    },
    "base": {
      "label": "bitcoin:master",
      "ref": "master",
      "sha": "8d651ae32013440b2af1267e87a9d93759a9471f",
      "user": {
        "login": "bitcoin",
        "id": 528860,
        "node_id": "MDEyOk9yZ2FuaXphdGlvbjUyODg2MA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/528860?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/bitcoin",
        "html_url": "https://github.com/bitcoin",
        "followers_url": "https://api.github.com/users/bitcoin/followers",
        "following_url": "https://api.github.com/users/bitcoin/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/bitcoin/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/bitcoin/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/bitcoin/subscriptions",
        "organizations_url": "https://api.github.com/users/bitcoin/orgs",
        "repos_url": "https://api.github.com/users/bitcoin/repos",
        "events_url": "https://api.github.com/users/bitcoin/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/bitcoin/received_events",
        "type": "Organization",
        "site_admin": false
      },
      "repo": {
        "id": 1181927,
        "node_id": "MDEwOlJlcG9zaXRvcnkxMTgxOTI3",
        "name": "bitcoin",
        "full_name": "bitcoin/bitcoin",
        "owner": {
          "login": "bitcoin",
          "id": 528860,
          "node_id": "MDEyOk9yZ2FuaXphdGlvbjUyODg2MA==",
          "avatar_url": "https://avatars.githubusercontent.com/u/528860?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/bitcoin",
          "html_url": "https://github.com/bitcoin",
          "followers_url": "https://api.github.com/users/bitcoin/followers",
          "following_url": "https://api.github.com/users/bitcoin/following%7B/other_user%7D",
          "gists_url": "https://api.github.com/users/bitcoin/gists%7B/gist_id%7D",
          "starred_url": "https://api.github.com/users/bitcoin/starred%7B/owner%7D%7B/repo%7D",
          "subscriptions_url": "https://api.github.com/users/bitcoin/subscriptions",
          "organizations_url": "https://api.github.com/users/bitcoin/orgs",
          "repos_url": "https://api.github.com/users/bitcoin/repos",
          "events_url": "https://api.github.com/users/bitcoin/events%7B/privacy%7D",
          "received_events_url": "https://api.github.com/users/bitcoin/received_events",
          "type": "Organization",
          "site_admin": false
        },
        "private": false,
        "html_url": "https://github.com/bitcoin/bitcoin",
        "description": "Bitcoin Core integration/staging tree",
        "fork": false,
        "url": "https://api.github.com/repos/bitcoin/bitcoin",
        "archive_url": "https://api.github.com/repos/bitcoin/bitcoin/%7Barchive_format%7D%7B/ref%7D",
        "assignees_url": "https://api.github.com/repos/bitcoin/bitcoin/assignees%7B/user%7D",
        "blobs_url": "https://api.github.com/repos/bitcoin/bitcoin/git/blobs%7B/sha%7D",
        "branches_url": "https://api.github.com/repos/bitcoin/bitcoin/branches%7B/branch%7D",
        "collaborators_url": "https://api.github.com/repos/bitcoin/bitcoin/collaborators%7B/collaborator%7D",
        "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/comments%7B/number%7D",
        "commits_url": "https://api.github.com/repos/bitcoin/bitcoin/commits%7B/sha%7D",
        "compare_url": "https://api.github.com/repos/bitcoin/bitcoin/compare/%7Bbase%7D...%7Bhead%7D",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/%7B+path%7D",
        "contributors_url": "https://api.github.com/repos/bitcoin/bitcoin/contributors",
        "deployments_url": "https://api.github.com/repos/bitcoin/bitcoin/deployments",
        "downloads_url": "https://api.github.com/repos/bitcoin/bitcoin/downloads",
        "events_url": "https://api.github.com/repos/bitcoin/bitcoin/events",
        "forks_url": "https://api.github.com/repos/bitcoin/bitcoin/forks",
        "git_commits_url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits%7B/sha%7D",
        "git_refs_url": "https://api.github.com/repos/bitcoin/bitcoin/git/refs%7B/sha%7D",
        "git_tags_url": "https://api.github.com/repos/bitcoin/bitcoin/git/tags%7B/sha%7D",
        "git_url": "git://github.com/bitcoin/bitcoin.git",
        "issue_comment_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments%7B/number%7D",
        "issue_events_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events%7B/number%7D",
        "issues_url": "https://api.github.com/repos/bitcoin/bitcoin/issues%7B/number%7D",
        "keys_url": "https://api.github.com/repos/bitcoin/bitcoin/keys%7B/key_id%7D",
        "labels_url": "https://api.github.com/repos/bitcoin/bitcoin/labels%7B/name%7D",
        "languages_url": "https://api.github.com/repos/bitcoin/bitcoin/languages",
        "merges_url": "https://api.github.com/repos/bitcoin/bitcoin/merges",
        "milestones_url": "https://api.github.com/repos/bitcoin/bitcoin/milestones%7B/number%7D",
        "notifications_url": "https://api.github.com/repos/bitcoin/bitcoin/notifications%7B?since,all,participating}",
        "pulls_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls%7B/number%7D",
        "releases_url": "https://api.github.com/repos/bitcoin/bitcoin/releases%7B/id%7D",
        "ssh_url": "git@github.com:bitcoin/bitcoin.git",
        "stargazers_url": "https://api.github.com/repos/bitcoin/bitcoin/stargazers",
        "statuses_url": "https://api.github.com/repos/bitcoin/bitcoin/statuses/%7Bsha%7D",
        "subscribers_url": "https://api.github.com/repos/bitcoin/bitcoin/subscribers",
        "subscription_url": "https://api.github.com/repos/bitcoin/bitcoin/subscription",
        "tags_url": "https://api.github.com/repos/bitcoin/bitcoin/tags",
        "teams_url": "https://api.github.com/repos/bitcoin/bitcoin/teams",
        "trees_url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees%7B/sha%7D",
        "clone_url": "https://github.com/bitcoin/bitcoin.git",
        "hooks_url": "https://api.github.com/repos/bitcoin/bitcoin/hooks",
        "svn_url": "https://github.com/bitcoin/bitcoin",
        "homepage": "https://bitcoincore.org/en/download",
        "language": "C++",
        "forks_count": 34324,
        "stargazers_count": 69818,
        "watchers_count": 69818,
        "size": 233879,
        "default_branch": "master",
        "open_issues_count": 627,
        "is_template": false,
        "topics": [
          "bitcoin",
          "c-plus-plus",
          "cryptocurrency",
          "cryptography",
          "p2p"
        ],
        "has_issues": true,
        "has_projects": true,
        "has_wiki": false,
        "has_pages": false,
        "has_downloads": false,
        "archived": false,
        "disabled": false,
        "visibility": "public",
        "pushed_at": "2023-06-06T22:42:00Z",
        "created_at": "2010-12-19T15:16:43Z",
        "updated_at": "2023-06-07T00:30:39Z",
        "license": {
          "key": "mit",
          "name": "MIT License",
          "node_id": "MDc6TGljZW5zZTEz",
          "spdx_id": "MIT",
          "url": "https://api.github.com/licenses/mit",
          "html_url": null,
          "description": null,
          "implementation": null,
          "permissions": null,
          "conditions": null,
          "limitations": null,
          "body": null,
          "featured": null
        }
      }
    },
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
      }
    },
    "author_association": "MEMBER",
    "draft": false,
    "additions": 822,
    "deletions": 5,
    "changed_files": 3,
    "commits": 2,
    "review_comments": 8,
    "comments": 18
  },
  "events": [
    {
      "event": "commented",
      "id": 377279610,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzI3OTYxMA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/377279610",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-29T15:47:44Z",
      "updated_at": "2018-04-10T16:08:17Z",
      "author_association": "MEMBER",
      "body": "TODO:\r\n\r\n* [x] Should be run on `make check`",
      "user": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-377279610",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "labeled",
      "id": 1548205033,
      "node_id": "MDEyOkxhYmVsZWRFdmVudDE1NDgyMDUwMzM=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1548205033",
      "actor": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-29T15:48:48Z",
      "label": {
        "name": "Tests",
        "color": "d4c5f9"
      }
    },
    {
      "event": "commented",
      "id": 377305854,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzMwNTg1NA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/377305854",
      "actor": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-29T17:11:19Z",
      "updated_at": "2018-03-29T17:11:19Z",
      "author_association": "CONTRIBUTOR",
      "body": "Concept ACK\r\n\r\nVery nice!",
      "user": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-377305854",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "commented",
      "id": 377306416,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzMwNjQxNg==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/377306416",
      "actor": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-29T17:13:03Z",
      "updated_at": "2018-03-29T17:13:36Z",
      "author_association": "CONTRIBUTOR",
      "body": "Perhaps a stupid question but why the need of a static `test_list.txt`? What would be the disadvantages of generating the test list at run-time?",
      "user": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-377306416",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "commented",
      "id": 377311124,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzMxMTEyNA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/377311124",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-29T17:28:05Z",
      "updated_at": "2018-03-29T17:28:05Z",
      "author_association": "MEMBER",
      "body": "`--list_content` is only documented in 1.60.0, so I assume it wouldn't work in previous versions. Currently we support 1.47.0+\r\n\r\nhttp://www.boost.org/doc/libs/1_60_0/libs/test/doc/html/boost_test/utf_reference/rt_param_reference/list_content.html\r\nhttps://github.com/bitcoin/bitcoin/blob/master/doc/dependencies.md#dependencies",
      "user": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-377311124",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "commented",
      "id": 377362816,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzM2MjgxNg==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/377362816",
      "actor": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-29T20:30:31Z",
      "updated_at": "2018-03-29T20:32:15Z",
      "author_association": "CONTRIBUTOR",
      "body": "@MarcoFalke The output from `git grep -E '(BOOST_FIXTURE_TEST_SUITE|BOOST_AUTO_TEST_CASE)' -- \"src/**.cpp\"` could perhaps be used to quickly (~14 ms on my machine) generate the list of available tests?",
      "user": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-377362816",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "mentioned",
      "id": 1548736983,
      "node_id": "MDE0Ok1lbnRpb25lZEV2ZW50MTU0ODczNjk4Mw==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1548736983",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-29T20:30:31Z"
    },
    {
      "event": "subscribed",
      "id": 1548736984,
      "node_id": "MDE1OlN1YnNjcmliZWRFdmVudDE1NDg3MzY5ODQ=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1548736984",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-29T20:30:31Z"
    },
    {
      "event": "commented",
      "id": 377365128,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzM2NTEyOA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/377365128",
      "actor": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-29T20:39:18Z",
      "updated_at": "2018-03-29T20:41:09Z",
      "author_association": "CONTRIBUTOR",
      "body": "If we go with the static text file `test_list.txt` I suggest adding a script `contrib/devtools/lint-test_list.sh` which checks that the list of tests in `test_list.txt` is in sync with the list of tests given by `src/test/test_bitcoin --list_content`.\r\n\r\nThat way Travis would automatically catch the case where someone adds a test and forgets to manually run `src/test/parallel.py --write_list` (which requires running Boost.Test 1.60.0 or above) and commit the changes made to `test_list.txt` after adding a new test.",
      "user": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-377365128",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "reviewed",
      "id": 108264341,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MTA4MjY0MzQx",
      "url": null,
      "actor": null,
      "commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#pullrequestreview-108264341",
      "submitted_at": "2018-03-30T05:08:49Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
    },
    {
      "event": "reviewed",
      "id": 108265562,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MTA4MjY1NTYy",
      "url": null,
      "actor": null,
      "commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#pullrequestreview-108265562",
      "submitted_at": "2018-03-30T05:24:29Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
    },
    {
      "event": "reviewed",
      "id": 108266847,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MTA4MjY2ODQ3",
      "url": null,
      "actor": null,
      "commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#pullrequestreview-108266847",
      "submitted_at": "2018-03-30T05:41:18Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
    },
    {
      "event": "reviewed",
      "id": 108267828,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MTA4MjY3ODI4",
      "url": null,
      "actor": null,
      "commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#pullrequestreview-108267828",
      "submitted_at": "2018-03-30T05:52:47Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
    },
    {
      "event": "reviewed",
      "id": 108268589,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MTA4MjY4NTg5",
      "url": null,
      "actor": null,
      "commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#pullrequestreview-108268589",
      "submitted_at": "2018-03-30T06:01:30Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
    },
    {
      "event": "reviewed",
      "id": 108269924,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MTA4MjY5OTI0",
      "url": null,
      "actor": null,
      "commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#pullrequestreview-108269924",
      "submitted_at": "2018-03-30T06:15:14Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
    },
    {
      "event": "reviewed",
      "id": 108270259,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MTA4MjcwMjU5",
      "url": null,
      "actor": null,
      "commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#pullrequestreview-108270259",
      "submitted_at": "2018-03-30T06:19:11Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
    },
    {
      "event": "commented",
      "id": 377455800,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzQ1NTgwMA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/377455800",
      "actor": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-30T06:21:41Z",
      "updated_at": "2018-03-30T06:21:41Z",
      "author_association": "CONTRIBUTOR",
      "body": "Concept ACK - Tested it out and left some initial feedback. Realize it's WIP so just left broad comments. ",
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-377455800",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 1549844488,
      "node_id": "MDIzOkhlYWRSZWZGb3JjZVB1c2hlZEV2ZW50MTU0OTg0NDQ4OA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1549844488",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-03-30T14:51:58Z"
    },
    {
      "event": "commented",
      "id": 377821283,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzgyMTI4Mw==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/377821283",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-01T22:21:44Z",
      "updated_at": "2018-04-01T22:21:44Z",
      "author_association": "MEMBER",
      "body": "Thanks for looking at this! I kept the patches to the gtest-parallel script minimal. Feedback not about my patches should be submitted upstream: https://github.com/google/gtest-parallel\r\n\r\nAlso, if someone knows more about autotools, help is very much appreciated to make it run on `make check`.",
      "user": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-377821283",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "labeled",
      "id": 1559036742,
      "node_id": "MDEyOkxhYmVsZWRFdmVudDE1NTkwMzY3NDI=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559036742",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T15:26:17Z",
      "label": {
        "name": "Up for grabs",
        "color": "99a810"
      }
    },
    {
      "event": "commented",
      "id": 378975587,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3ODk3NTU4Nw==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/378975587",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T15:26:48Z",
      "updated_at": "2018-04-05T15:26:48Z",
      "author_association": "MEMBER",
      "body": "@theuni Mind to give a Concept ACK/NACK or some general comments?",
      "user": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-378975587",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "mentioned",
      "id": 1559037929,
      "node_id": "MDE0Ok1lbnRpb25lZEV2ZW50MTU1OTAzNzkyOQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559037929",
      "actor": {
        "login": "theuni",
        "id": 417043,
        "node_id": "MDQ6VXNlcjQxNzA0Mw==",
        "avatar_url": "https://avatars.githubusercontent.com/u/417043?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/theuni",
        "html_url": "https://github.com/theuni",
        "followers_url": "https://api.github.com/users/theuni/followers",
        "following_url": "https://api.github.com/users/theuni/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/theuni/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/theuni/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/theuni/subscriptions",
        "organizations_url": "https://api.github.com/users/theuni/orgs",
        "repos_url": "https://api.github.com/users/theuni/repos",
        "events_url": "https://api.github.com/users/theuni/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/theuni/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T15:26:48Z"
    },
    {
      "event": "subscribed",
      "id": 1559037931,
      "node_id": "MDE1OlN1YnNjcmliZWRFdmVudDE1NTkwMzc5MzE=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559037931",
      "actor": {
        "login": "theuni",
        "id": 417043,
        "node_id": "MDQ6VXNlcjQxNzA0Mw==",
        "avatar_url": "https://avatars.githubusercontent.com/u/417043?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/theuni",
        "html_url": "https://github.com/theuni",
        "followers_url": "https://api.github.com/users/theuni/followers",
        "following_url": "https://api.github.com/users/theuni/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/theuni/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/theuni/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/theuni/subscriptions",
        "organizations_url": "https://api.github.com/users/theuni/orgs",
        "repos_url": "https://api.github.com/users/theuni/repos",
        "events_url": "https://api.github.com/users/theuni/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/theuni/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T15:26:48Z"
    },
    {
      "event": "commented",
      "id": 378981463,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3ODk4MTQ2Mw==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/378981463",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T15:44:23Z",
      "updated_at": "2018-04-05T15:44:23Z",
      "author_association": "MEMBER",
      "body": "I have an idea for a simpler approach, where you could tell the test binary there are N processes, and which one out of those it is. It would then partition the tests randomly into N groups, and only run one of them.\n\nIf there's interest, I'll try to implement that soon.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-378981463",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "commented",
      "id": 378985616,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3ODk4NTYxNg==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/378985616",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T15:56:35Z",
      "updated_at": "2018-04-05T15:56:35Z",
      "author_association": "MEMBER",
      "body": "@sipa That wouldn't help running the most time-expensive test first or avoiding that two expensive tests end up in the same group?",
      "user": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-378985616",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "mentioned",
      "id": 1559108119,
      "node_id": "MDE0Ok1lbnRpb25lZEV2ZW50MTU1OTEwODExOQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559108119",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T15:56:35Z"
    },
    {
      "event": "subscribed",
      "id": 1559108120,
      "node_id": "MDE1OlN1YnNjcmliZWRFdmVudDE1NTkxMDgxMjA=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559108120",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T15:56:35Z"
    },
    {
      "event": "commented",
      "id": 378991820,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3ODk5MTgyMA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/378991820",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T16:15:16Z",
      "updated_at": "2018-04-05T16:15:16Z",
      "author_association": "MEMBER",
      "body": "@MarcoFalke No, but I think that's an independent problem. If some tests take exorbitantly more time than others, perhaps those tests need to be split up.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-378991820",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "mentioned",
      "id": 1559150018,
      "node_id": "MDE0Ok1lbnRpb25lZEV2ZW50MTU1OTE1MDAxOA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559150018",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T16:15:16Z"
    },
    {
      "event": "subscribed",
      "id": 1559150019,
      "node_id": "MDE1OlN1YnNjcmliZWRFdmVudDE1NTkxNTAwMTk=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559150019",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T16:15:16Z"
    },
    {
      "event": "commented",
      "id": 379003069,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTAwMzA2OQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/379003069",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T16:52:25Z",
      "updated_at": "2018-04-05T16:52:25Z",
      "author_association": "MEMBER",
      "body": "See #10026 for an (outdated) list of slow unit tests. I haven't checked how practical it is to split them up, but there will always be tests that run slower compared to others.",
      "user": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-379003069",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 1559233713,
      "node_id": "MDIzOkhlYWRSZWZGb3JjZVB1c2hlZEV2ZW50MTU1OTIzMzcxMw==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559233713",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T16:56:11Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 1559241659,
      "node_id": "MDIzOkhlYWRSZWZGb3JjZVB1c2hlZEV2ZW50MTU1OTI0MTY1OQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559241659",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T17:00:14Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 1559274606,
      "node_id": "MDIzOkhlYWRSZWZGb3JjZVB1c2hlZEV2ZW50MTU1OTI3NDYwNg==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559274606",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T17:16:47Z"
    },
    {
      "event": "commented",
      "id": 379011508,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTAxMTUwOA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/379011508",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T17:20:28Z",
      "updated_at": "2018-04-05T17:20:28Z",
      "author_association": "MEMBER",
      "body": "The currently longest running test on my machine seems to be \"test_big_witness_transaction\":\r\n\r\n```\r\n$ python3 ./src/test/parallel.py | tail -3\r\n[285/287] streams_tests/streams_serializedata_xor (47 ms)\r\n[286/287] coinselector_tests/knapsack_solver_test (12060 ms)\r\n[287/287] transaction_tests/test_big_witness_transaction (17931 ms)",
      "user": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-379011508",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "commented",
      "id": 379058185,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTA1ODE4NQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/379058185",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T19:58:42Z",
      "updated_at": "2018-04-05T19:58:42Z",
      "author_association": "MEMBER",
      "body": "* Got rid of test_list.txt\r\n* Run test suites in parallel instead of test cases",
      "user": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-379058185",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "commented",
      "id": 379060530,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTA2MDUzMA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/379060530",
      "actor": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T20:07:23Z",
      "updated_at": "2018-04-05T20:07:33Z",
      "author_association": "CONTRIBUTOR",
      "body": "Repeating concept ACK\r\n\r\nAutomatic linting comment: `transform_boost_output_to_test_list` is unused now? :-)",
      "user": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-379060530",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 1559647130,
      "node_id": "MDIzOkhlYWRSZWZGb3JjZVB1c2hlZEV2ZW50MTU1OTY0NzEzMA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1559647130",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-05T20:31:12Z"
    },
    {
      "event": "commented",
      "id": 379905694,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTkwNTY5NA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/379905694",
      "actor": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-09T21:53:09Z",
      "updated_at": "2018-04-09T21:53:09Z",
      "author_association": "CONTRIBUTOR",
      "body": "NACK. Prefering #12926 :-)",
      "user": {
        "login": "practicalswift",
        "id": 7826565,
        "node_id": "MDQ6VXNlcjc4MjY1NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/practicalswift",
        "html_url": "https://github.com/practicalswift",
        "followers_url": "https://api.github.com/users/practicalswift/followers",
        "following_url": "https://api.github.com/users/practicalswift/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/practicalswift/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/practicalswift/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
        "organizations_url": "https://api.github.com/users/practicalswift/orgs",
        "repos_url": "https://api.github.com/users/practicalswift/repos",
        "events_url": "https://api.github.com/users/practicalswift/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/practicalswift/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-379905694",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "referenced",
      "id": 1566042405,
      "node_id": "MDE1OlJlZmVyZW5jZWRFdmVudDE1NjYwNDI0MDU=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1566042405",
      "actor": {
        "login": "laanwj",
        "id": 126646,
        "node_id": "MDQ6VXNlcjEyNjY0Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/laanwj",
        "html_url": "https://github.com/laanwj",
        "followers_url": "https://api.github.com/users/laanwj/followers",
        "following_url": "https://api.github.com/users/laanwj/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/laanwj/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/laanwj/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
        "organizations_url": "https://api.github.com/users/laanwj/orgs",
        "repos_url": "https://api.github.com/users/laanwj/repos",
        "events_url": "https://api.github.com/users/laanwj/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/laanwj/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": "dd1ca9e0b300f33eee0edcfe22024cef12c6a155",
      "commit_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/dd1ca9e0b300f33eee0edcfe22024cef12c6a155",
      "created_at": "2018-04-10T12:28:53Z"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "MDY6Q29tbWl0MTE4MTkyNzo4NTEwYzdlMjg5YTc1NGMwYTRjZmM2YjdiNjkwODE1ZmEzMTNhYjg5",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/8510c7e289a754c0a4cfc6b7b690815fa313ab89",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/8510c7e289a754c0a4cfc6b7b690815fa313ab89",
      "tree": {
        "sha": "bbb117d11768cf1a0264ccdc71a91bf97dc7e41d",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/bbb117d11768cf1a0264ccdc71a91bf97dc7e41d"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/8d651ae32013440b2af1267e87a9d93759a9471f",
          "sha": "8d651ae32013440b2af1267e87a9d93759a9471f",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/8d651ae32013440b2af1267e87a9d93759a9471f"
        }
      ],
      "message": "test: Add parallel.py from gtest-parallel\n\nAs of commit 9ae552468cf096cb281d1ab7c87d9baea56e86c9\n\nhttps://github.com/google/gtest-parallel/commit/9ae552468cf096cb281d1ab7c87d9baea56e86c9",
      "committer": {
        "name": "MarcoFalke",
        "email": "falke.marco@gmail.com",
        "date": "2018-04-10T15:51:57Z"
      },
      "author": {
        "name": "MarcoFalke",
        "email": "falke.marco@gmail.com",
        "date": "2018-03-29T15:41:45Z"
      },
      "sha": "8510c7e289a754c0a4cfc6b7b690815fa313ab89"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "MDY6Q29tbWl0MTE4MTkyNzo3Nzg1NjYzZDZmOTk2MGZmZDM4YmVjNmM0MGZhZDdlZmJkODE0MWZk",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "tree": {
        "sha": "18293ac408163f91a6a29a4803c3e4b5c1fa36e1",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/18293ac408163f91a6a29a4803c3e4b5c1fa36e1"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/8510c7e289a754c0a4cfc6b7b690815fa313ab89",
          "sha": "8510c7e289a754c0a4cfc6b7b690815fa313ab89",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/8510c7e289a754c0a4cfc6b7b690815fa313ab89"
        }
      ],
      "message": "test: Adjust parallel.find_tests for our unit tests",
      "committer": {
        "name": "MarcoFalke",
        "email": "falke.marco@gmail.com",
        "date": "2018-04-10T16:05:47Z"
      },
      "author": {
        "name": "MarcoFalke",
        "email": "falke.marco@gmail.com",
        "date": "2018-03-28T15:13:05Z"
      },
      "sha": "7785663d6f9960ffd38bec6c40fad7efbd8141fd"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 1566581415,
      "node_id": "MDIzOkhlYWRSZWZGb3JjZVB1c2hlZEV2ZW50MTU2NjU4MTQxNQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1566581415",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-10T16:06:27Z"
    },
    {
      "event": "unlabeled",
      "id": 1566585908,
      "node_id": "MDE0OlVubGFiZWxlZEV2ZW50MTU2NjU4NTkwOA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1566585908",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-10T16:08:23Z",
      "label": {
        "name": "Up for grabs",
        "color": "99a810"
      }
    },
    {
      "event": "commented",
      "id": 380157612,
      "node_id": "MDEyOklzc3VlQ29tbWVudDM4MDE1NzYxMg==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/380157612",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-10T16:08:40Z",
      "updated_at": "2018-04-10T16:08:40Z",
      "author_association": "MEMBER",
      "body": "Rebased",
      "user": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#issuecomment-380157612",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/12831"
    },
    {
      "event": "closed",
      "id": 1566587112,
      "node_id": "MDExOkNsb3NlZEV2ZW50MTU2NjU4NzExMg==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1566587112",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-10T16:08:56Z"
    },
    {
      "event": "head_ref_deleted",
      "id": 1566587246,
      "node_id": "MDE5OkhlYWRSZWZEZWxldGVkRXZlbnQxNTY2NTg3MjQ2",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/1566587246",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2018-04-10T16:09:00Z"
    },
    {
      "event": "referenced",
      "id": 4590615502,
      "node_id": "MDE1OlJlZmVyZW5jZWRFdmVudDQ1OTA2MTU1MDI=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/4590615502",
      "actor": {
        "login": "PastaPastaPasta",
        "id": 6443210,
        "node_id": "MDQ6VXNlcjY0NDMyMTA=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6443210?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/PastaPastaPasta",
        "html_url": "https://github.com/PastaPastaPasta",
        "followers_url": "https://api.github.com/users/PastaPastaPasta/followers",
        "following_url": "https://api.github.com/users/PastaPastaPasta/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/PastaPastaPasta/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/PastaPastaPasta/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/PastaPastaPasta/subscriptions",
        "organizations_url": "https://api.github.com/users/PastaPastaPasta/orgs",
        "repos_url": "https://api.github.com/users/PastaPastaPasta/repos",
        "events_url": "https://api.github.com/users/PastaPastaPasta/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/PastaPastaPasta/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": "e8962ff95390039580600075351996fc5234edb7",
      "commit_url": "https://api.github.com/repos/PastaPastaPasta/dash/commits/e8962ff95390039580600075351996fc5234edb7",
      "created_at": "2021-04-13T22:54:50Z"
    },
    {
      "event": "referenced",
      "id": 4608352667,
      "node_id": "MDE1OlJlZmVyZW5jZWRFdmVudDQ2MDgzNTI2Njc=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/4608352667",
      "actor": {
        "login": "PastaPastaPasta",
        "id": 6443210,
        "node_id": "MDQ6VXNlcjY0NDMyMTA=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6443210?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/PastaPastaPasta",
        "html_url": "https://github.com/PastaPastaPasta",
        "followers_url": "https://api.github.com/users/PastaPastaPasta/followers",
        "following_url": "https://api.github.com/users/PastaPastaPasta/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/PastaPastaPasta/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/PastaPastaPasta/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/PastaPastaPasta/subscriptions",
        "organizations_url": "https://api.github.com/users/PastaPastaPasta/orgs",
        "repos_url": "https://api.github.com/users/PastaPastaPasta/repos",
        "events_url": "https://api.github.com/users/PastaPastaPasta/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/PastaPastaPasta/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": "460c1ee359ce4f077fb8af33c95104585534dcb8",
      "commit_url": "https://api.github.com/repos/PastaPastaPasta/dash/commits/460c1ee359ce4f077fb8af33c95104585534dcb8",
      "created_at": "2021-04-17T20:23:46Z"
    },
    {
      "event": "referenced",
      "id": 4637192266,
      "node_id": "MDE1OlJlZmVyZW5jZWRFdmVudDQ2MzcxOTIyNjY=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/4637192266",
      "actor": {
        "login": "kittywhiskers",
        "id": 63189531,
        "node_id": "MDQ6VXNlcjYzMTg5NTMx",
        "avatar_url": "https://avatars.githubusercontent.com/u/63189531?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/kittywhiskers",
        "html_url": "https://github.com/kittywhiskers",
        "followers_url": "https://api.github.com/users/kittywhiskers/followers",
        "following_url": "https://api.github.com/users/kittywhiskers/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/kittywhiskers/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/kittywhiskers/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/kittywhiskers/subscriptions",
        "organizations_url": "https://api.github.com/users/kittywhiskers/orgs",
        "repos_url": "https://api.github.com/users/kittywhiskers/repos",
        "events_url": "https://api.github.com/users/kittywhiskers/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/kittywhiskers/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": "53254c5dbf1b1a3e5f52b0956e76bcf1e49c338c",
      "commit_url": "https://api.github.com/repos/kittywhiskers/dash/commits/53254c5dbf1b1a3e5f52b0956e76bcf1e49c338c",
      "created_at": "2021-04-23T14:20:01Z"
    },
    {
      "event": "locked",
      "id": 5271796460,
      "node_id": "LOE_lADOABII584Sd0nHzwAAAAE6OTrs",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/5271796460",
      "actor": {
        "login": "MarcoFalke",
        "id": 6399679,
        "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MarcoFalke",
        "html_url": "https://github.com/MarcoFalke",
        "followers_url": "https://api.github.com/users/MarcoFalke/followers",
        "following_url": "https://api.github.com/users/MarcoFalke/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/MarcoFalke/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/MarcoFalke/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
        "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
        "repos_url": "https://api.github.com/users/MarcoFalke/repos",
        "events_url": "https://api.github.com/users/MarcoFalke/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2021-09-08T11:52:54Z",
      "lock_reason": "resolved"
    }
  ],
  "comments": [
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178233629",
      "pull_request_review_id": 108264341,
      "id": 178233629,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODIzMzYyOQ==",
      "diff_hunk": "@@ -0,0 +1,864 @@\n+#!/usr/bin/env python",
      "path": "src/test/parallel.py",
      "position": 1,
      "original_position": 1,
      "commit_id": "7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "original_commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "in_reply_to_id": null,
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Should be `python3`￼?",
      "created_at": "2018-03-30T05:08:48Z",
      "updated_at": "2018-04-10T16:06:27Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#discussion_r178233629",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178233629"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1,
      "original_line": 1,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178234706",
      "pull_request_review_id": 108265562,
      "id": 178234706,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODIzNDcwNg==",
      "diff_hunk": "@@ -0,0 +1,864 @@\n+#!/usr/bin/env python\n+#\n+# Copyright 2013 Google Inc. All rights reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+try:\n+    import _pickle as cPickle\n+except ImportError:\n+    import cPickle\n+import errno\n+from functools import total_ordering\n+import gzip\n+import json\n+import multiprocessing\n+import configparser\n+import optparse\n+import os\n+from pickle import HIGHEST_PROTOCOL as PICKLE_HIGHEST_PROTOCOL\n+import re\n+import shutil\n+import signal\n+import subprocess\n+import sys\n+import tempfile\n+try:\n+    import _thread as thread\n+except ImportError:\n+    import thread\n+import threading\n+import time\n+\n+if sys.version_info.major >= 3:\n+    long = int\n+\n+if sys.platform == 'win32':\n+  import msvcrt\n+else:\n+  import fcntl\n+\n+\n+# An object that catches SIGINT sent to the Python process and notices\n+# if processes passed to wait() die by SIGINT (we need to look for\n+# both of those cases, because pressing Ctrl+C can result in either\n+# the main process or one of the subprocesses getting the signal).\n+#\n+# Before a SIGINT is seen, wait(p) will simply call p.wait() and\n+# return the result. Once a SIGINT has been seen (in the main process\n+# or a subprocess, including the one the current call is waiting for),\n+# wait(p) will call p.terminate() and raise ProcessWasInterrupted.\n+class SigintHandler(object):\n+  class ProcessWasInterrupted(Exception): pass\n+  sigint_returncodes = {-signal.SIGINT,  # Unix\n+                        -1073741510,     # Windows\n+                        }\n+  def __init__(self):\n+    self.__lock = threading.Lock()\n+    self.__processes = set()\n+    self.__got_sigint = False\n+    signal.signal(signal.SIGINT, lambda signal_num, frame: self.interrupt())\n+  def __on_sigint(self):\n+    self.__got_sigint = True\n+    while self.__processes:\n+      try:\n+        self.__processes.pop().terminate()\n+      except OSError:\n+        pass\n+  def interrupt(self):\n+    with self.__lock:\n+      self.__on_sigint()\n+  def got_sigint(self):\n+    with self.__lock:\n+      return self.__got_sigint\n+  def wait(self, p):\n+    with self.__lock:\n+      if self.__got_sigint:\n+        p.terminate()\n+      self.__processes.add(p)\n+    code = p.wait()\n+    with self.__lock:\n+      self.__processes.discard(p)\n+      if code in self.sigint_returncodes:\n+        self.__on_sigint()\n+      if self.__got_sigint:\n+        raise self.ProcessWasInterrupted\n+    return code\n+sigint_handler = SigintHandler()\n+\n+\n+# Return the width of the terminal, or None if it couldn't be\n+# determined (e.g. because we're not being run interactively).\n+def term_width(out):\n+  if not out.isatty():\n+    return None\n+  try:\n+    p = subprocess.Popen([\"stty\", \"size\"],\n+                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n+    (out, err) = p.communicate()\n+    if p.returncode != 0 or err:\n+      return None\n+    return int(out.split()[1])\n+  except (IndexError, OSError, ValueError):\n+    return None\n+\n+\n+# Output transient and permanent lines of text. If several transient\n+# lines are written in sequence, the new will overwrite the old. We\n+# use this to ensure that lots of unimportant info (tests passing)\n+# won't drown out important info (tests failing).\n+class Outputter(object):\n+  def __init__(self, out_file):\n+    self.__out_file = out_file\n+    self.__previous_line_was_transient = False\n+    self.__width = term_width(out_file)  # Line width, or None if not a tty.\n+  def transient_line(self, msg):\n+    if self.__width is None:\n+      self.__out_file.write(msg + \"\\n\")\n+    else:\n+      self.__out_file.write(\"\\r\" + msg[:self.__width].ljust(self.__width))\n+      self.__previous_line_was_transient = True\n+  def flush_transient_output(self):\n+    if self.__previous_line_was_transient:\n+      self.__out_file.write(\"\\n\")\n+      self.__previous_line_was_transient = False\n+  def permanent_line(self, msg):\n+    self.flush_transient_output()\n+    self.__out_file.write(msg + \"\\n\")\n+\n+\n+def get_save_file_path():\n+  \"\"\"Return path to file for saving transient data.\"\"\"\n+  if sys.platform == 'win32':\n+    default_cache_path = os.path.join(os.path.expanduser('~'),\n+                                      'AppData', 'Local')\n+    cache_path = os.environ.get('LOCALAPPDATA', default_cache_path)\n+  else:\n+    # We don't use xdg module since it's not a standard.\n+    default_cache_path = os.path.join(os.path.expanduser('~'), '.cache')\n+    cache_path = os.environ.get('XDG_CACHE_HOME', default_cache_path)\n+\n+  if os.path.isdir(cache_path):\n+    return os.path.join(cache_path, 'gtest-parallel')\n+  else:\n+    sys.stderr.write('Directory {} does not exist'.format(cache_path))\n+    return os.path.join(os.path.expanduser('~'), '.gtest-parallel-times')\n+\n+\n+@total_ordering\n+class Task(object):\n+  \"\"\"Stores information about a task (single execution of a test).\n+\n+  This class stores information about the test to be executed (gtest binary and\n+  test name), and its result (log file, exit code and runtime).\n+  Each task is uniquely identified by the gtest binary, the test name and an\n+  execution number that increases each time the test is executed.\n+  Additionaly we store the last execution time, so that next time the test is\n+  executed, the slowest tests are run first.\n+  \"\"\"\n+  def __init__(self, test_binary, test_name, test_command, execution_number,\n+               last_execution_time, output_dir):\n+    self.test_name = test_name\n+    self.output_dir = output_dir\n+    self.test_binary = test_binary\n+    self.test_command = test_command\n+    self.execution_number = execution_number\n+    self.last_execution_time = last_execution_time\n+\n+    self.exit_code = None\n+    self.runtime_ms = None\n+\n+    self.test_id = (test_binary, test_name)\n+    self.task_id = (test_binary, test_name, self.execution_number)\n+\n+    self.log_file = Task._logname(self.output_dir, self.test_binary,\n+                                  test_name, self.execution_number)\n+\n+  def __sorting_key(self):\n+    # Unseen or failing tests (both missing execution time) take precedence over\n+    # execution time. Tests are greater (seen as slower) when missing times so\n+    # that they are executed first.\n+    return (1 if self.last_execution_time is None else 0,\n+            self.last_execution_time)\n+\n+  def __eq__(self, other):\n+      return self.__sorting_key() == other.__sorting_key()\n+\n+  def __ne__(self, other):\n+      return not (self == other)\n+\n+  def __lt__(self, other):\n+      return self.__sorting_key() < other.__sorting_key()\n+\n+  @staticmethod\n+  def _normalize(string):\n+    return re.sub('[^A-Za-z0-9]', '_', string)\n+\n+  @staticmethod\n+  def _logname(output_dir, test_binary, test_name, execution_number):\n+    # Store logs to temporary files if there is no output_dir.\n+    if output_dir is None:\n+      (log_handle, log_name) = tempfile.mkstemp(prefix='gtest_parallel_',\n+                                                suffix=\".log\")\n+      os.close(log_handle)\n+      return log_name\n+\n+    log_name = '%s-%s-%d.log' % (Task._normalize(os.path.basename(test_binary)),\n+                                 Task._normalize(test_name), execution_number)\n+\n+    return os.path.join(output_dir, log_name)\n+\n+  def run(self):\n+    begin = time.time()\n+    with open(self.log_file, 'w') as log:\n+      task = subprocess.Popen(self.test_command, stdout=log, stderr=log)\n+      try:\n+        self.exit_code = sigint_handler.wait(task)\n+      except sigint_handler.ProcessWasInterrupted:\n+        thread.exit()\n+    self.runtime_ms = int(1000 * (time.time() - begin))\n+    self.last_execution_time = None if self.exit_code else self.runtime_ms\n+\n+\n+class TaskManager(object):\n+  \"\"\"Executes the tasks and stores the passed, failed and interrupted tasks.\n+\n+  When a task is run, this class keeps track if it passed, failed or was\n+  interrupted. After a task finishes it calls the relevant functions of the\n+  Logger, TestResults and TestTimes classes, and in case of failure, retries the\n+  test as specified by the --retry_failed flag.\n+  \"\"\"\n+  def __init__(self, times, logger, test_results, task_factory, times_to_retry,\n+               initial_execution_number):\n+    self.times = times\n+    self.logger = logger\n+    self.test_results = test_results\n+    self.task_factory = task_factory\n+    self.times_to_retry = times_to_retry\n+    self.initial_execution_number = initial_execution_number\n+\n+    self.global_exit_code = 0\n+\n+    self.passed = []\n+    self.failed = []\n+    self.started = {}\n+    self.execution_number = {}\n+\n+    self.lock = threading.Lock()\n+\n+  def __get_next_execution_number(self, test_id):\n+    with self.lock:\n+      next_execution_number = self.execution_number.setdefault(\n+          test_id, self.initial_execution_number)\n+      self.execution_number[test_id] += 1\n+    return next_execution_number\n+\n+  def __register_start(self, task):\n+    with self.lock:\n+      self.started[task.task_id] = task\n+\n+  def __register_exit(self, task):\n+    self.logger.log_exit(task)\n+    self.times.record_test_time(task.test_binary, task.test_name,\n+                                task.last_execution_time)\n+    if self.test_results:\n+      self.test_results.log(task.test_name, task.runtime_ms,\n+                            \"PASS\" if task.exit_code == 0 else \"FAIL\")\n+\n+    with self.lock:\n+      self.started.pop(task.task_id)\n+      if task.exit_code == 0:\n+        self.passed.append(task)\n+      else:\n+        self.failed.append(task)\n+\n+  def run_task(self, task):\n+    for try_number in range(self.times_to_retry + 1):\n+      self.__register_start(task)\n+      task.run()\n+      self.__register_exit(task)\n+\n+      if task.exit_code == 0:\n+        break\n+\n+      if try_number < self.times_to_retry:\n+        execution_number = self.__get_next_execution_number(task.test_id)\n+        # We need create a new Task instance. Each task represents a single test\n+        # execution, with its own runtime, exit code and log file.\n+        task = self.task_factory(task.test_binary, task.test_name,\n+                                 task.test_command, execution_number,\n+                                 task.last_execution_time, task.output_dir)\n+\n+    with self.lock:\n+      if task.exit_code != 0:\n+        self.global_exit_code = task.exit_code\n+\n+\n+class FilterFormat(object):\n+  def __init__(self, output_dir):\n+    if sys.stdout.isatty():\n+      # stdout needs to be unbuffered since the output is interactive.\n+      sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)",
      "path": "src/test/parallel.py",
      "position": 310,
      "original_position": 310,
      "commit_id": "7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "original_commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "in_reply_to_id": null,
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "This seems to be fine in python 2.7 but is a problem in 3.x\r\n```\r\nValueError: can't have unbuffered text I/O\r\n```\r\nThe 0 buffer is only valid for byte streams in python 3, from docs the default buffer policy for interactive text files is line buffering, which is probably fine. ",
      "created_at": "2018-03-30T05:24:29Z",
      "updated_at": "2018-04-10T16:06:27Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#discussion_r178234706",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178234706"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 310,
      "original_line": 310,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178235787",
      "pull_request_review_id": 108266847,
      "id": 178235787,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODIzNTc4Nw==",
      "diff_hunk": "@@ -0,0 +1,285 @@\n+arith_uint256_tests/basics\n+arith_uint256_tests/shifts\n+arith_uint256_tests/unaryOperators\n+arith_uint256_tests/bitwiseOperators\n+arith_uint256_tests/comparison\n+arith_uint256_tests/plusMinus\n+arith_uint256_tests/multiply\n+arith_uint256_tests/divide\n+arith_uint256_tests/methods\n+arith_uint256_tests/bignum_SetCompact\n+arith_uint256_tests/getmaxcoverage\n+addrman_tests/addrman_simple\n+addrman_tests/addrman_ports\n+addrman_tests/addrman_select\n+addrman_tests/addrman_new_collisions\n+addrman_tests/addrman_tried_collisions\n+addrman_tests/addrman_find\n+addrman_tests/addrman_create\n+addrman_tests/addrman_delete\n+addrman_tests/addrman_getaddr\n+addrman_tests/caddrinfo_get_tried_bucket\n+addrman_tests/caddrinfo_get_new_bucket\n+addrman_tests/addrman_selecttriedcollision\n+addrman_tests/addrman_noevict\n+addrman_tests/addrman_evictionworks\n+amount_tests/MoneyRangeTest\n+amount_tests/GetFeeTest\n+amount_tests/BinaryOperatorTest\n+amount_tests/ToStringTest\n+allocator_tests/arena_tests\n+allocator_tests/lockedpool_tests_mock\n+allocator_tests/lockedpool_tests_live\n+base32_tests/base32_testvectors\n+base58_tests/base58_EncodeBase58\n+base58_tests/base58_DecodeBase58\n+base64_tests/base64_testvectors\n+abc/bech32_tests/bip173_testvectors_valid",
      "path": "src/test/test_list.txt",
      "position": null,
      "original_position": 37,
      "commit_id": "7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "original_commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "in_reply_to_id": null,
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "not sure why abc/ is appended to path. Getting error:\r\n```\r\nTest setup error: no test cases matching filter\r\n```\r\nRemoving abc/ lets tests run and pass. ",
      "created_at": "2018-03-30T05:41:18Z",
      "updated_at": "2018-04-10T16:06:27Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#discussion_r178235787",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178235787"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 37,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178236227",
      "pull_request_review_id": 108267366,
      "id": 178236227,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODIzNjIyNw==",
      "diff_hunk": "@@ -0,0 +1,285 @@\n+arith_uint256_tests/basics\n+arith_uint256_tests/shifts\n+arith_uint256_tests/unaryOperators\n+arith_uint256_tests/bitwiseOperators\n+arith_uint256_tests/comparison\n+arith_uint256_tests/plusMinus\n+arith_uint256_tests/multiply\n+arith_uint256_tests/divide\n+arith_uint256_tests/methods\n+arith_uint256_tests/bignum_SetCompact\n+arith_uint256_tests/getmaxcoverage\n+addrman_tests/addrman_simple\n+addrman_tests/addrman_ports\n+addrman_tests/addrman_select\n+addrman_tests/addrman_new_collisions\n+addrman_tests/addrman_tried_collisions\n+addrman_tests/addrman_find\n+addrman_tests/addrman_create\n+addrman_tests/addrman_delete\n+addrman_tests/addrman_getaddr\n+addrman_tests/caddrinfo_get_tried_bucket\n+addrman_tests/caddrinfo_get_new_bucket\n+addrman_tests/addrman_selecttriedcollision\n+addrman_tests/addrman_noevict\n+addrman_tests/addrman_evictionworks\n+amount_tests/MoneyRangeTest\n+amount_tests/GetFeeTest\n+amount_tests/BinaryOperatorTest\n+amount_tests/ToStringTest\n+allocator_tests/arena_tests\n+allocator_tests/lockedpool_tests_mock\n+allocator_tests/lockedpool_tests_live\n+base32_tests/base32_testvectors\n+base58_tests/base58_EncodeBase58\n+base58_tests/base58_DecodeBase58\n+base64_tests/base64_testvectors\n+abc/bech32_tests/bip173_testvectors_valid",
      "path": "src/test/test_list.txt",
      "position": null,
      "original_position": 37,
      "commit_id": "7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "original_commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "in_reply_to_id": 178235787,
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "This also poses an interesting problem. If the test case isn't found, its listed as `FAILED TESTS`, which is somewhat confusing, because `bech32_tests/bip173_testvectors_valid` would pass, it's just the path listed is wrong. \r\n\r\nMaybe the initial reader of `FILE_TEST_LIST` can verify the path exists before handing it off to workers. ",
      "created_at": "2018-03-30T05:47:40Z",
      "updated_at": "2018-04-10T16:06:27Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#discussion_r178236227",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178236227"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 37,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178236641",
      "pull_request_review_id": 108267828,
      "id": 178236641,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODIzNjY0MQ==",
      "diff_hunk": "@@ -0,0 +1,864 @@\n+#!/usr/bin/env python\n+#\n+# Copyright 2013 Google Inc. All rights reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+try:\n+    import _pickle as cPickle\n+except ImportError:\n+    import cPickle\n+import errno\n+from functools import total_ordering\n+import gzip\n+import json\n+import multiprocessing\n+import configparser\n+import optparse\n+import os\n+from pickle import HIGHEST_PROTOCOL as PICKLE_HIGHEST_PROTOCOL\n+import re\n+import shutil\n+import signal\n+import subprocess\n+import sys\n+import tempfile\n+try:\n+    import _thread as thread\n+except ImportError:\n+    import thread\n+import threading\n+import time\n+\n+if sys.version_info.major >= 3:\n+    long = int\n+\n+if sys.platform == 'win32':\n+  import msvcrt\n+else:\n+  import fcntl\n+\n+\n+# An object that catches SIGINT sent to the Python process and notices\n+# if processes passed to wait() die by SIGINT (we need to look for\n+# both of those cases, because pressing Ctrl+C can result in either\n+# the main process or one of the subprocesses getting the signal).\n+#\n+# Before a SIGINT is seen, wait(p) will simply call p.wait() and\n+# return the result. Once a SIGINT has been seen (in the main process\n+# or a subprocess, including the one the current call is waiting for),\n+# wait(p) will call p.terminate() and raise ProcessWasInterrupted.\n+class SigintHandler(object):\n+  class ProcessWasInterrupted(Exception): pass\n+  sigint_returncodes = {-signal.SIGINT,  # Unix\n+                        -1073741510,     # Windows\n+                        }\n+  def __init__(self):\n+    self.__lock = threading.Lock()\n+    self.__processes = set()\n+    self.__got_sigint = False\n+    signal.signal(signal.SIGINT, lambda signal_num, frame: self.interrupt())\n+  def __on_sigint(self):\n+    self.__got_sigint = True\n+    while self.__processes:\n+      try:\n+        self.__processes.pop().terminate()\n+      except OSError:\n+        pass\n+  def interrupt(self):\n+    with self.__lock:\n+      self.__on_sigint()\n+  def got_sigint(self):\n+    with self.__lock:\n+      return self.__got_sigint\n+  def wait(self, p):\n+    with self.__lock:\n+      if self.__got_sigint:\n+        p.terminate()\n+      self.__processes.add(p)\n+    code = p.wait()\n+    with self.__lock:\n+      self.__processes.discard(p)\n+      if code in self.sigint_returncodes:\n+        self.__on_sigint()\n+      if self.__got_sigint:\n+        raise self.ProcessWasInterrupted\n+    return code\n+sigint_handler = SigintHandler()\n+\n+\n+# Return the width of the terminal, or None if it couldn't be\n+# determined (e.g. because we're not being run interactively).\n+def term_width(out):\n+  if not out.isatty():\n+    return None\n+  try:\n+    p = subprocess.Popen([\"stty\", \"size\"],\n+                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n+    (out, err) = p.communicate()\n+    if p.returncode != 0 or err:\n+      return None\n+    return int(out.split()[1])\n+  except (IndexError, OSError, ValueError):\n+    return None\n+\n+\n+# Output transient and permanent lines of text. If several transient\n+# lines are written in sequence, the new will overwrite the old. We\n+# use this to ensure that lots of unimportant info (tests passing)\n+# won't drown out important info (tests failing).\n+class Outputter(object):\n+  def __init__(self, out_file):\n+    self.__out_file = out_file\n+    self.__previous_line_was_transient = False\n+    self.__width = term_width(out_file)  # Line width, or None if not a tty.\n+  def transient_line(self, msg):\n+    if self.__width is None:\n+      self.__out_file.write(msg + \"\\n\")\n+    else:\n+      self.__out_file.write(\"\\r\" + msg[:self.__width].ljust(self.__width))\n+      self.__previous_line_was_transient = True\n+  def flush_transient_output(self):\n+    if self.__previous_line_was_transient:\n+      self.__out_file.write(\"\\n\")\n+      self.__previous_line_was_transient = False\n+  def permanent_line(self, msg):\n+    self.flush_transient_output()\n+    self.__out_file.write(msg + \"\\n\")\n+\n+\n+def get_save_file_path():\n+  \"\"\"Return path to file for saving transient data.\"\"\"\n+  if sys.platform == 'win32':\n+    default_cache_path = os.path.join(os.path.expanduser('~'),\n+                                      'AppData', 'Local')\n+    cache_path = os.environ.get('LOCALAPPDATA', default_cache_path)\n+  else:\n+    # We don't use xdg module since it's not a standard.\n+    default_cache_path = os.path.join(os.path.expanduser('~'), '.cache')\n+    cache_path = os.environ.get('XDG_CACHE_HOME', default_cache_path)\n+\n+  if os.path.isdir(cache_path):\n+    return os.path.join(cache_path, 'gtest-parallel')\n+  else:\n+    sys.stderr.write('Directory {} does not exist'.format(cache_path))\n+    return os.path.join(os.path.expanduser('~'), '.gtest-parallel-times')\n+\n+\n+@total_ordering\n+class Task(object):\n+  \"\"\"Stores information about a task (single execution of a test).\n+\n+  This class stores information about the test to be executed (gtest binary and\n+  test name), and its result (log file, exit code and runtime).\n+  Each task is uniquely identified by the gtest binary, the test name and an\n+  execution number that increases each time the test is executed.\n+  Additionaly we store the last execution time, so that next time the test is\n+  executed, the slowest tests are run first.\n+  \"\"\"\n+  def __init__(self, test_binary, test_name, test_command, execution_number,\n+               last_execution_time, output_dir):\n+    self.test_name = test_name\n+    self.output_dir = output_dir\n+    self.test_binary = test_binary\n+    self.test_command = test_command\n+    self.execution_number = execution_number\n+    self.last_execution_time = last_execution_time\n+\n+    self.exit_code = None\n+    self.runtime_ms = None\n+\n+    self.test_id = (test_binary, test_name)\n+    self.task_id = (test_binary, test_name, self.execution_number)\n+\n+    self.log_file = Task._logname(self.output_dir, self.test_binary,\n+                                  test_name, self.execution_number)\n+\n+  def __sorting_key(self):\n+    # Unseen or failing tests (both missing execution time) take precedence over\n+    # execution time. Tests are greater (seen as slower) when missing times so\n+    # that they are executed first.\n+    return (1 if self.last_execution_time is None else 0,\n+            self.last_execution_time)\n+\n+  def __eq__(self, other):\n+      return self.__sorting_key() == other.__sorting_key()\n+\n+  def __ne__(self, other):\n+      return not (self == other)\n+\n+  def __lt__(self, other):\n+      return self.__sorting_key() < other.__sorting_key()\n+\n+  @staticmethod\n+  def _normalize(string):\n+    return re.sub('[^A-Za-z0-9]', '_', string)\n+\n+  @staticmethod\n+  def _logname(output_dir, test_binary, test_name, execution_number):\n+    # Store logs to temporary files if there is no output_dir.\n+    if output_dir is None:\n+      (log_handle, log_name) = tempfile.mkstemp(prefix='gtest_parallel_',\n+                                                suffix=\".log\")\n+      os.close(log_handle)\n+      return log_name\n+\n+    log_name = '%s-%s-%d.log' % (Task._normalize(os.path.basename(test_binary)),\n+                                 Task._normalize(test_name), execution_number)\n+\n+    return os.path.join(output_dir, log_name)\n+\n+  def run(self):\n+    begin = time.time()\n+    with open(self.log_file, 'w') as log:\n+      task = subprocess.Popen(self.test_command, stdout=log, stderr=log)\n+      try:\n+        self.exit_code = sigint_handler.wait(task)\n+      except sigint_handler.ProcessWasInterrupted:\n+        thread.exit()\n+    self.runtime_ms = int(1000 * (time.time() - begin))\n+    self.last_execution_time = None if self.exit_code else self.runtime_ms\n+\n+\n+class TaskManager(object):\n+  \"\"\"Executes the tasks and stores the passed, failed and interrupted tasks.\n+\n+  When a task is run, this class keeps track if it passed, failed or was\n+  interrupted. After a task finishes it calls the relevant functions of the\n+  Logger, TestResults and TestTimes classes, and in case of failure, retries the\n+  test as specified by the --retry_failed flag.\n+  \"\"\"\n+  def __init__(self, times, logger, test_results, task_factory, times_to_retry,\n+               initial_execution_number):\n+    self.times = times\n+    self.logger = logger\n+    self.test_results = test_results\n+    self.task_factory = task_factory\n+    self.times_to_retry = times_to_retry\n+    self.initial_execution_number = initial_execution_number\n+\n+    self.global_exit_code = 0\n+\n+    self.passed = []\n+    self.failed = []\n+    self.started = {}\n+    self.execution_number = {}\n+\n+    self.lock = threading.Lock()\n+\n+  def __get_next_execution_number(self, test_id):\n+    with self.lock:\n+      next_execution_number = self.execution_number.setdefault(\n+          test_id, self.initial_execution_number)\n+      self.execution_number[test_id] += 1\n+    return next_execution_number\n+\n+  def __register_start(self, task):\n+    with self.lock:\n+      self.started[task.task_id] = task\n+\n+  def __register_exit(self, task):\n+    self.logger.log_exit(task)\n+    self.times.record_test_time(task.test_binary, task.test_name,\n+                                task.last_execution_time)\n+    if self.test_results:\n+      self.test_results.log(task.test_name, task.runtime_ms,\n+                            \"PASS\" if task.exit_code == 0 else \"FAIL\")\n+\n+    with self.lock:\n+      self.started.pop(task.task_id)\n+      if task.exit_code == 0:\n+        self.passed.append(task)\n+      else:\n+        self.failed.append(task)\n+\n+  def run_task(self, task):\n+    for try_number in range(self.times_to_retry + 1):\n+      self.__register_start(task)\n+      task.run()\n+      self.__register_exit(task)\n+\n+      if task.exit_code == 0:\n+        break\n+\n+      if try_number < self.times_to_retry:\n+        execution_number = self.__get_next_execution_number(task.test_id)\n+        # We need create a new Task instance. Each task represents a single test\n+        # execution, with its own runtime, exit code and log file.\n+        task = self.task_factory(task.test_binary, task.test_name,\n+                                 task.test_command, execution_number,\n+                                 task.last_execution_time, task.output_dir)\n+\n+    with self.lock:\n+      if task.exit_code != 0:\n+        self.global_exit_code = task.exit_code\n+\n+\n+class FilterFormat(object):\n+  def __init__(self, output_dir):\n+    if sys.stdout.isatty():\n+      # stdout needs to be unbuffered since the output is interactive.\n+      sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)\n+\n+    self.output_dir = output_dir\n+\n+    self.total_tasks = 0\n+    self.finished_tasks = 0\n+    self.out = Outputter(sys.stdout)\n+    self.stdout_lock = threading.Lock()\n+\n+  def move_to(self, destination_dir, tasks):\n+    if self.output_dir is None:\n+      return\n+\n+    destination_dir = os.path.join(self.output_dir, destination_dir)\n+    os.makedirs(destination_dir)\n+    for task in tasks:\n+      shutil.move(task.log_file, destination_dir)\n+\n+  def print_tests(self, message, tasks, print_try_number):\n+    self.out.permanent_line(\"%s (%s/%s):\" %\n+                            (message, len(tasks), self.total_tasks))\n+    for task in sorted(tasks):\n+      runtime_ms = 'Interrupted'\n+      if task.runtime_ms is not None:\n+        runtime_ms = '%d ms' % task.runtime_ms\n+      self.out.permanent_line(\"%11s: %s %s%s\" % (\n+          runtime_ms, task.test_binary, task.test_name,\n+          (\" (try #%d)\" % task.execution_number) if print_try_number else \"\"))\n+\n+  def log_exit(self, task):\n+    with self.stdout_lock:\n+      self.finished_tasks += 1\n+      self.out.transient_line(\"[%d/%d] %s (%d ms)\"\n+                              % (self.finished_tasks, self.total_tasks,\n+                                 task.test_name, task.runtime_ms))\n+      if task.exit_code != 0:\n+        with open(task.log_file) as f:\n+          for line in f.readlines():\n+            self.out.permanent_line(line.rstrip())\n+        self.out.permanent_line(\n+          \"[%d/%d] %s returned/aborted with exit code %d (%d ms)\"\n+          % (self.finished_tasks, self.total_tasks, task.test_name,\n+             task.exit_code, task.runtime_ms))\n+\n+    if self.output_dir is None:\n+      # Try to remove the file 100 times (sleeping for 0.1 second in between).\n+      # This is a workaround for a process handle seemingly holding on to the\n+      # file for too long inside os.subprocess. This workaround is in place\n+      # until we figure out a minimal repro to report upstream (or a better\n+      # suspect) to prevent os.remove exceptions.\n+      num_tries = 100\n+      for i in range(num_tries):\n+        try:\n+          os.remove(task.log_file)\n+        except OSError as e:\n+          if e.errno is not errno.ENOENT:\n+            if i is num_tries - 1:\n+              self.out.permanent_line('Could not remove temporary log file: ' + str(e))\n+            else:\n+              time.sleep(0.1)\n+            continue\n+        break\n+\n+  def log_tasks(self, total_tasks):\n+    self.total_tasks += total_tasks\n+    self.out.transient_line(\"[0/%d] Running tests...\" % self.total_tasks)\n+\n+  def summarize(self, passed_tasks, failed_tasks, interrupted_tasks):\n+    stats = {}\n+    def add_stats(stats, task, idx):\n+      task_key = (task.test_binary, task.test_name)\n+      if not task_key in stats:\n+        # (passed, failed, interrupted) task_key is added as tie breaker to get\n+        # alphabetic sorting on equally-stable tests\n+        stats[task_key] = [0, 0, 0, task_key]\n+      stats[task_key][idx] += 1\n+\n+    for task in passed_tasks:\n+      add_stats(stats, task, 0)\n+    for task in failed_tasks:\n+      add_stats(stats, task, 1)\n+    for task in interrupted_tasks:\n+      add_stats(stats, task, 2)\n+\n+    self.out.permanent_line(\"SUMMARY:\")\n+    for task_key in sorted(stats, key=stats.__getitem__):\n+      (num_passed, num_failed, num_interrupted, _) = stats[task_key]\n+      (test_binary, task_name) = task_key\n+      self.out.permanent_line(\n+          \"  %s %s passed %d / %d times%s.\" %\n+              (test_binary, task_name, num_passed,\n+               num_passed + num_failed + num_interrupted,\n+               \"\" if num_interrupted == 0 else (\" (%d interrupted)\" % num_interrupted)))\n+\n+  def flush(self):\n+    self.out.flush_transient_output()\n+\n+\n+class CollectTestResults(object):\n+  def __init__(self, json_dump_filepath):\n+    self.test_results_lock = threading.Lock()\n+    self.json_dump_file = open(json_dump_filepath, 'w')\n+    self.test_results = {\n+        \"interrupted\": False,\n+        \"path_delimiter\": \".\",\n+        # Third version of the file format. See the link in the flag description\n+        # for details.\n+        \"version\": 3,\n+        \"seconds_since_epoch\": int(time.time()),\n+        \"num_failures_by_type\": {\n+            \"PASS\": 0,\n+            \"FAIL\": 0,\n+        },\n+        \"tests\": {},\n+    }\n+\n+  def log(self, test, runtime_ms, actual_result):\n+    with self.test_results_lock:\n+      self.test_results['num_failures_by_type'][actual_result] += 1\n+      results = self.test_results['tests']\n+      for name in test.split('.'):\n+        results = results.setdefault(name, {})\n+\n+      if results:\n+        results['actual'] += ' ' + actual_result\n+        results['times'].append(runtime_ms)\n+      else:  # This is the first invocation of the test\n+        results['actual'] = actual_result\n+        results['times'] = [runtime_ms]\n+        results['time'] = runtime_ms\n+        results['expected'] = 'PASS'\n+\n+  def dump_to_file_and_close(self):\n+    json.dump(self.test_results, self.json_dump_file)\n+    self.json_dump_file.close()\n+\n+\n+# Record of test runtimes. Has built-in locking.\n+class TestTimes(object):\n+  class LockedFile(object):\n+    def __init__(self, filename, mode):\n+      self._filename = filename\n+      self._mode = mode\n+      self._fo = None\n+\n+    def __enter__(self):\n+      self._fo = open(self._filename, self._mode)\n+\n+      # Regardless of opening mode we always seek to the beginning of file.\n+      # This simplifies code working with LockedFile and also ensures that\n+      # we lock (and unlock below) always the same region in file on win32.\n+      self._fo.seek(0)\n+\n+      try:\n+        if sys.platform == 'win32':\n+          # We are locking here fixed location in file to use it as\n+          # an exclusive lock on entire file.\n+          msvcrt.locking(self._fo.fileno(), msvcrt.LK_LOCK, 1)\n+        else:\n+          fcntl.flock(self._fo.fileno(), fcntl.LOCK_EX)\n+      except IOError:\n+        self._fo.close()\n+        raise\n+\n+      return self._fo\n+\n+    def __exit__(self, exc_type, exc_value, traceback):\n+      # Flush any buffered data to disk. This is needed to prevent race\n+      # condition which happens from the moment of releasing file lock\n+      # till closing the file.\n+      self._fo.flush()\n+\n+      try:\n+        if sys.platform == 'win32':\n+          self._fo.seek(0)\n+          msvcrt.locking(self._fo.fileno(), msvcrt.LK_UNLCK, 1)\n+        else:\n+          fcntl.flock(self._fo.fileno(), fcntl.LOCK_UN)\n+      finally:\n+        self._fo.close()\n+\n+      return exc_value is None\n+\n+  def __init__(self, save_file):\n+    \"Create new object seeded with saved test times from the given file.\"\n+    self.__times = {}  # (test binary, test name) -> runtime in ms\n+\n+    # Protects calls to record_test_time(); other calls are not\n+    # expected to be made concurrently.\n+    self.__lock = threading.Lock()\n+\n+    try:\n+      with TestTimes.LockedFile(save_file, 'rb') as fd:\n+        times = TestTimes.__read_test_times_file(fd)\n+    except IOError:\n+      # We couldn't obtain the lock.\n+      return\n+\n+    # Discard saved times if the format isn't right.\n+    if type(times) is not dict:\n+      return\n+    for ((test_binary, test_name), runtime) in list(times.items()):\n+      if (type(test_binary) is not str or type(test_name) is not str\n+          or type(runtime) not in {int, long, type(None)}):\n+        return\n+\n+    self.__times = times\n+\n+  def get_test_time(self, binary, testname):\n+    \"\"\"Return the last duration for the given test as an integer number of\n+    milliseconds, or None if the test failed or if there's no record for it.\"\"\"\n+    return self.__times.get((binary, testname), None)\n+\n+  def record_test_time(self, binary, testname, runtime_ms):\n+    \"\"\"Record that the given test ran in the specified number of\n+    milliseconds. If the test failed, runtime_ms should be None.\"\"\"\n+    with self.__lock:\n+      self.__times[(binary, testname)] = runtime_ms\n+\n+  def write_to_file(self, save_file):\n+    \"Write all the times to file.\"\n+    try:\n+      with TestTimes.LockedFile(save_file, 'a+b') as fd:\n+        times = TestTimes.__read_test_times_file(fd)\n+\n+        if times is None:\n+          times = self.__times\n+        else:\n+          times.update(self.__times)\n+\n+        # We erase data from file while still holding a lock to it. This\n+        # way reading old test times and appending new ones are atomic\n+        # for external viewer.\n+        fd.seek(0)\n+        fd.truncate()\n+        with gzip.GzipFile(fileobj=fd, mode='wb') as gzf:\n+          cPickle.dump(times, gzf, PICKLE_HIGHEST_PROTOCOL)\n+    except IOError:\n+      pass  # ignore errors---saving the times isn't that important\n+\n+  @staticmethod\n+  def __read_test_times_file(fd):\n+    try:\n+      with gzip.GzipFile(fileobj=fd, mode='rb') as gzf:\n+        times = cPickle.load(gzf)\n+    except Exception:\n+      # File doesn't exist, isn't readable, is malformed---whatever.\n+      # Just ignore it.\n+      return None\n+    else:\n+      return times\n+\n+\n+def find_tests(test_list, binaries, additional_args, options, times):\n+  test_count = 0\n+  tasks = []\n+  for test_binary in binaries:\n+    command = [test_binary]\n+    command += additional_args\n+\n+    for test_name in test_list:\n+      last_execution_time = times.get_test_time(test_binary, test_name)\n+      if options.failed and last_execution_time is not None:\n+        continue\n+\n+      test_command = command + ['--run_test=' + test_name]\n+      if (test_count - options.shard_index) % options.shard_count == 0:\n+        for execution_number in range(options.repeat):\n+          tasks.append(Task(test_binary, test_name, test_command,\n+                            execution_number + 1, last_execution_time,\n+                            options.output_dir))\n+\n+      test_count += 1\n+\n+  # Sort the tasks to run the slowest tests first, so that faster ones can be\n+  # finished in parallel.\n+  return sorted(tasks, reverse=True)\n+\n+\n+def execute_tasks(tasks, pool_size, task_manager,\n+                  timeout, serialize_test_cases):\n+  class WorkerFn(object):\n+    def __init__(self, tasks, running_groups):\n+      self.tasks = tasks\n+      self.running_groups = running_groups\n+      self.task_lock = threading.Lock()\n+\n+    def __call__(self):\n+      while True:\n+        with self.task_lock:\n+          for task_id in range(len(self.tasks)):\n+            task = self.tasks[task_id]\n+\n+            if self.running_groups is not None:\n+              test_group = task.test_name.split('.')[0]\n+              if test_group in self.running_groups:\n+                # Try to find other non-running test group.\n+                continue\n+              else:\n+                self.running_groups.add(test_group)\n+\n+            del self.tasks[task_id]\n+            break\n+          else:\n+            # Either there is no tasks left or number or remaining test\n+            # cases (groups) is less than number or running threads.\n+            return\n+\n+        task_manager.run_task(task)\n+\n+        if self.running_groups is not None:\n+          with self.task_lock:\n+            self.running_groups.remove(test_group)\n+\n+  def start_daemon(func):\n+    t = threading.Thread(target=func)\n+    t.daemon = True\n+    t.start()\n+    return t\n+\n+  try:\n+    if timeout:\n+      timeout.start()\n+    running_groups = set() if serialize_test_cases else None\n+    worker_fn = WorkerFn(tasks, running_groups)\n+    workers = [start_daemon(worker_fn) for _ in range(pool_size)]\n+    for worker in workers:\n+      worker.join()\n+  finally:\n+    if timeout:\n+      timeout.cancel()\n+\n+\n+def default_options_parser(default_binary, file_test_list):\n+  parser = optparse.OptionParser(\n+      usage = 'usage: %prog [options] binary [binary ...] -- [additional args]')\n+\n+  parser.add_option('-d', '--output_dir', type='string', default=None,\n+                    help='Output directory for test logs. Logs will be '\n+                         'available under gtest-parallel-logs/, so '\n+                         '--output_dir=/tmp will results in all logs being '\n+                         'available under /tmp/gtest-parallel-logs/.')\n+  parser.add_option('-r', '--repeat', type='int', default=1,\n+                    help='Number of times to execute all the tests.')\n+  parser.add_option('--retry_failed', type='int', default=0,\n+                    help='Number of times to repeat failed tests.')\n+  parser.add_option('--failed', action='store_true', default=False,\n+                    help='run only failed and new tests')\n+  parser.add_option('-w', '--workers', type='int',\n+                    default=multiprocessing.cpu_count(),\n+                    help='number of workers to spawn')\n+  parser.add_option('--gtest_color', type='string', default='yes',\n+                    help='color output')\n+  parser.add_option('--gtest_filter', type='string', default='',\n+                    help='test filter')\n+  parser.add_option('--gtest_also_run_disabled_tests', action='store_true',\n+                    default=False, help='run disabled tests too')\n+  parser.add_option('--print_test_times', action='store_true', default=False,\n+                    help='list the run time of each test at the end of execution')\n+  parser.add_option('--shard_count', type='int', default=1,\n+                    help='total number of shards (for sharding test execution '\n+                         'between multiple machines)')\n+  parser.add_option('--shard_index', type='int', default=0,\n+                    help='zero-indexed number identifying this shard (for '\n+                         'sharding test execution between multiple machines)')\n+  parser.add_option('--dump_json_test_results', type='string', default=None,\n+                    help='Saves the results of the tests as a JSON machine-'\n+                         'readable file. The format of the file is specified at '\n+                         'https://www.chromium.org/developers/the-json-test-results-format')\n+  parser.add_option('--timeout', type='int', default=None,\n+                    help='Interrupt all remaining processes after the given '\n+                         'time (in seconds).')\n+  parser.add_option('--serialize_test_cases', action='store_true',\n+                    default=False, help='Do not run tests from the same test '\n+                                        'case in parallel.')\n+# Bitcoin Core specific options parsing: start\n+  parser.add_option('-l', '--write_list', action='store_true',\n+                    default=False, help='Write test list from the binary to '\n+                                        '{} and exit.'.format(file_test_list))\n+  parser.add_option('-b', '--binary', type=str, default=default_binary,\n+                    help='The test binary (default: {})'.format(default_binary))\n+# Bitcoin Core specific options parsing: end\n+  return parser\n+\n+\n+def main():\n+  # Remove additional arguments (anything after --).\n+  additional_args = []\n+\n+  for i in range(len(sys.argv)):\n+    if sys.argv[i] == '--':\n+      additional_args = sys.argv[i+1:]\n+      sys.argv = sys.argv[:i]\n+      break\n+# Bitcoin Core specific options parsing: start\n+  config = configparser.ConfigParser()\n+  configfile = os.path.abspath(os.path.dirname(__file__)) + \"/../../test/config.ini\"\n+  config.read_file(open(configfile))\n+  env = config['environment']\n+  FILE_TEST_LIST = os.path.join(env['SRCDIR'], 'src', 'test', 'test_list.txt')\n+  DEFAULT_BINARY = os.path.join(env['BUILDDIR'],'src', 'test','test_bitcoin'+env['EXEEXT'])\n+  parser = default_options_parser(DEFAULT_BINARY, FILE_TEST_LIST)\n+  (options, binaries) = parser.parse_args()\n+  if options.write_list:\n+      write_test_list(options.binary, FILE_TEST_LIST)\n+      sys.exit(0)\n+  test_list = read_test_list(FILE_TEST_LIST)\n+  binaries = [options.binary]\n+# Bitcoin Core specific options parsing: end\n+\n+  if (options.output_dir is not None and\n+      not os.path.isdir(options.output_dir)):\n+    parser.error('--output_dir value must be an existing directory, '\n+                 'current value is \"%s\"' % options.output_dir)\n+\n+  # Append gtest-parallel-logs to log output, this is to avoid deleting user\n+  # data if an user passes a directory where files are already present. If a\n+  # user specifies --output_dir=Docs/, we'll create Docs/gtest-parallel-logs\n+  # and clean that directory out on startup, instead of nuking Docs/.\n+  if options.output_dir:\n+    options.output_dir = os.path.join(options.output_dir,\n+                                      'gtest-parallel-logs')\n+\n+  if binaries == []:\n+    parser.print_usage()\n+    sys.exit(1)\n+\n+  if options.shard_count < 1:",
      "path": "src/test/parallel.py",
      "position": 730,
      "original_position": 737,
      "commit_id": "7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "original_commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "in_reply_to_id": null,
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Nit: if you are going to verify the input is valid, you can check some other fields as well\r\n\r\nRight now you could input a negative for `workers`, `repeat`, `timeout`, etc. without complaint",
      "created_at": "2018-03-30T05:52:47Z",
      "updated_at": "2018-04-10T16:06:27Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#discussion_r178236641",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178236641"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 730,
      "original_line": 730,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178237305",
      "pull_request_review_id": 108268589,
      "id": 178237305,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODIzNzMwNQ==",
      "diff_hunk": "@@ -0,0 +1,864 @@\n+#!/usr/bin/env python\n+#\n+# Copyright 2013 Google Inc. All rights reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+try:\n+    import _pickle as cPickle\n+except ImportError:\n+    import cPickle\n+import errno\n+from functools import total_ordering\n+import gzip\n+import json\n+import multiprocessing\n+import configparser\n+import optparse\n+import os\n+from pickle import HIGHEST_PROTOCOL as PICKLE_HIGHEST_PROTOCOL\n+import re\n+import shutil\n+import signal\n+import subprocess\n+import sys\n+import tempfile\n+try:\n+    import _thread as thread\n+except ImportError:\n+    import thread\n+import threading\n+import time\n+\n+if sys.version_info.major >= 3:\n+    long = int\n+\n+if sys.platform == 'win32':\n+  import msvcrt\n+else:\n+  import fcntl\n+\n+\n+# An object that catches SIGINT sent to the Python process and notices\n+# if processes passed to wait() die by SIGINT (we need to look for\n+# both of those cases, because pressing Ctrl+C can result in either\n+# the main process or one of the subprocesses getting the signal).\n+#\n+# Before a SIGINT is seen, wait(p) will simply call p.wait() and\n+# return the result. Once a SIGINT has been seen (in the main process\n+# or a subprocess, including the one the current call is waiting for),\n+# wait(p) will call p.terminate() and raise ProcessWasInterrupted.\n+class SigintHandler(object):\n+  class ProcessWasInterrupted(Exception): pass\n+  sigint_returncodes = {-signal.SIGINT,  # Unix\n+                        -1073741510,     # Windows\n+                        }\n+  def __init__(self):\n+    self.__lock = threading.Lock()\n+    self.__processes = set()\n+    self.__got_sigint = False\n+    signal.signal(signal.SIGINT, lambda signal_num, frame: self.interrupt())\n+  def __on_sigint(self):\n+    self.__got_sigint = True\n+    while self.__processes:\n+      try:\n+        self.__processes.pop().terminate()\n+      except OSError:\n+        pass\n+  def interrupt(self):\n+    with self.__lock:\n+      self.__on_sigint()\n+  def got_sigint(self):\n+    with self.__lock:\n+      return self.__got_sigint\n+  def wait(self, p):\n+    with self.__lock:\n+      if self.__got_sigint:\n+        p.terminate()\n+      self.__processes.add(p)\n+    code = p.wait()\n+    with self.__lock:\n+      self.__processes.discard(p)\n+      if code in self.sigint_returncodes:\n+        self.__on_sigint()\n+      if self.__got_sigint:\n+        raise self.ProcessWasInterrupted\n+    return code\n+sigint_handler = SigintHandler()\n+\n+\n+# Return the width of the terminal, or None if it couldn't be\n+# determined (e.g. because we're not being run interactively).\n+def term_width(out):\n+  if not out.isatty():\n+    return None\n+  try:\n+    p = subprocess.Popen([\"stty\", \"size\"],\n+                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n+    (out, err) = p.communicate()\n+    if p.returncode != 0 or err:\n+      return None\n+    return int(out.split()[1])\n+  except (IndexError, OSError, ValueError):\n+    return None\n+\n+\n+# Output transient and permanent lines of text. If several transient\n+# lines are written in sequence, the new will overwrite the old. We\n+# use this to ensure that lots of unimportant info (tests passing)\n+# won't drown out important info (tests failing).\n+class Outputter(object):\n+  def __init__(self, out_file):\n+    self.__out_file = out_file\n+    self.__previous_line_was_transient = False\n+    self.__width = term_width(out_file)  # Line width, or None if not a tty.\n+  def transient_line(self, msg):\n+    if self.__width is None:\n+      self.__out_file.write(msg + \"\\n\")\n+    else:\n+      self.__out_file.write(\"\\r\" + msg[:self.__width].ljust(self.__width))\n+      self.__previous_line_was_transient = True\n+  def flush_transient_output(self):\n+    if self.__previous_line_was_transient:\n+      self.__out_file.write(\"\\n\")\n+      self.__previous_line_was_transient = False\n+  def permanent_line(self, msg):\n+    self.flush_transient_output()\n+    self.__out_file.write(msg + \"\\n\")\n+\n+\n+def get_save_file_path():\n+  \"\"\"Return path to file for saving transient data.\"\"\"\n+  if sys.platform == 'win32':\n+    default_cache_path = os.path.join(os.path.expanduser('~'),\n+                                      'AppData', 'Local')\n+    cache_path = os.environ.get('LOCALAPPDATA', default_cache_path)\n+  else:\n+    # We don't use xdg module since it's not a standard.\n+    default_cache_path = os.path.join(os.path.expanduser('~'), '.cache')\n+    cache_path = os.environ.get('XDG_CACHE_HOME', default_cache_path)\n+\n+  if os.path.isdir(cache_path):\n+    return os.path.join(cache_path, 'gtest-parallel')\n+  else:\n+    sys.stderr.write('Directory {} does not exist'.format(cache_path))\n+    return os.path.join(os.path.expanduser('~'), '.gtest-parallel-times')\n+\n+\n+@total_ordering\n+class Task(object):\n+  \"\"\"Stores information about a task (single execution of a test).\n+\n+  This class stores information about the test to be executed (gtest binary and\n+  test name), and its result (log file, exit code and runtime).\n+  Each task is uniquely identified by the gtest binary, the test name and an\n+  execution number that increases each time the test is executed.\n+  Additionaly we store the last execution time, so that next time the test is\n+  executed, the slowest tests are run first.\n+  \"\"\"\n+  def __init__(self, test_binary, test_name, test_command, execution_number,\n+               last_execution_time, output_dir):\n+    self.test_name = test_name\n+    self.output_dir = output_dir\n+    self.test_binary = test_binary\n+    self.test_command = test_command\n+    self.execution_number = execution_number\n+    self.last_execution_time = last_execution_time\n+\n+    self.exit_code = None\n+    self.runtime_ms = None\n+\n+    self.test_id = (test_binary, test_name)\n+    self.task_id = (test_binary, test_name, self.execution_number)\n+\n+    self.log_file = Task._logname(self.output_dir, self.test_binary,\n+                                  test_name, self.execution_number)\n+\n+  def __sorting_key(self):\n+    # Unseen or failing tests (both missing execution time) take precedence over\n+    # execution time. Tests are greater (seen as slower) when missing times so\n+    # that they are executed first.\n+    return (1 if self.last_execution_time is None else 0,\n+            self.last_execution_time)\n+\n+  def __eq__(self, other):\n+      return self.__sorting_key() == other.__sorting_key()\n+\n+  def __ne__(self, other):\n+      return not (self == other)\n+\n+  def __lt__(self, other):\n+      return self.__sorting_key() < other.__sorting_key()\n+\n+  @staticmethod\n+  def _normalize(string):\n+    return re.sub('[^A-Za-z0-9]', '_', string)\n+\n+  @staticmethod\n+  def _logname(output_dir, test_binary, test_name, execution_number):\n+    # Store logs to temporary files if there is no output_dir.\n+    if output_dir is None:\n+      (log_handle, log_name) = tempfile.mkstemp(prefix='gtest_parallel_',\n+                                                suffix=\".log\")\n+      os.close(log_handle)\n+      return log_name\n+\n+    log_name = '%s-%s-%d.log' % (Task._normalize(os.path.basename(test_binary)),\n+                                 Task._normalize(test_name), execution_number)\n+\n+    return os.path.join(output_dir, log_name)\n+\n+  def run(self):\n+    begin = time.time()\n+    with open(self.log_file, 'w') as log:\n+      task = subprocess.Popen(self.test_command, stdout=log, stderr=log)\n+      try:\n+        self.exit_code = sigint_handler.wait(task)\n+      except sigint_handler.ProcessWasInterrupted:\n+        thread.exit()\n+    self.runtime_ms = int(1000 * (time.time() - begin))\n+    self.last_execution_time = None if self.exit_code else self.runtime_ms\n+\n+\n+class TaskManager(object):\n+  \"\"\"Executes the tasks and stores the passed, failed and interrupted tasks.\n+\n+  When a task is run, this class keeps track if it passed, failed or was\n+  interrupted. After a task finishes it calls the relevant functions of the\n+  Logger, TestResults and TestTimes classes, and in case of failure, retries the\n+  test as specified by the --retry_failed flag.\n+  \"\"\"\n+  def __init__(self, times, logger, test_results, task_factory, times_to_retry,\n+               initial_execution_number):\n+    self.times = times\n+    self.logger = logger\n+    self.test_results = test_results\n+    self.task_factory = task_factory\n+    self.times_to_retry = times_to_retry\n+    self.initial_execution_number = initial_execution_number\n+\n+    self.global_exit_code = 0\n+\n+    self.passed = []\n+    self.failed = []\n+    self.started = {}\n+    self.execution_number = {}\n+\n+    self.lock = threading.Lock()\n+\n+  def __get_next_execution_number(self, test_id):\n+    with self.lock:\n+      next_execution_number = self.execution_number.setdefault(\n+          test_id, self.initial_execution_number)\n+      self.execution_number[test_id] += 1\n+    return next_execution_number\n+\n+  def __register_start(self, task):\n+    with self.lock:\n+      self.started[task.task_id] = task\n+\n+  def __register_exit(self, task):\n+    self.logger.log_exit(task)\n+    self.times.record_test_time(task.test_binary, task.test_name,\n+                                task.last_execution_time)\n+    if self.test_results:\n+      self.test_results.log(task.test_name, task.runtime_ms,\n+                            \"PASS\" if task.exit_code == 0 else \"FAIL\")\n+\n+    with self.lock:\n+      self.started.pop(task.task_id)\n+      if task.exit_code == 0:\n+        self.passed.append(task)\n+      else:\n+        self.failed.append(task)\n+\n+  def run_task(self, task):\n+    for try_number in range(self.times_to_retry + 1):\n+      self.__register_start(task)\n+      task.run()\n+      self.__register_exit(task)\n+\n+      if task.exit_code == 0:\n+        break\n+\n+      if try_number < self.times_to_retry:\n+        execution_number = self.__get_next_execution_number(task.test_id)\n+        # We need create a new Task instance. Each task represents a single test\n+        # execution, with its own runtime, exit code and log file.\n+        task = self.task_factory(task.test_binary, task.test_name,\n+                                 task.test_command, execution_number,\n+                                 task.last_execution_time, task.output_dir)\n+\n+    with self.lock:\n+      if task.exit_code != 0:\n+        self.global_exit_code = task.exit_code\n+\n+\n+class FilterFormat(object):\n+  def __init__(self, output_dir):\n+    if sys.stdout.isatty():\n+      # stdout needs to be unbuffered since the output is interactive.\n+      sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)\n+\n+    self.output_dir = output_dir\n+\n+    self.total_tasks = 0\n+    self.finished_tasks = 0\n+    self.out = Outputter(sys.stdout)\n+    self.stdout_lock = threading.Lock()\n+\n+  def move_to(self, destination_dir, tasks):\n+    if self.output_dir is None:\n+      return\n+\n+    destination_dir = os.path.join(self.output_dir, destination_dir)\n+    os.makedirs(destination_dir)\n+    for task in tasks:\n+      shutil.move(task.log_file, destination_dir)\n+\n+  def print_tests(self, message, tasks, print_try_number):\n+    self.out.permanent_line(\"%s (%s/%s):\" %\n+                            (message, len(tasks), self.total_tasks))\n+    for task in sorted(tasks):\n+      runtime_ms = 'Interrupted'\n+      if task.runtime_ms is not None:\n+        runtime_ms = '%d ms' % task.runtime_ms\n+      self.out.permanent_line(\"%11s: %s %s%s\" % (\n+          runtime_ms, task.test_binary, task.test_name,\n+          (\" (try #%d)\" % task.execution_number) if print_try_number else \"\"))\n+\n+  def log_exit(self, task):\n+    with self.stdout_lock:\n+      self.finished_tasks += 1\n+      self.out.transient_line(\"[%d/%d] %s (%d ms)\"\n+                              % (self.finished_tasks, self.total_tasks,\n+                                 task.test_name, task.runtime_ms))\n+      if task.exit_code != 0:\n+        with open(task.log_file) as f:\n+          for line in f.readlines():\n+            self.out.permanent_line(line.rstrip())\n+        self.out.permanent_line(\n+          \"[%d/%d] %s returned/aborted with exit code %d (%d ms)\"\n+          % (self.finished_tasks, self.total_tasks, task.test_name,\n+             task.exit_code, task.runtime_ms))\n+\n+    if self.output_dir is None:\n+      # Try to remove the file 100 times (sleeping for 0.1 second in between).\n+      # This is a workaround for a process handle seemingly holding on to the\n+      # file for too long inside os.subprocess. This workaround is in place\n+      # until we figure out a minimal repro to report upstream (or a better\n+      # suspect) to prevent os.remove exceptions.\n+      num_tries = 100\n+      for i in range(num_tries):\n+        try:\n+          os.remove(task.log_file)\n+        except OSError as e:\n+          if e.errno is not errno.ENOENT:\n+            if i is num_tries - 1:\n+              self.out.permanent_line('Could not remove temporary log file: ' + str(e))\n+            else:\n+              time.sleep(0.1)\n+            continue\n+        break\n+\n+  def log_tasks(self, total_tasks):\n+    self.total_tasks += total_tasks\n+    self.out.transient_line(\"[0/%d] Running tests...\" % self.total_tasks)\n+\n+  def summarize(self, passed_tasks, failed_tasks, interrupted_tasks):\n+    stats = {}\n+    def add_stats(stats, task, idx):\n+      task_key = (task.test_binary, task.test_name)\n+      if not task_key in stats:\n+        # (passed, failed, interrupted) task_key is added as tie breaker to get\n+        # alphabetic sorting on equally-stable tests\n+        stats[task_key] = [0, 0, 0, task_key]\n+      stats[task_key][idx] += 1\n+\n+    for task in passed_tasks:\n+      add_stats(stats, task, 0)\n+    for task in failed_tasks:\n+      add_stats(stats, task, 1)\n+    for task in interrupted_tasks:\n+      add_stats(stats, task, 2)\n+\n+    self.out.permanent_line(\"SUMMARY:\")\n+    for task_key in sorted(stats, key=stats.__getitem__):\n+      (num_passed, num_failed, num_interrupted, _) = stats[task_key]\n+      (test_binary, task_name) = task_key\n+      self.out.permanent_line(\n+          \"  %s %s passed %d / %d times%s.\" %\n+              (test_binary, task_name, num_passed,\n+               num_passed + num_failed + num_interrupted,\n+               \"\" if num_interrupted == 0 else (\" (%d interrupted)\" % num_interrupted)))\n+\n+  def flush(self):\n+    self.out.flush_transient_output()\n+\n+\n+class CollectTestResults(object):\n+  def __init__(self, json_dump_filepath):\n+    self.test_results_lock = threading.Lock()\n+    self.json_dump_file = open(json_dump_filepath, 'w')\n+    self.test_results = {\n+        \"interrupted\": False,\n+        \"path_delimiter\": \".\",\n+        # Third version of the file format. See the link in the flag description\n+        # for details.\n+        \"version\": 3,\n+        \"seconds_since_epoch\": int(time.time()),\n+        \"num_failures_by_type\": {\n+            \"PASS\": 0,\n+            \"FAIL\": 0,\n+        },\n+        \"tests\": {},\n+    }\n+\n+  def log(self, test, runtime_ms, actual_result):\n+    with self.test_results_lock:\n+      self.test_results['num_failures_by_type'][actual_result] += 1\n+      results = self.test_results['tests']\n+      for name in test.split('.'):\n+        results = results.setdefault(name, {})\n+\n+      if results:\n+        results['actual'] += ' ' + actual_result\n+        results['times'].append(runtime_ms)\n+      else:  # This is the first invocation of the test\n+        results['actual'] = actual_result\n+        results['times'] = [runtime_ms]\n+        results['time'] = runtime_ms\n+        results['expected'] = 'PASS'\n+\n+  def dump_to_file_and_close(self):\n+    json.dump(self.test_results, self.json_dump_file)\n+    self.json_dump_file.close()\n+\n+\n+# Record of test runtimes. Has built-in locking.\n+class TestTimes(object):\n+  class LockedFile(object):\n+    def __init__(self, filename, mode):\n+      self._filename = filename\n+      self._mode = mode\n+      self._fo = None\n+\n+    def __enter__(self):\n+      self._fo = open(self._filename, self._mode)\n+\n+      # Regardless of opening mode we always seek to the beginning of file.\n+      # This simplifies code working with LockedFile and also ensures that\n+      # we lock (and unlock below) always the same region in file on win32.\n+      self._fo.seek(0)\n+\n+      try:\n+        if sys.platform == 'win32':\n+          # We are locking here fixed location in file to use it as\n+          # an exclusive lock on entire file.\n+          msvcrt.locking(self._fo.fileno(), msvcrt.LK_LOCK, 1)\n+        else:\n+          fcntl.flock(self._fo.fileno(), fcntl.LOCK_EX)\n+      except IOError:\n+        self._fo.close()\n+        raise\n+\n+      return self._fo\n+\n+    def __exit__(self, exc_type, exc_value, traceback):\n+      # Flush any buffered data to disk. This is needed to prevent race\n+      # condition which happens from the moment of releasing file lock\n+      # till closing the file.\n+      self._fo.flush()\n+\n+      try:\n+        if sys.platform == 'win32':\n+          self._fo.seek(0)\n+          msvcrt.locking(self._fo.fileno(), msvcrt.LK_UNLCK, 1)\n+        else:\n+          fcntl.flock(self._fo.fileno(), fcntl.LOCK_UN)\n+      finally:\n+        self._fo.close()\n+\n+      return exc_value is None\n+\n+  def __init__(self, save_file):\n+    \"Create new object seeded with saved test times from the given file.\"\n+    self.__times = {}  # (test binary, test name) -> runtime in ms\n+\n+    # Protects calls to record_test_time(); other calls are not\n+    # expected to be made concurrently.\n+    self.__lock = threading.Lock()\n+\n+    try:\n+      with TestTimes.LockedFile(save_file, 'rb') as fd:\n+        times = TestTimes.__read_test_times_file(fd)\n+    except IOError:\n+      # We couldn't obtain the lock.\n+      return\n+\n+    # Discard saved times if the format isn't right.\n+    if type(times) is not dict:\n+      return\n+    for ((test_binary, test_name), runtime) in list(times.items()):\n+      if (type(test_binary) is not str or type(test_name) is not str\n+          or type(runtime) not in {int, long, type(None)}):\n+        return\n+\n+    self.__times = times\n+\n+  def get_test_time(self, binary, testname):\n+    \"\"\"Return the last duration for the given test as an integer number of\n+    milliseconds, or None if the test failed or if there's no record for it.\"\"\"\n+    return self.__times.get((binary, testname), None)\n+\n+  def record_test_time(self, binary, testname, runtime_ms):\n+    \"\"\"Record that the given test ran in the specified number of\n+    milliseconds. If the test failed, runtime_ms should be None.\"\"\"\n+    with self.__lock:\n+      self.__times[(binary, testname)] = runtime_ms\n+\n+  def write_to_file(self, save_file):\n+    \"Write all the times to file.\"\n+    try:\n+      with TestTimes.LockedFile(save_file, 'a+b') as fd:\n+        times = TestTimes.__read_test_times_file(fd)\n+\n+        if times is None:\n+          times = self.__times\n+        else:\n+          times.update(self.__times)\n+\n+        # We erase data from file while still holding a lock to it. This\n+        # way reading old test times and appending new ones are atomic\n+        # for external viewer.\n+        fd.seek(0)\n+        fd.truncate()\n+        with gzip.GzipFile(fileobj=fd, mode='wb') as gzf:\n+          cPickle.dump(times, gzf, PICKLE_HIGHEST_PROTOCOL)\n+    except IOError:\n+      pass  # ignore errors---saving the times isn't that important\n+\n+  @staticmethod\n+  def __read_test_times_file(fd):\n+    try:\n+      with gzip.GzipFile(fileobj=fd, mode='rb') as gzf:\n+        times = cPickle.load(gzf)\n+    except Exception:\n+      # File doesn't exist, isn't readable, is malformed---whatever.\n+      # Just ignore it.\n+      return None\n+    else:\n+      return times\n+\n+\n+def find_tests(test_list, binaries, additional_args, options, times):\n+  test_count = 0\n+  tasks = []\n+  for test_binary in binaries:\n+    command = [test_binary]\n+    command += additional_args\n+\n+    for test_name in test_list:\n+      last_execution_time = times.get_test_time(test_binary, test_name)\n+      if options.failed and last_execution_time is not None:\n+        continue\n+\n+      test_command = command + ['--run_test=' + test_name]\n+      if (test_count - options.shard_index) % options.shard_count == 0:\n+        for execution_number in range(options.repeat):\n+          tasks.append(Task(test_binary, test_name, test_command,\n+                            execution_number + 1, last_execution_time,\n+                            options.output_dir))\n+\n+      test_count += 1\n+\n+  # Sort the tasks to run the slowest tests first, so that faster ones can be\n+  # finished in parallel.\n+  return sorted(tasks, reverse=True)\n+\n+\n+def execute_tasks(tasks, pool_size, task_manager,\n+                  timeout, serialize_test_cases):\n+  class WorkerFn(object):\n+    def __init__(self, tasks, running_groups):\n+      self.tasks = tasks\n+      self.running_groups = running_groups\n+      self.task_lock = threading.Lock()\n+\n+    def __call__(self):\n+      while True:\n+        with self.task_lock:\n+          for task_id in range(len(self.tasks)):\n+            task = self.tasks[task_id]\n+\n+            if self.running_groups is not None:\n+              test_group = task.test_name.split('.')[0]\n+              if test_group in self.running_groups:\n+                # Try to find other non-running test group.\n+                continue\n+              else:\n+                self.running_groups.add(test_group)\n+\n+            del self.tasks[task_id]\n+            break\n+          else:\n+            # Either there is no tasks left or number or remaining test\n+            # cases (groups) is less than number or running threads.\n+            return\n+\n+        task_manager.run_task(task)\n+\n+        if self.running_groups is not None:\n+          with self.task_lock:\n+            self.running_groups.remove(test_group)\n+\n+  def start_daemon(func):\n+    t = threading.Thread(target=func)\n+    t.daemon = True\n+    t.start()\n+    return t\n+\n+  try:\n+    if timeout:\n+      timeout.start()\n+    running_groups = set() if serialize_test_cases else None\n+    worker_fn = WorkerFn(tasks, running_groups)\n+    workers = [start_daemon(worker_fn) for _ in range(pool_size)]\n+    for worker in workers:\n+      worker.join()\n+  finally:\n+    if timeout:\n+      timeout.cancel()\n+\n+\n+def default_options_parser(default_binary, file_test_list):\n+  parser = optparse.OptionParser(\n+      usage = 'usage: %prog [options] binary [binary ...] -- [additional args]')\n+\n+  parser.add_option('-d', '--output_dir', type='string', default=None,\n+                    help='Output directory for test logs. Logs will be '\n+                         'available under gtest-parallel-logs/, so '\n+                         '--output_dir=/tmp will results in all logs being '\n+                         'available under /tmp/gtest-parallel-logs/.')\n+  parser.add_option('-r', '--repeat', type='int', default=1,\n+                    help='Number of times to execute all the tests.')\n+  parser.add_option('--retry_failed', type='int', default=0,\n+                    help='Number of times to repeat failed tests.')\n+  parser.add_option('--failed', action='store_true', default=False,\n+                    help='run only failed and new tests')\n+  parser.add_option('-w', '--workers', type='int',\n+                    default=multiprocessing.cpu_count(),\n+                    help='number of workers to spawn')\n+  parser.add_option('--gtest_color', type='string', default='yes',\n+                    help='color output')\n+  parser.add_option('--gtest_filter', type='string', default='',\n+                    help='test filter')\n+  parser.add_option('--gtest_also_run_disabled_tests', action='store_true',\n+                    default=False, help='run disabled tests too')\n+  parser.add_option('--print_test_times', action='store_true', default=False,\n+                    help='list the run time of each test at the end of execution')\n+  parser.add_option('--shard_count', type='int', default=1,\n+                    help='total number of shards (for sharding test execution '\n+                         'between multiple machines)')\n+  parser.add_option('--shard_index', type='int', default=0,",
      "path": "src/test/parallel.py",
      "position": 672,
      "original_position": 672,
      "commit_id": "7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "original_commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "in_reply_to_id": null,
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Not sure it makes sense to give `shard_index` a default. I think you want to ensure that `shard_count` and `shard_index` are used in combination, so if `shard_count` is used and `options.shard_index` is `None`,  you print proper usage. Right now `options.shard_index` will just default to 0, so you can't tell if it's being used properly with `shard_count`. ",
      "created_at": "2018-03-30T06:01:30Z",
      "updated_at": "2018-04-10T16:06:27Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#discussion_r178237305",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178237305"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 672,
      "original_line": 672,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178238524",
      "pull_request_review_id": 108269924,
      "id": 178238524,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODIzODUyNA==",
      "diff_hunk": "@@ -0,0 +1,864 @@\n+#!/usr/bin/env python\n+#\n+# Copyright 2013 Google Inc. All rights reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+try:\n+    import _pickle as cPickle\n+except ImportError:\n+    import cPickle\n+import errno\n+from functools import total_ordering\n+import gzip\n+import json\n+import multiprocessing\n+import configparser\n+import optparse\n+import os\n+from pickle import HIGHEST_PROTOCOL as PICKLE_HIGHEST_PROTOCOL\n+import re\n+import shutil\n+import signal\n+import subprocess\n+import sys\n+import tempfile\n+try:\n+    import _thread as thread\n+except ImportError:\n+    import thread\n+import threading\n+import time\n+\n+if sys.version_info.major >= 3:\n+    long = int\n+\n+if sys.platform == 'win32':\n+  import msvcrt\n+else:\n+  import fcntl\n+\n+\n+# An object that catches SIGINT sent to the Python process and notices\n+# if processes passed to wait() die by SIGINT (we need to look for\n+# both of those cases, because pressing Ctrl+C can result in either\n+# the main process or one of the subprocesses getting the signal).\n+#\n+# Before a SIGINT is seen, wait(p) will simply call p.wait() and\n+# return the result. Once a SIGINT has been seen (in the main process\n+# or a subprocess, including the one the current call is waiting for),\n+# wait(p) will call p.terminate() and raise ProcessWasInterrupted.\n+class SigintHandler(object):\n+  class ProcessWasInterrupted(Exception): pass\n+  sigint_returncodes = {-signal.SIGINT,  # Unix\n+                        -1073741510,     # Windows\n+                        }\n+  def __init__(self):\n+    self.__lock = threading.Lock()\n+    self.__processes = set()\n+    self.__got_sigint = False\n+    signal.signal(signal.SIGINT, lambda signal_num, frame: self.interrupt())\n+  def __on_sigint(self):\n+    self.__got_sigint = True\n+    while self.__processes:\n+      try:\n+        self.__processes.pop().terminate()\n+      except OSError:\n+        pass\n+  def interrupt(self):\n+    with self.__lock:\n+      self.__on_sigint()\n+  def got_sigint(self):\n+    with self.__lock:\n+      return self.__got_sigint\n+  def wait(self, p):\n+    with self.__lock:\n+      if self.__got_sigint:\n+        p.terminate()\n+      self.__processes.add(p)\n+    code = p.wait()\n+    with self.__lock:\n+      self.__processes.discard(p)\n+      if code in self.sigint_returncodes:\n+        self.__on_sigint()\n+      if self.__got_sigint:\n+        raise self.ProcessWasInterrupted\n+    return code\n+sigint_handler = SigintHandler()\n+\n+\n+# Return the width of the terminal, or None if it couldn't be\n+# determined (e.g. because we're not being run interactively).\n+def term_width(out):\n+  if not out.isatty():\n+    return None\n+  try:\n+    p = subprocess.Popen([\"stty\", \"size\"],\n+                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n+    (out, err) = p.communicate()\n+    if p.returncode != 0 or err:\n+      return None\n+    return int(out.split()[1])\n+  except (IndexError, OSError, ValueError):\n+    return None\n+\n+\n+# Output transient and permanent lines of text. If several transient\n+# lines are written in sequence, the new will overwrite the old. We\n+# use this to ensure that lots of unimportant info (tests passing)\n+# won't drown out important info (tests failing).\n+class Outputter(object):\n+  def __init__(self, out_file):\n+    self.__out_file = out_file\n+    self.__previous_line_was_transient = False\n+    self.__width = term_width(out_file)  # Line width, or None if not a tty.\n+  def transient_line(self, msg):\n+    if self.__width is None:\n+      self.__out_file.write(msg + \"\\n\")\n+    else:\n+      self.__out_file.write(\"\\r\" + msg[:self.__width].ljust(self.__width))\n+      self.__previous_line_was_transient = True\n+  def flush_transient_output(self):\n+    if self.__previous_line_was_transient:\n+      self.__out_file.write(\"\\n\")\n+      self.__previous_line_was_transient = False\n+  def permanent_line(self, msg):\n+    self.flush_transient_output()\n+    self.__out_file.write(msg + \"\\n\")\n+\n+\n+def get_save_file_path():\n+  \"\"\"Return path to file for saving transient data.\"\"\"\n+  if sys.platform == 'win32':\n+    default_cache_path = os.path.join(os.path.expanduser('~'),\n+                                      'AppData', 'Local')\n+    cache_path = os.environ.get('LOCALAPPDATA', default_cache_path)\n+  else:\n+    # We don't use xdg module since it's not a standard.\n+    default_cache_path = os.path.join(os.path.expanduser('~'), '.cache')\n+    cache_path = os.environ.get('XDG_CACHE_HOME', default_cache_path)\n+\n+  if os.path.isdir(cache_path):\n+    return os.path.join(cache_path, 'gtest-parallel')\n+  else:\n+    sys.stderr.write('Directory {} does not exist'.format(cache_path))\n+    return os.path.join(os.path.expanduser('~'), '.gtest-parallel-times')\n+\n+\n+@total_ordering\n+class Task(object):\n+  \"\"\"Stores information about a task (single execution of a test).\n+\n+  This class stores information about the test to be executed (gtest binary and\n+  test name), and its result (log file, exit code and runtime).\n+  Each task is uniquely identified by the gtest binary, the test name and an\n+  execution number that increases each time the test is executed.\n+  Additionaly we store the last execution time, so that next time the test is\n+  executed, the slowest tests are run first.\n+  \"\"\"\n+  def __init__(self, test_binary, test_name, test_command, execution_number,\n+               last_execution_time, output_dir):\n+    self.test_name = test_name\n+    self.output_dir = output_dir\n+    self.test_binary = test_binary\n+    self.test_command = test_command\n+    self.execution_number = execution_number\n+    self.last_execution_time = last_execution_time\n+\n+    self.exit_code = None\n+    self.runtime_ms = None\n+\n+    self.test_id = (test_binary, test_name)\n+    self.task_id = (test_binary, test_name, self.execution_number)\n+\n+    self.log_file = Task._logname(self.output_dir, self.test_binary,\n+                                  test_name, self.execution_number)\n+\n+  def __sorting_key(self):\n+    # Unseen or failing tests (both missing execution time) take precedence over\n+    # execution time. Tests are greater (seen as slower) when missing times so\n+    # that they are executed first.\n+    return (1 if self.last_execution_time is None else 0,\n+            self.last_execution_time)\n+\n+  def __eq__(self, other):\n+      return self.__sorting_key() == other.__sorting_key()\n+\n+  def __ne__(self, other):\n+      return not (self == other)\n+\n+  def __lt__(self, other):\n+      return self.__sorting_key() < other.__sorting_key()\n+\n+  @staticmethod\n+  def _normalize(string):\n+    return re.sub('[^A-Za-z0-9]', '_', string)\n+\n+  @staticmethod\n+  def _logname(output_dir, test_binary, test_name, execution_number):\n+    # Store logs to temporary files if there is no output_dir.\n+    if output_dir is None:\n+      (log_handle, log_name) = tempfile.mkstemp(prefix='gtest_parallel_',\n+                                                suffix=\".log\")\n+      os.close(log_handle)\n+      return log_name\n+\n+    log_name = '%s-%s-%d.log' % (Task._normalize(os.path.basename(test_binary)),\n+                                 Task._normalize(test_name), execution_number)\n+\n+    return os.path.join(output_dir, log_name)\n+\n+  def run(self):\n+    begin = time.time()\n+    with open(self.log_file, 'w') as log:\n+      task = subprocess.Popen(self.test_command, stdout=log, stderr=log)\n+      try:\n+        self.exit_code = sigint_handler.wait(task)\n+      except sigint_handler.ProcessWasInterrupted:\n+        thread.exit()\n+    self.runtime_ms = int(1000 * (time.time() - begin))\n+    self.last_execution_time = None if self.exit_code else self.runtime_ms\n+\n+\n+class TaskManager(object):\n+  \"\"\"Executes the tasks and stores the passed, failed and interrupted tasks.\n+\n+  When a task is run, this class keeps track if it passed, failed or was\n+  interrupted. After a task finishes it calls the relevant functions of the\n+  Logger, TestResults and TestTimes classes, and in case of failure, retries the\n+  test as specified by the --retry_failed flag.\n+  \"\"\"\n+  def __init__(self, times, logger, test_results, task_factory, times_to_retry,\n+               initial_execution_number):\n+    self.times = times\n+    self.logger = logger\n+    self.test_results = test_results\n+    self.task_factory = task_factory\n+    self.times_to_retry = times_to_retry\n+    self.initial_execution_number = initial_execution_number\n+\n+    self.global_exit_code = 0\n+\n+    self.passed = []\n+    self.failed = []\n+    self.started = {}\n+    self.execution_number = {}\n+\n+    self.lock = threading.Lock()\n+\n+  def __get_next_execution_number(self, test_id):\n+    with self.lock:\n+      next_execution_number = self.execution_number.setdefault(\n+          test_id, self.initial_execution_number)\n+      self.execution_number[test_id] += 1\n+    return next_execution_number\n+\n+  def __register_start(self, task):\n+    with self.lock:\n+      self.started[task.task_id] = task\n+\n+  def __register_exit(self, task):\n+    self.logger.log_exit(task)\n+    self.times.record_test_time(task.test_binary, task.test_name,\n+                                task.last_execution_time)\n+    if self.test_results:\n+      self.test_results.log(task.test_name, task.runtime_ms,\n+                            \"PASS\" if task.exit_code == 0 else \"FAIL\")\n+\n+    with self.lock:\n+      self.started.pop(task.task_id)\n+      if task.exit_code == 0:\n+        self.passed.append(task)\n+      else:\n+        self.failed.append(task)\n+\n+  def run_task(self, task):\n+    for try_number in range(self.times_to_retry + 1):\n+      self.__register_start(task)\n+      task.run()\n+      self.__register_exit(task)\n+\n+      if task.exit_code == 0:\n+        break\n+\n+      if try_number < self.times_to_retry:\n+        execution_number = self.__get_next_execution_number(task.test_id)\n+        # We need create a new Task instance. Each task represents a single test\n+        # execution, with its own runtime, exit code and log file.\n+        task = self.task_factory(task.test_binary, task.test_name,\n+                                 task.test_command, execution_number,\n+                                 task.last_execution_time, task.output_dir)\n+\n+    with self.lock:\n+      if task.exit_code != 0:\n+        self.global_exit_code = task.exit_code\n+\n+\n+class FilterFormat(object):\n+  def __init__(self, output_dir):\n+    if sys.stdout.isatty():\n+      # stdout needs to be unbuffered since the output is interactive.\n+      sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)\n+\n+    self.output_dir = output_dir\n+\n+    self.total_tasks = 0\n+    self.finished_tasks = 0\n+    self.out = Outputter(sys.stdout)\n+    self.stdout_lock = threading.Lock()\n+\n+  def move_to(self, destination_dir, tasks):\n+    if self.output_dir is None:\n+      return\n+\n+    destination_dir = os.path.join(self.output_dir, destination_dir)\n+    os.makedirs(destination_dir)\n+    for task in tasks:\n+      shutil.move(task.log_file, destination_dir)\n+\n+  def print_tests(self, message, tasks, print_try_number):\n+    self.out.permanent_line(\"%s (%s/%s):\" %\n+                            (message, len(tasks), self.total_tasks))\n+    for task in sorted(tasks):\n+      runtime_ms = 'Interrupted'\n+      if task.runtime_ms is not None:\n+        runtime_ms = '%d ms' % task.runtime_ms\n+      self.out.permanent_line(\"%11s: %s %s%s\" % (\n+          runtime_ms, task.test_binary, task.test_name,\n+          (\" (try #%d)\" % task.execution_number) if print_try_number else \"\"))\n+\n+  def log_exit(self, task):\n+    with self.stdout_lock:\n+      self.finished_tasks += 1\n+      self.out.transient_line(\"[%d/%d] %s (%d ms)\"\n+                              % (self.finished_tasks, self.total_tasks,\n+                                 task.test_name, task.runtime_ms))\n+      if task.exit_code != 0:\n+        with open(task.log_file) as f:\n+          for line in f.readlines():\n+            self.out.permanent_line(line.rstrip())\n+        self.out.permanent_line(\n+          \"[%d/%d] %s returned/aborted with exit code %d (%d ms)\"\n+          % (self.finished_tasks, self.total_tasks, task.test_name,\n+             task.exit_code, task.runtime_ms))\n+\n+    if self.output_dir is None:\n+      # Try to remove the file 100 times (sleeping for 0.1 second in between).\n+      # This is a workaround for a process handle seemingly holding on to the\n+      # file for too long inside os.subprocess. This workaround is in place\n+      # until we figure out a minimal repro to report upstream (or a better\n+      # suspect) to prevent os.remove exceptions.\n+      num_tries = 100\n+      for i in range(num_tries):\n+        try:\n+          os.remove(task.log_file)\n+        except OSError as e:\n+          if e.errno is not errno.ENOENT:\n+            if i is num_tries - 1:\n+              self.out.permanent_line('Could not remove temporary log file: ' + str(e))\n+            else:\n+              time.sleep(0.1)\n+            continue\n+        break\n+\n+  def log_tasks(self, total_tasks):\n+    self.total_tasks += total_tasks\n+    self.out.transient_line(\"[0/%d] Running tests...\" % self.total_tasks)\n+\n+  def summarize(self, passed_tasks, failed_tasks, interrupted_tasks):\n+    stats = {}\n+    def add_stats(stats, task, idx):\n+      task_key = (task.test_binary, task.test_name)\n+      if not task_key in stats:\n+        # (passed, failed, interrupted) task_key is added as tie breaker to get\n+        # alphabetic sorting on equally-stable tests\n+        stats[task_key] = [0, 0, 0, task_key]\n+      stats[task_key][idx] += 1\n+\n+    for task in passed_tasks:\n+      add_stats(stats, task, 0)\n+    for task in failed_tasks:\n+      add_stats(stats, task, 1)\n+    for task in interrupted_tasks:\n+      add_stats(stats, task, 2)\n+\n+    self.out.permanent_line(\"SUMMARY:\")\n+    for task_key in sorted(stats, key=stats.__getitem__):\n+      (num_passed, num_failed, num_interrupted, _) = stats[task_key]\n+      (test_binary, task_name) = task_key\n+      self.out.permanent_line(\n+          \"  %s %s passed %d / %d times%s.\" %\n+              (test_binary, task_name, num_passed,\n+               num_passed + num_failed + num_interrupted,\n+               \"\" if num_interrupted == 0 else (\" (%d interrupted)\" % num_interrupted)))\n+\n+  def flush(self):\n+    self.out.flush_transient_output()\n+\n+\n+class CollectTestResults(object):\n+  def __init__(self, json_dump_filepath):\n+    self.test_results_lock = threading.Lock()\n+    self.json_dump_file = open(json_dump_filepath, 'w')\n+    self.test_results = {\n+        \"interrupted\": False,\n+        \"path_delimiter\": \".\",\n+        # Third version of the file format. See the link in the flag description\n+        # for details.\n+        \"version\": 3,\n+        \"seconds_since_epoch\": int(time.time()),\n+        \"num_failures_by_type\": {\n+            \"PASS\": 0,\n+            \"FAIL\": 0,\n+        },\n+        \"tests\": {},\n+    }\n+\n+  def log(self, test, runtime_ms, actual_result):\n+    with self.test_results_lock:\n+      self.test_results['num_failures_by_type'][actual_result] += 1\n+      results = self.test_results['tests']\n+      for name in test.split('.'):\n+        results = results.setdefault(name, {})\n+\n+      if results:\n+        results['actual'] += ' ' + actual_result\n+        results['times'].append(runtime_ms)\n+      else:  # This is the first invocation of the test\n+        results['actual'] = actual_result\n+        results['times'] = [runtime_ms]\n+        results['time'] = runtime_ms\n+        results['expected'] = 'PASS'\n+\n+  def dump_to_file_and_close(self):\n+    json.dump(self.test_results, self.json_dump_file)\n+    self.json_dump_file.close()\n+\n+\n+# Record of test runtimes. Has built-in locking.\n+class TestTimes(object):\n+  class LockedFile(object):\n+    def __init__(self, filename, mode):\n+      self._filename = filename\n+      self._mode = mode\n+      self._fo = None\n+\n+    def __enter__(self):\n+      self._fo = open(self._filename, self._mode)\n+\n+      # Regardless of opening mode we always seek to the beginning of file.\n+      # This simplifies code working with LockedFile and also ensures that\n+      # we lock (and unlock below) always the same region in file on win32.\n+      self._fo.seek(0)\n+\n+      try:\n+        if sys.platform == 'win32':\n+          # We are locking here fixed location in file to use it as\n+          # an exclusive lock on entire file.\n+          msvcrt.locking(self._fo.fileno(), msvcrt.LK_LOCK, 1)\n+        else:\n+          fcntl.flock(self._fo.fileno(), fcntl.LOCK_EX)\n+      except IOError:\n+        self._fo.close()\n+        raise\n+\n+      return self._fo\n+\n+    def __exit__(self, exc_type, exc_value, traceback):\n+      # Flush any buffered data to disk. This is needed to prevent race\n+      # condition which happens from the moment of releasing file lock\n+      # till closing the file.\n+      self._fo.flush()\n+\n+      try:\n+        if sys.platform == 'win32':\n+          self._fo.seek(0)\n+          msvcrt.locking(self._fo.fileno(), msvcrt.LK_UNLCK, 1)\n+        else:\n+          fcntl.flock(self._fo.fileno(), fcntl.LOCK_UN)\n+      finally:\n+        self._fo.close()\n+\n+      return exc_value is None\n+\n+  def __init__(self, save_file):\n+    \"Create new object seeded with saved test times from the given file.\"\n+    self.__times = {}  # (test binary, test name) -> runtime in ms\n+\n+    # Protects calls to record_test_time(); other calls are not\n+    # expected to be made concurrently.\n+    self.__lock = threading.Lock()\n+\n+    try:\n+      with TestTimes.LockedFile(save_file, 'rb') as fd:\n+        times = TestTimes.__read_test_times_file(fd)\n+    except IOError:\n+      # We couldn't obtain the lock.\n+      return\n+\n+    # Discard saved times if the format isn't right.\n+    if type(times) is not dict:\n+      return\n+    for ((test_binary, test_name), runtime) in list(times.items()):\n+      if (type(test_binary) is not str or type(test_name) is not str\n+          or type(runtime) not in {int, long, type(None)}):\n+        return\n+\n+    self.__times = times\n+\n+  def get_test_time(self, binary, testname):\n+    \"\"\"Return the last duration for the given test as an integer number of\n+    milliseconds, or None if the test failed or if there's no record for it.\"\"\"\n+    return self.__times.get((binary, testname), None)\n+\n+  def record_test_time(self, binary, testname, runtime_ms):\n+    \"\"\"Record that the given test ran in the specified number of\n+    milliseconds. If the test failed, runtime_ms should be None.\"\"\"\n+    with self.__lock:\n+      self.__times[(binary, testname)] = runtime_ms\n+\n+  def write_to_file(self, save_file):\n+    \"Write all the times to file.\"\n+    try:\n+      with TestTimes.LockedFile(save_file, 'a+b') as fd:\n+        times = TestTimes.__read_test_times_file(fd)\n+\n+        if times is None:\n+          times = self.__times\n+        else:\n+          times.update(self.__times)\n+\n+        # We erase data from file while still holding a lock to it. This\n+        # way reading old test times and appending new ones are atomic\n+        # for external viewer.\n+        fd.seek(0)\n+        fd.truncate()\n+        with gzip.GzipFile(fileobj=fd, mode='wb') as gzf:\n+          cPickle.dump(times, gzf, PICKLE_HIGHEST_PROTOCOL)\n+    except IOError:\n+      pass  # ignore errors---saving the times isn't that important\n+\n+  @staticmethod\n+  def __read_test_times_file(fd):\n+    try:\n+      with gzip.GzipFile(fileobj=fd, mode='rb') as gzf:\n+        times = cPickle.load(gzf)\n+    except Exception:\n+      # File doesn't exist, isn't readable, is malformed---whatever.\n+      # Just ignore it.\n+      return None\n+    else:\n+      return times\n+\n+\n+def find_tests(test_list, binaries, additional_args, options, times):\n+  test_count = 0\n+  tasks = []\n+  for test_binary in binaries:\n+    command = [test_binary]\n+    command += additional_args\n+\n+    for test_name in test_list:\n+      last_execution_time = times.get_test_time(test_binary, test_name)\n+      if options.failed and last_execution_time is not None:\n+        continue\n+\n+      test_command = command + ['--run_test=' + test_name]\n+      if (test_count - options.shard_index) % options.shard_count == 0:\n+        for execution_number in range(options.repeat):\n+          tasks.append(Task(test_binary, test_name, test_command,\n+                            execution_number + 1, last_execution_time,\n+                            options.output_dir))\n+\n+      test_count += 1\n+\n+  # Sort the tasks to run the slowest tests first, so that faster ones can be\n+  # finished in parallel.\n+  return sorted(tasks, reverse=True)\n+\n+\n+def execute_tasks(tasks, pool_size, task_manager,\n+                  timeout, serialize_test_cases):\n+  class WorkerFn(object):\n+    def __init__(self, tasks, running_groups):\n+      self.tasks = tasks\n+      self.running_groups = running_groups\n+      self.task_lock = threading.Lock()\n+\n+    def __call__(self):\n+      while True:\n+        with self.task_lock:\n+          for task_id in range(len(self.tasks)):\n+            task = self.tasks[task_id]\n+\n+            if self.running_groups is not None:\n+              test_group = task.test_name.split('.')[0]",
      "path": "src/test/parallel.py",
      "position": 604,
      "original_position": 604,
      "commit_id": "7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "original_commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "in_reply_to_id": null,
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Should this be `split('/')[0]` ?\r\n\r\nRight now `task.test_name` is a line from `src/test/test_list.txt` like \r\n```\r\nbloom_tests/rolling_bloom\r\n```\r\nSo the split will always return that full path, since there is no `.` - making `option.serialize_test_cases` just run everything in parallel anyway. ",
      "created_at": "2018-03-30T06:15:14Z",
      "updated_at": "2018-04-10T16:06:27Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#discussion_r178238524",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178238524"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 604,
      "original_line": 604,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178238820",
      "pull_request_review_id": 108270259,
      "id": 178238820,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODIzODgyMA==",
      "diff_hunk": "@@ -0,0 +1,864 @@\n+#!/usr/bin/env python\n+#\n+# Copyright 2013 Google Inc. All rights reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+try:\n+    import _pickle as cPickle\n+except ImportError:\n+    import cPickle\n+import errno\n+from functools import total_ordering\n+import gzip\n+import json\n+import multiprocessing\n+import configparser\n+import optparse\n+import os\n+from pickle import HIGHEST_PROTOCOL as PICKLE_HIGHEST_PROTOCOL\n+import re\n+import shutil\n+import signal\n+import subprocess\n+import sys\n+import tempfile\n+try:\n+    import _thread as thread\n+except ImportError:\n+    import thread\n+import threading\n+import time\n+\n+if sys.version_info.major >= 3:\n+    long = int\n+\n+if sys.platform == 'win32':\n+  import msvcrt\n+else:\n+  import fcntl\n+\n+\n+# An object that catches SIGINT sent to the Python process and notices\n+# if processes passed to wait() die by SIGINT (we need to look for\n+# both of those cases, because pressing Ctrl+C can result in either\n+# the main process or one of the subprocesses getting the signal).\n+#\n+# Before a SIGINT is seen, wait(p) will simply call p.wait() and\n+# return the result. Once a SIGINT has been seen (in the main process\n+# or a subprocess, including the one the current call is waiting for),\n+# wait(p) will call p.terminate() and raise ProcessWasInterrupted.\n+class SigintHandler(object):\n+  class ProcessWasInterrupted(Exception): pass\n+  sigint_returncodes = {-signal.SIGINT,  # Unix\n+                        -1073741510,     # Windows\n+                        }\n+  def __init__(self):\n+    self.__lock = threading.Lock()\n+    self.__processes = set()\n+    self.__got_sigint = False\n+    signal.signal(signal.SIGINT, lambda signal_num, frame: self.interrupt())\n+  def __on_sigint(self):\n+    self.__got_sigint = True\n+    while self.__processes:\n+      try:\n+        self.__processes.pop().terminate()\n+      except OSError:\n+        pass\n+  def interrupt(self):\n+    with self.__lock:\n+      self.__on_sigint()\n+  def got_sigint(self):\n+    with self.__lock:\n+      return self.__got_sigint\n+  def wait(self, p):\n+    with self.__lock:\n+      if self.__got_sigint:\n+        p.terminate()\n+      self.__processes.add(p)\n+    code = p.wait()\n+    with self.__lock:\n+      self.__processes.discard(p)\n+      if code in self.sigint_returncodes:\n+        self.__on_sigint()\n+      if self.__got_sigint:\n+        raise self.ProcessWasInterrupted\n+    return code\n+sigint_handler = SigintHandler()\n+\n+\n+# Return the width of the terminal, or None if it couldn't be\n+# determined (e.g. because we're not being run interactively).\n+def term_width(out):\n+  if not out.isatty():\n+    return None\n+  try:\n+    p = subprocess.Popen([\"stty\", \"size\"],\n+                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n+    (out, err) = p.communicate()\n+    if p.returncode != 0 or err:\n+      return None\n+    return int(out.split()[1])\n+  except (IndexError, OSError, ValueError):\n+    return None\n+\n+\n+# Output transient and permanent lines of text. If several transient\n+# lines are written in sequence, the new will overwrite the old. We\n+# use this to ensure that lots of unimportant info (tests passing)\n+# won't drown out important info (tests failing).\n+class Outputter(object):\n+  def __init__(self, out_file):\n+    self.__out_file = out_file\n+    self.__previous_line_was_transient = False\n+    self.__width = term_width(out_file)  # Line width, or None if not a tty.\n+  def transient_line(self, msg):\n+    if self.__width is None:\n+      self.__out_file.write(msg + \"\\n\")\n+    else:\n+      self.__out_file.write(\"\\r\" + msg[:self.__width].ljust(self.__width))\n+      self.__previous_line_was_transient = True\n+  def flush_transient_output(self):\n+    if self.__previous_line_was_transient:\n+      self.__out_file.write(\"\\n\")\n+      self.__previous_line_was_transient = False\n+  def permanent_line(self, msg):\n+    self.flush_transient_output()\n+    self.__out_file.write(msg + \"\\n\")\n+\n+\n+def get_save_file_path():\n+  \"\"\"Return path to file for saving transient data.\"\"\"\n+  if sys.platform == 'win32':\n+    default_cache_path = os.path.join(os.path.expanduser('~'),\n+                                      'AppData', 'Local')\n+    cache_path = os.environ.get('LOCALAPPDATA', default_cache_path)\n+  else:\n+    # We don't use xdg module since it's not a standard.\n+    default_cache_path = os.path.join(os.path.expanduser('~'), '.cache')\n+    cache_path = os.environ.get('XDG_CACHE_HOME', default_cache_path)\n+\n+  if os.path.isdir(cache_path):\n+    return os.path.join(cache_path, 'gtest-parallel')\n+  else:\n+    sys.stderr.write('Directory {} does not exist'.format(cache_path))\n+    return os.path.join(os.path.expanduser('~'), '.gtest-parallel-times')\n+\n+\n+@total_ordering\n+class Task(object):\n+  \"\"\"Stores information about a task (single execution of a test).\n+\n+  This class stores information about the test to be executed (gtest binary and\n+  test name), and its result (log file, exit code and runtime).\n+  Each task is uniquely identified by the gtest binary, the test name and an\n+  execution number that increases each time the test is executed.\n+  Additionaly we store the last execution time, so that next time the test is\n+  executed, the slowest tests are run first.\n+  \"\"\"\n+  def __init__(self, test_binary, test_name, test_command, execution_number,\n+               last_execution_time, output_dir):\n+    self.test_name = test_name\n+    self.output_dir = output_dir\n+    self.test_binary = test_binary\n+    self.test_command = test_command\n+    self.execution_number = execution_number\n+    self.last_execution_time = last_execution_time\n+\n+    self.exit_code = None\n+    self.runtime_ms = None\n+\n+    self.test_id = (test_binary, test_name)\n+    self.task_id = (test_binary, test_name, self.execution_number)\n+\n+    self.log_file = Task._logname(self.output_dir, self.test_binary,\n+                                  test_name, self.execution_number)\n+\n+  def __sorting_key(self):\n+    # Unseen or failing tests (both missing execution time) take precedence over\n+    # execution time. Tests are greater (seen as slower) when missing times so\n+    # that they are executed first.\n+    return (1 if self.last_execution_time is None else 0,\n+            self.last_execution_time)\n+\n+  def __eq__(self, other):\n+      return self.__sorting_key() == other.__sorting_key()\n+\n+  def __ne__(self, other):\n+      return not (self == other)\n+\n+  def __lt__(self, other):\n+      return self.__sorting_key() < other.__sorting_key()\n+\n+  @staticmethod\n+  def _normalize(string):\n+    return re.sub('[^A-Za-z0-9]', '_', string)\n+\n+  @staticmethod\n+  def _logname(output_dir, test_binary, test_name, execution_number):\n+    # Store logs to temporary files if there is no output_dir.\n+    if output_dir is None:\n+      (log_handle, log_name) = tempfile.mkstemp(prefix='gtest_parallel_',\n+                                                suffix=\".log\")\n+      os.close(log_handle)\n+      return log_name\n+\n+    log_name = '%s-%s-%d.log' % (Task._normalize(os.path.basename(test_binary)),\n+                                 Task._normalize(test_name), execution_number)\n+\n+    return os.path.join(output_dir, log_name)\n+\n+  def run(self):\n+    begin = time.time()\n+    with open(self.log_file, 'w') as log:\n+      task = subprocess.Popen(self.test_command, stdout=log, stderr=log)\n+      try:\n+        self.exit_code = sigint_handler.wait(task)\n+      except sigint_handler.ProcessWasInterrupted:\n+        thread.exit()\n+    self.runtime_ms = int(1000 * (time.time() - begin))\n+    self.last_execution_time = None if self.exit_code else self.runtime_ms\n+\n+\n+class TaskManager(object):\n+  \"\"\"Executes the tasks and stores the passed, failed and interrupted tasks.\n+\n+  When a task is run, this class keeps track if it passed, failed or was\n+  interrupted. After a task finishes it calls the relevant functions of the\n+  Logger, TestResults and TestTimes classes, and in case of failure, retries the\n+  test as specified by the --retry_failed flag.\n+  \"\"\"\n+  def __init__(self, times, logger, test_results, task_factory, times_to_retry,\n+               initial_execution_number):\n+    self.times = times\n+    self.logger = logger\n+    self.test_results = test_results\n+    self.task_factory = task_factory\n+    self.times_to_retry = times_to_retry\n+    self.initial_execution_number = initial_execution_number\n+\n+    self.global_exit_code = 0\n+\n+    self.passed = []\n+    self.failed = []\n+    self.started = {}\n+    self.execution_number = {}\n+\n+    self.lock = threading.Lock()\n+\n+  def __get_next_execution_number(self, test_id):\n+    with self.lock:\n+      next_execution_number = self.execution_number.setdefault(\n+          test_id, self.initial_execution_number)\n+      self.execution_number[test_id] += 1\n+    return next_execution_number\n+\n+  def __register_start(self, task):\n+    with self.lock:\n+      self.started[task.task_id] = task\n+\n+  def __register_exit(self, task):\n+    self.logger.log_exit(task)\n+    self.times.record_test_time(task.test_binary, task.test_name,\n+                                task.last_execution_time)\n+    if self.test_results:\n+      self.test_results.log(task.test_name, task.runtime_ms,\n+                            \"PASS\" if task.exit_code == 0 else \"FAIL\")\n+\n+    with self.lock:\n+      self.started.pop(task.task_id)\n+      if task.exit_code == 0:\n+        self.passed.append(task)\n+      else:\n+        self.failed.append(task)\n+\n+  def run_task(self, task):\n+    for try_number in range(self.times_to_retry + 1):\n+      self.__register_start(task)\n+      task.run()\n+      self.__register_exit(task)\n+\n+      if task.exit_code == 0:\n+        break\n+\n+      if try_number < self.times_to_retry:\n+        execution_number = self.__get_next_execution_number(task.test_id)\n+        # We need create a new Task instance. Each task represents a single test\n+        # execution, with its own runtime, exit code and log file.\n+        task = self.task_factory(task.test_binary, task.test_name,\n+                                 task.test_command, execution_number,\n+                                 task.last_execution_time, task.output_dir)\n+\n+    with self.lock:\n+      if task.exit_code != 0:\n+        self.global_exit_code = task.exit_code\n+\n+\n+class FilterFormat(object):\n+  def __init__(self, output_dir):\n+    if sys.stdout.isatty():\n+      # stdout needs to be unbuffered since the output is interactive.\n+      sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)\n+\n+    self.output_dir = output_dir\n+\n+    self.total_tasks = 0\n+    self.finished_tasks = 0\n+    self.out = Outputter(sys.stdout)\n+    self.stdout_lock = threading.Lock()\n+\n+  def move_to(self, destination_dir, tasks):\n+    if self.output_dir is None:\n+      return\n+\n+    destination_dir = os.path.join(self.output_dir, destination_dir)\n+    os.makedirs(destination_dir)\n+    for task in tasks:\n+      shutil.move(task.log_file, destination_dir)\n+\n+  def print_tests(self, message, tasks, print_try_number):\n+    self.out.permanent_line(\"%s (%s/%s):\" %\n+                            (message, len(tasks), self.total_tasks))\n+    for task in sorted(tasks):\n+      runtime_ms = 'Interrupted'\n+      if task.runtime_ms is not None:\n+        runtime_ms = '%d ms' % task.runtime_ms\n+      self.out.permanent_line(\"%11s: %s %s%s\" % (\n+          runtime_ms, task.test_binary, task.test_name,\n+          (\" (try #%d)\" % task.execution_number) if print_try_number else \"\"))\n+\n+  def log_exit(self, task):\n+    with self.stdout_lock:\n+      self.finished_tasks += 1\n+      self.out.transient_line(\"[%d/%d] %s (%d ms)\"\n+                              % (self.finished_tasks, self.total_tasks,\n+                                 task.test_name, task.runtime_ms))\n+      if task.exit_code != 0:\n+        with open(task.log_file) as f:\n+          for line in f.readlines():\n+            self.out.permanent_line(line.rstrip())\n+        self.out.permanent_line(\n+          \"[%d/%d] %s returned/aborted with exit code %d (%d ms)\"\n+          % (self.finished_tasks, self.total_tasks, task.test_name,\n+             task.exit_code, task.runtime_ms))\n+\n+    if self.output_dir is None:\n+      # Try to remove the file 100 times (sleeping for 0.1 second in between).\n+      # This is a workaround for a process handle seemingly holding on to the\n+      # file for too long inside os.subprocess. This workaround is in place\n+      # until we figure out a minimal repro to report upstream (or a better\n+      # suspect) to prevent os.remove exceptions.\n+      num_tries = 100\n+      for i in range(num_tries):\n+        try:\n+          os.remove(task.log_file)\n+        except OSError as e:\n+          if e.errno is not errno.ENOENT:\n+            if i is num_tries - 1:\n+              self.out.permanent_line('Could not remove temporary log file: ' + str(e))\n+            else:\n+              time.sleep(0.1)\n+            continue\n+        break\n+\n+  def log_tasks(self, total_tasks):\n+    self.total_tasks += total_tasks\n+    self.out.transient_line(\"[0/%d] Running tests...\" % self.total_tasks)\n+\n+  def summarize(self, passed_tasks, failed_tasks, interrupted_tasks):\n+    stats = {}\n+    def add_stats(stats, task, idx):\n+      task_key = (task.test_binary, task.test_name)\n+      if not task_key in stats:\n+        # (passed, failed, interrupted) task_key is added as tie breaker to get\n+        # alphabetic sorting on equally-stable tests\n+        stats[task_key] = [0, 0, 0, task_key]\n+      stats[task_key][idx] += 1\n+\n+    for task in passed_tasks:\n+      add_stats(stats, task, 0)\n+    for task in failed_tasks:\n+      add_stats(stats, task, 1)\n+    for task in interrupted_tasks:\n+      add_stats(stats, task, 2)\n+\n+    self.out.permanent_line(\"SUMMARY:\")\n+    for task_key in sorted(stats, key=stats.__getitem__):\n+      (num_passed, num_failed, num_interrupted, _) = stats[task_key]\n+      (test_binary, task_name) = task_key\n+      self.out.permanent_line(\n+          \"  %s %s passed %d / %d times%s.\" %\n+              (test_binary, task_name, num_passed,\n+               num_passed + num_failed + num_interrupted,\n+               \"\" if num_interrupted == 0 else (\" (%d interrupted)\" % num_interrupted)))\n+\n+  def flush(self):\n+    self.out.flush_transient_output()\n+\n+\n+class CollectTestResults(object):\n+  def __init__(self, json_dump_filepath):\n+    self.test_results_lock = threading.Lock()\n+    self.json_dump_file = open(json_dump_filepath, 'w')\n+    self.test_results = {\n+        \"interrupted\": False,\n+        \"path_delimiter\": \".\",\n+        # Third version of the file format. See the link in the flag description\n+        # for details.\n+        \"version\": 3,\n+        \"seconds_since_epoch\": int(time.time()),\n+        \"num_failures_by_type\": {\n+            \"PASS\": 0,\n+            \"FAIL\": 0,\n+        },\n+        \"tests\": {},\n+    }\n+\n+  def log(self, test, runtime_ms, actual_result):\n+    with self.test_results_lock:\n+      self.test_results['num_failures_by_type'][actual_result] += 1\n+      results = self.test_results['tests']\n+      for name in test.split('.'):\n+        results = results.setdefault(name, {})\n+\n+      if results:\n+        results['actual'] += ' ' + actual_result\n+        results['times'].append(runtime_ms)\n+      else:  # This is the first invocation of the test\n+        results['actual'] = actual_result\n+        results['times'] = [runtime_ms]\n+        results['time'] = runtime_ms\n+        results['expected'] = 'PASS'\n+\n+  def dump_to_file_and_close(self):\n+    json.dump(self.test_results, self.json_dump_file)\n+    self.json_dump_file.close()\n+\n+\n+# Record of test runtimes. Has built-in locking.\n+class TestTimes(object):\n+  class LockedFile(object):\n+    def __init__(self, filename, mode):\n+      self._filename = filename\n+      self._mode = mode\n+      self._fo = None\n+\n+    def __enter__(self):\n+      self._fo = open(self._filename, self._mode)\n+\n+      # Regardless of opening mode we always seek to the beginning of file.\n+      # This simplifies code working with LockedFile and also ensures that\n+      # we lock (and unlock below) always the same region in file on win32.\n+      self._fo.seek(0)\n+\n+      try:\n+        if sys.platform == 'win32':\n+          # We are locking here fixed location in file to use it as\n+          # an exclusive lock on entire file.\n+          msvcrt.locking(self._fo.fileno(), msvcrt.LK_LOCK, 1)\n+        else:\n+          fcntl.flock(self._fo.fileno(), fcntl.LOCK_EX)\n+      except IOError:\n+        self._fo.close()\n+        raise\n+\n+      return self._fo\n+\n+    def __exit__(self, exc_type, exc_value, traceback):\n+      # Flush any buffered data to disk. This is needed to prevent race\n+      # condition which happens from the moment of releasing file lock\n+      # till closing the file.\n+      self._fo.flush()\n+\n+      try:\n+        if sys.platform == 'win32':\n+          self._fo.seek(0)\n+          msvcrt.locking(self._fo.fileno(), msvcrt.LK_UNLCK, 1)\n+        else:\n+          fcntl.flock(self._fo.fileno(), fcntl.LOCK_UN)\n+      finally:\n+        self._fo.close()\n+\n+      return exc_value is None\n+\n+  def __init__(self, save_file):\n+    \"Create new object seeded with saved test times from the given file.\"\n+    self.__times = {}  # (test binary, test name) -> runtime in ms\n+\n+    # Protects calls to record_test_time(); other calls are not\n+    # expected to be made concurrently.\n+    self.__lock = threading.Lock()\n+\n+    try:\n+      with TestTimes.LockedFile(save_file, 'rb') as fd:\n+        times = TestTimes.__read_test_times_file(fd)\n+    except IOError:\n+      # We couldn't obtain the lock.\n+      return\n+\n+    # Discard saved times if the format isn't right.\n+    if type(times) is not dict:\n+      return\n+    for ((test_binary, test_name), runtime) in list(times.items()):\n+      if (type(test_binary) is not str or type(test_name) is not str\n+          or type(runtime) not in {int, long, type(None)}):\n+        return\n+\n+    self.__times = times\n+\n+  def get_test_time(self, binary, testname):\n+    \"\"\"Return the last duration for the given test as an integer number of\n+    milliseconds, or None if the test failed or if there's no record for it.\"\"\"\n+    return self.__times.get((binary, testname), None)\n+\n+  def record_test_time(self, binary, testname, runtime_ms):\n+    \"\"\"Record that the given test ran in the specified number of\n+    milliseconds. If the test failed, runtime_ms should be None.\"\"\"\n+    with self.__lock:\n+      self.__times[(binary, testname)] = runtime_ms\n+\n+  def write_to_file(self, save_file):\n+    \"Write all the times to file.\"\n+    try:\n+      with TestTimes.LockedFile(save_file, 'a+b') as fd:\n+        times = TestTimes.__read_test_times_file(fd)\n+\n+        if times is None:\n+          times = self.__times\n+        else:\n+          times.update(self.__times)\n+\n+        # We erase data from file while still holding a lock to it. This\n+        # way reading old test times and appending new ones are atomic\n+        # for external viewer.\n+        fd.seek(0)\n+        fd.truncate()\n+        with gzip.GzipFile(fileobj=fd, mode='wb') as gzf:\n+          cPickle.dump(times, gzf, PICKLE_HIGHEST_PROTOCOL)\n+    except IOError:\n+      pass  # ignore errors---saving the times isn't that important\n+\n+  @staticmethod\n+  def __read_test_times_file(fd):\n+    try:\n+      with gzip.GzipFile(fileobj=fd, mode='rb') as gzf:\n+        times = cPickle.load(gzf)\n+    except Exception:\n+      # File doesn't exist, isn't readable, is malformed---whatever.\n+      # Just ignore it.\n+      return None\n+    else:\n+      return times\n+\n+\n+def find_tests(test_list, binaries, additional_args, options, times):\n+  test_count = 0\n+  tasks = []\n+  for test_binary in binaries:\n+    command = [test_binary]\n+    command += additional_args\n+\n+    for test_name in test_list:\n+      last_execution_time = times.get_test_time(test_binary, test_name)\n+      if options.failed and last_execution_time is not None:\n+        continue\n+\n+      test_command = command + ['--run_test=' + test_name]\n+      if (test_count - options.shard_index) % options.shard_count == 0:\n+        for execution_number in range(options.repeat):\n+          tasks.append(Task(test_binary, test_name, test_command,\n+                            execution_number + 1, last_execution_time,\n+                            options.output_dir))\n+\n+      test_count += 1\n+\n+  # Sort the tasks to run the slowest tests first, so that faster ones can be\n+  # finished in parallel.\n+  return sorted(tasks, reverse=True)\n+\n+\n+def execute_tasks(tasks, pool_size, task_manager,\n+                  timeout, serialize_test_cases):\n+  class WorkerFn(object):\n+    def __init__(self, tasks, running_groups):\n+      self.tasks = tasks\n+      self.running_groups = running_groups\n+      self.task_lock = threading.Lock()\n+\n+    def __call__(self):\n+      while True:\n+        with self.task_lock:\n+          for task_id in range(len(self.tasks)):\n+            task = self.tasks[task_id]\n+\n+            if self.running_groups is not None:\n+              test_group = task.test_name.split('.')[0]\n+              if test_group in self.running_groups:\n+                # Try to find other non-running test group.\n+                continue\n+              else:\n+                self.running_groups.add(test_group)\n+\n+            del self.tasks[task_id]\n+            break\n+          else:\n+            # Either there is no tasks left or number or remaining test\n+            # cases (groups) is less than number or running threads.\n+            return\n+\n+        task_manager.run_task(task)\n+\n+        if self.running_groups is not None:\n+          with self.task_lock:\n+            self.running_groups.remove(test_group)\n+\n+  def start_daemon(func):\n+    t = threading.Thread(target=func)\n+    t.daemon = True\n+    t.start()\n+    return t\n+\n+  try:\n+    if timeout:\n+      timeout.start()\n+    running_groups = set() if serialize_test_cases else None\n+    worker_fn = WorkerFn(tasks, running_groups)\n+    workers = [start_daemon(worker_fn) for _ in range(pool_size)]\n+    for worker in workers:\n+      worker.join()\n+  finally:\n+    if timeout:\n+      timeout.cancel()\n+\n+\n+def default_options_parser(default_binary, file_test_list):\n+  parser = optparse.OptionParser(\n+      usage = 'usage: %prog [options] binary [binary ...] -- [additional args]')\n+\n+  parser.add_option('-d', '--output_dir', type='string', default=None,\n+                    help='Output directory for test logs. Logs will be '\n+                         'available under gtest-parallel-logs/, so '\n+                         '--output_dir=/tmp will results in all logs being '\n+                         'available under /tmp/gtest-parallel-logs/.')\n+  parser.add_option('-r', '--repeat', type='int', default=1,\n+                    help='Number of times to execute all the tests.')\n+  parser.add_option('--retry_failed', type='int', default=0,\n+                    help='Number of times to repeat failed tests.')\n+  parser.add_option('--failed', action='store_true', default=False,\n+                    help='run only failed and new tests')\n+  parser.add_option('-w', '--workers', type='int',\n+                    default=multiprocessing.cpu_count(),\n+                    help='number of workers to spawn')\n+  parser.add_option('--gtest_color', type='string', default='yes',\n+                    help='color output')\n+  parser.add_option('--gtest_filter', type='string', default='',\n+                    help='test filter')\n+  parser.add_option('--gtest_also_run_disabled_tests', action='store_true',\n+                    default=False, help='run disabled tests too')\n+  parser.add_option('--print_test_times', action='store_true', default=False,\n+                    help='list the run time of each test at the end of execution')\n+  parser.add_option('--shard_count', type='int', default=1,\n+                    help='total number of shards (for sharding test execution '\n+                         'between multiple machines)')\n+  parser.add_option('--shard_index', type='int', default=0,\n+                    help='zero-indexed number identifying this shard (for '\n+                         'sharding test execution between multiple machines)')\n+  parser.add_option('--dump_json_test_results', type='string', default=None,\n+                    help='Saves the results of the tests as a JSON machine-'\n+                         'readable file. The format of the file is specified at '\n+                         'https://www.chromium.org/developers/the-json-test-results-format')\n+  parser.add_option('--timeout', type='int', default=None,\n+                    help='Interrupt all remaining processes after the given '\n+                         'time (in seconds).')\n+  parser.add_option('--serialize_test_cases', action='store_true',",
      "path": "src/test/parallel.py",
      "position": 682,
      "original_position": 682,
      "commit_id": "7785663d6f9960ffd38bec6c40fad7efbd8141fd",
      "original_commit_id": "4292954ebeac41092d3218fdc665bd267530513b",
      "in_reply_to_id": null,
      "user": {
        "login": "conscott",
        "id": 14220652,
        "node_id": "MDQ6VXNlcjE0MjIwNjUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/14220652?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/conscott",
        "html_url": "https://github.com/conscott",
        "followers_url": "https://api.github.com/users/conscott/followers",
        "following_url": "https://api.github.com/users/conscott/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/conscott/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/conscott/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/conscott/subscriptions",
        "organizations_url": "https://api.github.com/users/conscott/orgs",
        "repos_url": "https://api.github.com/users/conscott/repos",
        "events_url": "https://api.github.com/users/conscott/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/conscott/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "I think this option is currently incompatible with sharding, since it shards tests in a round-robin type fashion, thus splitting up test_groups between shards. This is probably desired, but just need to document it, or try to prevent the two options being used in combination.",
      "created_at": "2018-03-30T06:19:11Z",
      "updated_at": "2018-04-10T16:06:27Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/12831#discussion_r178238820",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/178238820"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/12831"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 682,
      "original_line": 682,
      "side": "RIGHT"
    }
  ]
}