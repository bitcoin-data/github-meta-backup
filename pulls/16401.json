{
  "type": "pull",
  "pull": {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401",
    "id": 298194662,
    "node_id": "MDExOlB1bGxSZXF1ZXN0Mjk4MTk0NjYy",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/16401",
    "diff_url": "https://github.com/bitcoin/bitcoin/pull/16401.diff",
    "patch_url": "https://github.com/bitcoin/bitcoin/pull/16401.patch",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/16401",
    "commits_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401/commits",
    "review_comments_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401/comments",
    "review_comment_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments%7B/number%7D",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/16401/comments",
    "statuses_url": "https://api.github.com/repos/bitcoin/bitcoin/statuses/6a3bdba0746efe9a38f560bb116a8425e0410cb7",
    "number": 16401,
    "state": "closed",
    "locked": true,
    "maintainer_can_modify": false,
    "title": "Add package acceptance logic to mempool",
    "user": {
      "login": "sdaftuar",
      "id": 7463573,
      "node_id": "MDQ6VXNlcjc0NjM1NzM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sdaftuar",
      "html_url": "https://github.com/sdaftuar",
      "followers_url": "https://api.github.com/users/sdaftuar/followers",
      "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
      "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
      "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
      "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
      "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
      "repos_url": "https://api.github.com/users/sdaftuar/repos",
      "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
      "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "Accepting a single transaction to the mempool only succeeds if (among other things) the feerate of the transaction is greater than both the min relay fee and the mempool min fee. Consequently, a transaction below the minimum fee may not be accepted to the mempool, even if we later learn of a transaction with a high fee that depends on it.\r\n\r\nThis PR adds code to validation that will accept a package of transactions to the mempool under the following conditions:\r\n\r\n- All package transactions must be direct parents of the final transaction.\r\n  This is a simple heuristic for ensuring that a candidate list of transactions\r\n  is in fact a package (we wouldn't want arbitrary transactions to be paying\r\n  for random low feerate transactions)\r\n\r\n- The feerate of the package, as a whole, exceeds the mempool min fee and the\r\n  min relay fee.\r\n\r\n- No transactions in the mempool conflict with any transactions in the package.\r\n  This is a simplification that makes the logic easier to write. Without this\r\n  requirement, we would need to do additional checks to ensure that no parent\r\n  transaction would evict a transaction from the mempool that some other child\r\n  depends on.\r\n\r\n- The ancestor/descendant size limits are calculated assuming that any mempool\r\n  ancestor of any candidate transaction is an ancestor of all the candidate\r\n  transactions.\r\n  This allows for doing simpler calculations to ensure that we're staying\r\n  within the mempool's package limits. If we eliminated this, we would need to\r\n  do much more careful package calculations for each candidate transaction and each\r\n  in-mempool ancestor.\r\n\r\nThis PR also adds code to net_processing that will attempt to process transaction packages in one narrow case: if a transaction fails to get into the mempool due to insufficient fee, but has an orphan in the orphan pool, then we will try to process the pair together to see if they can be accepted as a package.\r\n\r\nThis PR is definitely WIP, but I'm opening it as a proof-of-concept motivation for refactoring ATMP (#16400).",
    "labels": [
      {
        "id": 62963516,
        "node_id": "MDU6TGFiZWw2Mjk2MzUxNg==",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/labels/Tests",
        "name": "Tests",
        "color": "d4c5f9",
        "default": false
      },
      {
        "id": 98298007,
        "node_id": "MDU6TGFiZWw5ODI5ODAwNw==",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/labels/P2P",
        "name": "P2P",
        "color": "006b75",
        "default": false
      },
      {
        "id": 118379652,
        "node_id": "MDU6TGFiZWwxMTgzNzk2NTI=",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/labels/Validation",
        "name": "Validation",
        "color": "6060aa",
        "default": false
      },
      {
        "id": 164208572,
        "node_id": "MDU6TGFiZWwxNjQyMDg1NzI=",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/labels/Mempool",
        "name": "Mempool",
        "color": "fef2c0",
        "default": false
      }
    ],
    "active_lock_reason": "resolved",
    "created_at": "2019-07-16T20:16:12Z",
    "updated_at": "2022-02-15T10:26:39Z",
    "closed_at": "2020-01-29T14:55:24Z",
    "mergeable_state": "unknown",
    "merge_commit_sha": "31312f8e8b7d3af80bc3eb20a9bd3e018ea09224",
    "assignees": [],
    "requested_reviewers": [],
    "requested_teams": [],
    "head": {
      "label": "sdaftuar:2019-07-package-relay",
      "ref": "2019-07-package-relay",
      "sha": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "user": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "repo": {
        "id": 28761781,
        "node_id": "MDEwOlJlcG9zaXRvcnkyODc2MTc4MQ==",
        "name": "bitcoin",
        "full_name": "sdaftuar/bitcoin",
        "owner": {
          "login": "sdaftuar",
          "id": 7463573,
          "node_id": "MDQ6VXNlcjc0NjM1NzM=",
          "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/sdaftuar",
          "html_url": "https://github.com/sdaftuar",
          "followers_url": "https://api.github.com/users/sdaftuar/followers",
          "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
          "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
          "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
          "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
          "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
          "repos_url": "https://api.github.com/users/sdaftuar/repos",
          "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
          "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
          "type": "User",
          "site_admin": false
        },
        "private": false,
        "html_url": "https://github.com/sdaftuar/bitcoin",
        "description": "Bitcoin Core integration/staging tree",
        "fork": true,
        "url": "https://api.github.com/repos/sdaftuar/bitcoin",
        "archive_url": "https://api.github.com/repos/sdaftuar/bitcoin/%7Barchive_format%7D%7B/ref%7D",
        "assignees_url": "https://api.github.com/repos/sdaftuar/bitcoin/assignees%7B/user%7D",
        "blobs_url": "https://api.github.com/repos/sdaftuar/bitcoin/git/blobs%7B/sha%7D",
        "branches_url": "https://api.github.com/repos/sdaftuar/bitcoin/branches%7B/branch%7D",
        "collaborators_url": "https://api.github.com/repos/sdaftuar/bitcoin/collaborators%7B/collaborator%7D",
        "comments_url": "https://api.github.com/repos/sdaftuar/bitcoin/comments%7B/number%7D",
        "commits_url": "https://api.github.com/repos/sdaftuar/bitcoin/commits%7B/sha%7D",
        "compare_url": "https://api.github.com/repos/sdaftuar/bitcoin/compare/%7Bbase%7D...%7Bhead%7D",
        "contents_url": "https://api.github.com/repos/sdaftuar/bitcoin/contents/%7B+path%7D",
        "contributors_url": "https://api.github.com/repos/sdaftuar/bitcoin/contributors",
        "deployments_url": "https://api.github.com/repos/sdaftuar/bitcoin/deployments",
        "downloads_url": "https://api.github.com/repos/sdaftuar/bitcoin/downloads",
        "events_url": "https://api.github.com/repos/sdaftuar/bitcoin/events",
        "forks_url": "https://api.github.com/repos/sdaftuar/bitcoin/forks",
        "git_commits_url": "https://api.github.com/repos/sdaftuar/bitcoin/git/commits%7B/sha%7D",
        "git_refs_url": "https://api.github.com/repos/sdaftuar/bitcoin/git/refs%7B/sha%7D",
        "git_tags_url": "https://api.github.com/repos/sdaftuar/bitcoin/git/tags%7B/sha%7D",
        "git_url": "git://github.com/sdaftuar/bitcoin.git",
        "issue_comment_url": "https://api.github.com/repos/sdaftuar/bitcoin/issues/comments%7B/number%7D",
        "issue_events_url": "https://api.github.com/repos/sdaftuar/bitcoin/issues/events%7B/number%7D",
        "issues_url": "https://api.github.com/repos/sdaftuar/bitcoin/issues%7B/number%7D",
        "keys_url": "https://api.github.com/repos/sdaftuar/bitcoin/keys%7B/key_id%7D",
        "labels_url": "https://api.github.com/repos/sdaftuar/bitcoin/labels%7B/name%7D",
        "languages_url": "https://api.github.com/repos/sdaftuar/bitcoin/languages",
        "merges_url": "https://api.github.com/repos/sdaftuar/bitcoin/merges",
        "milestones_url": "https://api.github.com/repos/sdaftuar/bitcoin/milestones%7B/number%7D",
        "notifications_url": "https://api.github.com/repos/sdaftuar/bitcoin/notifications%7B?since,all,participating}",
        "pulls_url": "https://api.github.com/repos/sdaftuar/bitcoin/pulls%7B/number%7D",
        "releases_url": "https://api.github.com/repos/sdaftuar/bitcoin/releases%7B/id%7D",
        "ssh_url": "git@github.com:sdaftuar/bitcoin.git",
        "stargazers_url": "https://api.github.com/repos/sdaftuar/bitcoin/stargazers",
        "statuses_url": "https://api.github.com/repos/sdaftuar/bitcoin/statuses/%7Bsha%7D",
        "subscribers_url": "https://api.github.com/repos/sdaftuar/bitcoin/subscribers",
        "subscription_url": "https://api.github.com/repos/sdaftuar/bitcoin/subscription",
        "tags_url": "https://api.github.com/repos/sdaftuar/bitcoin/tags",
        "teams_url": "https://api.github.com/repos/sdaftuar/bitcoin/teams",
        "trees_url": "https://api.github.com/repos/sdaftuar/bitcoin/git/trees%7B/sha%7D",
        "clone_url": "https://github.com/sdaftuar/bitcoin.git",
        "hooks_url": "https://api.github.com/repos/sdaftuar/bitcoin/hooks",
        "svn_url": "https://github.com/sdaftuar/bitcoin",
        "homepage": "https://bitcoin.org/en/download",
        "language": "C++",
        "forks_count": 1,
        "stargazers_count": 3,
        "watchers_count": 3,
        "size": 245665,
        "default_branch": "master",
        "open_issues_count": 1,
        "is_template": false,
        "topics": [],
        "has_issues": false,
        "has_projects": true,
        "has_wiki": false,
        "has_pages": false,
        "has_downloads": false,
        "archived": false,
        "disabled": false,
        "visibility": "public",
        "pushed_at": "2023-06-06T22:41:53Z",
        "created_at": "2015-01-04T02:52:13Z",
        "updated_at": "2023-02-11T10:16:01Z",
        "license": {
          "key": "mit",
          "name": "MIT License",
          "node_id": "MDc6TGljZW5zZTEz",
          "spdx_id": "MIT",
          "url": "https://api.github.com/licenses/mit",
          "html_url": null,
          "description": null,
          "implementation": null,
          "permissions": null,
          "conditions": null,
          "limitations": null,
          "body": null,
          "featured": null
        }
      }
    },
    "base": {
      "label": "bitcoin:master",
      "ref": "master",
      "sha": "6196e930018181301b5972842ae384ea4288ff34",
      "user": {
        "login": "bitcoin",
        "id": 528860,
        "node_id": "MDEyOk9yZ2FuaXphdGlvbjUyODg2MA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/528860?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/bitcoin",
        "html_url": "https://github.com/bitcoin",
        "followers_url": "https://api.github.com/users/bitcoin/followers",
        "following_url": "https://api.github.com/users/bitcoin/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/bitcoin/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/bitcoin/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/bitcoin/subscriptions",
        "organizations_url": "https://api.github.com/users/bitcoin/orgs",
        "repos_url": "https://api.github.com/users/bitcoin/repos",
        "events_url": "https://api.github.com/users/bitcoin/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/bitcoin/received_events",
        "type": "Organization",
        "site_admin": false
      },
      "repo": {
        "id": 1181927,
        "node_id": "MDEwOlJlcG9zaXRvcnkxMTgxOTI3",
        "name": "bitcoin",
        "full_name": "bitcoin/bitcoin",
        "owner": {
          "login": "bitcoin",
          "id": 528860,
          "node_id": "MDEyOk9yZ2FuaXphdGlvbjUyODg2MA==",
          "avatar_url": "https://avatars.githubusercontent.com/u/528860?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/bitcoin",
          "html_url": "https://github.com/bitcoin",
          "followers_url": "https://api.github.com/users/bitcoin/followers",
          "following_url": "https://api.github.com/users/bitcoin/following%7B/other_user%7D",
          "gists_url": "https://api.github.com/users/bitcoin/gists%7B/gist_id%7D",
          "starred_url": "https://api.github.com/users/bitcoin/starred%7B/owner%7D%7B/repo%7D",
          "subscriptions_url": "https://api.github.com/users/bitcoin/subscriptions",
          "organizations_url": "https://api.github.com/users/bitcoin/orgs",
          "repos_url": "https://api.github.com/users/bitcoin/repos",
          "events_url": "https://api.github.com/users/bitcoin/events%7B/privacy%7D",
          "received_events_url": "https://api.github.com/users/bitcoin/received_events",
          "type": "Organization",
          "site_admin": false
        },
        "private": false,
        "html_url": "https://github.com/bitcoin/bitcoin",
        "description": "Bitcoin Core integration/staging tree",
        "fork": false,
        "url": "https://api.github.com/repos/bitcoin/bitcoin",
        "archive_url": "https://api.github.com/repos/bitcoin/bitcoin/%7Barchive_format%7D%7B/ref%7D",
        "assignees_url": "https://api.github.com/repos/bitcoin/bitcoin/assignees%7B/user%7D",
        "blobs_url": "https://api.github.com/repos/bitcoin/bitcoin/git/blobs%7B/sha%7D",
        "branches_url": "https://api.github.com/repos/bitcoin/bitcoin/branches%7B/branch%7D",
        "collaborators_url": "https://api.github.com/repos/bitcoin/bitcoin/collaborators%7B/collaborator%7D",
        "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/comments%7B/number%7D",
        "commits_url": "https://api.github.com/repos/bitcoin/bitcoin/commits%7B/sha%7D",
        "compare_url": "https://api.github.com/repos/bitcoin/bitcoin/compare/%7Bbase%7D...%7Bhead%7D",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/%7B+path%7D",
        "contributors_url": "https://api.github.com/repos/bitcoin/bitcoin/contributors",
        "deployments_url": "https://api.github.com/repos/bitcoin/bitcoin/deployments",
        "downloads_url": "https://api.github.com/repos/bitcoin/bitcoin/downloads",
        "events_url": "https://api.github.com/repos/bitcoin/bitcoin/events",
        "forks_url": "https://api.github.com/repos/bitcoin/bitcoin/forks",
        "git_commits_url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits%7B/sha%7D",
        "git_refs_url": "https://api.github.com/repos/bitcoin/bitcoin/git/refs%7B/sha%7D",
        "git_tags_url": "https://api.github.com/repos/bitcoin/bitcoin/git/tags%7B/sha%7D",
        "git_url": "git://github.com/bitcoin/bitcoin.git",
        "issue_comment_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments%7B/number%7D",
        "issue_events_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events%7B/number%7D",
        "issues_url": "https://api.github.com/repos/bitcoin/bitcoin/issues%7B/number%7D",
        "keys_url": "https://api.github.com/repos/bitcoin/bitcoin/keys%7B/key_id%7D",
        "labels_url": "https://api.github.com/repos/bitcoin/bitcoin/labels%7B/name%7D",
        "languages_url": "https://api.github.com/repos/bitcoin/bitcoin/languages",
        "merges_url": "https://api.github.com/repos/bitcoin/bitcoin/merges",
        "milestones_url": "https://api.github.com/repos/bitcoin/bitcoin/milestones%7B/number%7D",
        "notifications_url": "https://api.github.com/repos/bitcoin/bitcoin/notifications%7B?since,all,participating}",
        "pulls_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls%7B/number%7D",
        "releases_url": "https://api.github.com/repos/bitcoin/bitcoin/releases%7B/id%7D",
        "ssh_url": "git@github.com:bitcoin/bitcoin.git",
        "stargazers_url": "https://api.github.com/repos/bitcoin/bitcoin/stargazers",
        "statuses_url": "https://api.github.com/repos/bitcoin/bitcoin/statuses/%7Bsha%7D",
        "subscribers_url": "https://api.github.com/repos/bitcoin/bitcoin/subscribers",
        "subscription_url": "https://api.github.com/repos/bitcoin/bitcoin/subscription",
        "tags_url": "https://api.github.com/repos/bitcoin/bitcoin/tags",
        "teams_url": "https://api.github.com/repos/bitcoin/bitcoin/teams",
        "trees_url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees%7B/sha%7D",
        "clone_url": "https://github.com/bitcoin/bitcoin.git",
        "hooks_url": "https://api.github.com/repos/bitcoin/bitcoin/hooks",
        "svn_url": "https://github.com/bitcoin/bitcoin",
        "homepage": "https://bitcoincore.org/en/download",
        "language": "C++",
        "forks_count": 34324,
        "stargazers_count": 69817,
        "watchers_count": 69817,
        "size": 233879,
        "default_branch": "master",
        "open_issues_count": 627,
        "is_template": false,
        "topics": [
          "bitcoin",
          "c-plus-plus",
          "cryptocurrency",
          "cryptography",
          "p2p"
        ],
        "has_issues": true,
        "has_projects": true,
        "has_wiki": false,
        "has_pages": false,
        "has_downloads": false,
        "archived": false,
        "disabled": false,
        "visibility": "public",
        "pushed_at": "2023-06-06T22:42:00Z",
        "created_at": "2010-12-19T15:16:43Z",
        "updated_at": "2023-06-07T01:13:41Z",
        "license": {
          "key": "mit",
          "name": "MIT License",
          "node_id": "MDc6TGljZW5zZTEz",
          "spdx_id": "MIT",
          "url": "https://api.github.com/licenses/mit",
          "html_url": null,
          "description": null,
          "implementation": null,
          "permissions": null,
          "conditions": null,
          "limitations": null,
          "body": null,
          "featured": null
        }
      }
    },
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
      }
    },
    "author_association": "MEMBER",
    "draft": false,
    "additions": 296,
    "deletions": 51,
    "changed_files": 6,
    "commits": 2,
    "review_comments": 29,
    "comments": 7
  },
  "events": [
    {
      "event": "commented",
      "id": 512027094,
      "node_id": "MDEyOklzc3VlQ29tbWVudDUxMjAyNzA5NA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/512027094",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2019-07-16T22:33:17Z",
      "updated_at": "2020-01-23T02:35:04Z",
      "author_association": "MEMBER",
      "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#17985](https://drahtbot.github.io/bitcoin_core_issue_redirect/r/17985.html) (net: Remove forcerelay of rejected txs by MarcoFalke)\n* [#17399](https://drahtbot.github.io/bitcoin_core_issue_redirect/r/17399.html) (validation: Templatize ValidationState instead of subclassing by jkczyz)\n* [#15606](https://drahtbot.github.io/bitcoin_core_issue_redirect/r/15606.html) ([experimental] UTXO snapshots by jamesob)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#issuecomment-512027094",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/16401"
    },
    {
      "event": "labeled",
      "id": 2488949882,
      "node_id": "MDEyOkxhYmVsZWRFdmVudDI0ODg5NDk4ODI=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2488949882",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2019-07-17T10:27:54Z",
      "label": {
        "name": "Mempool",
        "color": "fef2c0"
      }
    },
    {
      "event": "labeled",
      "id": 2488949885,
      "node_id": "MDEyOkxhYmVsZWRFdmVudDI0ODg5NDk4ODU=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2488949885",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2019-07-17T10:27:54Z",
      "label": {
        "name": "P2P",
        "color": "006b75"
      }
    },
    {
      "event": "labeled",
      "id": 2488949889,
      "node_id": "MDEyOkxhYmVsZWRFdmVudDI0ODg5NDk4ODk=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2488949889",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2019-07-17T10:27:54Z",
      "label": {
        "name": "Tests",
        "color": "d4c5f9"
      }
    },
    {
      "event": "labeled",
      "id": 2488949891,
      "node_id": "MDEyOkxhYmVsZWRFdmVudDI0ODg5NDk4OTE=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2488949891",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2019-07-17T10:27:54Z",
      "label": {
        "name": "Validation",
        "color": "6060aa"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 2507249819,
      "node_id": "MDIzOkhlYWRSZWZGb3JjZVB1c2hlZEV2ZW50MjUwNzI0OTgxOQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2507249819",
      "actor": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2019-07-24T18:31:59Z"
    },
    {
      "event": "reviewed",
      "id": 266360368,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MjY2MzYwMzY4",
      "url": null,
      "actor": null,
      "commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "I think this works as a proof of concept.",
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#pullrequestreview-266360368",
      "submitted_at": "2019-07-25T03:33:31Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 2523415661,
      "node_id": "MDIzOkhlYWRSZWZGb3JjZVB1c2hlZEV2ZW50MjUyMzQxNTY2MQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2523415661",
      "actor": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2019-07-31T14:27:50Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 2647206138,
      "node_id": "MDIzOkhlYWRSZWZGb3JjZVB1c2hlZEV2ZW50MjY0NzIwNjEzOA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2647206138",
      "actor": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2019-09-19T14:28:29Z"
    },
    {
      "event": "reviewed",
      "id": 294815427,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mjk0ODE1NDI3",
      "url": null,
      "actor": null,
      "commit_id": "cd8f11aaaa7dd27f95af3d4cb85ff7c7607e76f9",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "NicolasDorier",
        "id": 3020646,
        "node_id": "MDQ6VXNlcjMwMjA2NDY=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3020646?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/NicolasDorier",
        "html_url": "https://github.com/NicolasDorier",
        "followers_url": "https://api.github.com/users/NicolasDorier/followers",
        "following_url": "https://api.github.com/users/NicolasDorier/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/NicolasDorier/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/NicolasDorier/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/NicolasDorier/subscriptions",
        "organizations_url": "https://api.github.com/users/NicolasDorier/orgs",
        "repos_url": "https://api.github.com/users/NicolasDorier/repos",
        "events_url": "https://api.github.com/users/NicolasDorier/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/NicolasDorier/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#pullrequestreview-294815427",
      "submitted_at": "2019-09-30T08:21:37Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
    },
    {
      "event": "reviewed",
      "id": 295669946,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mjk1NjY5OTQ2",
      "url": null,
      "actor": null,
      "commit_id": "92cc72905ab15f4474b055da95f5a45b7e8b90c8",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "etscrivner",
        "id": 69561,
        "node_id": "MDQ6VXNlcjY5NTYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/69561?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/etscrivner",
        "html_url": "https://github.com/etscrivner",
        "followers_url": "https://api.github.com/users/etscrivner/followers",
        "following_url": "https://api.github.com/users/etscrivner/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/etscrivner/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/etscrivner/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/etscrivner/subscriptions",
        "organizations_url": "https://api.github.com/users/etscrivner/orgs",
        "repos_url": "https://api.github.com/users/etscrivner/repos",
        "events_url": "https://api.github.com/users/etscrivner/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/etscrivner/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#pullrequestreview-295669946",
      "submitted_at": "2019-10-01T14:57:06Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
    },
    {
      "event": "reviewed",
      "id": 296243224,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mjk2MjQzMjI0",
      "url": null,
      "actor": null,
      "commit_id": "cd8f11aaaa7dd27f95af3d4cb85ff7c7607e76f9",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "pinheadmz",
        "id": 2084648,
        "node_id": "MDQ6VXNlcjIwODQ2NDg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2084648?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/pinheadmz",
        "html_url": "https://github.com/pinheadmz",
        "followers_url": "https://api.github.com/users/pinheadmz/followers",
        "following_url": "https://api.github.com/users/pinheadmz/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/pinheadmz/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/pinheadmz/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/pinheadmz/subscriptions",
        "organizations_url": "https://api.github.com/users/pinheadmz/orgs",
        "repos_url": "https://api.github.com/users/pinheadmz/repos",
        "events_url": "https://api.github.com/users/pinheadmz/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/pinheadmz/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#pullrequestreview-296243224",
      "submitted_at": "2019-10-02T13:37:22Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
    },
    {
      "event": "commented",
      "id": 537522080,
      "node_id": "MDEyOklzc3VlQ29tbWVudDUzNzUyMjA4MA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/537522080",
      "actor": {
        "login": "etscrivner",
        "id": 69561,
        "node_id": "MDQ6VXNlcjY5NTYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/69561?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/etscrivner",
        "html_url": "https://github.com/etscrivner",
        "followers_url": "https://api.github.com/users/etscrivner/followers",
        "following_url": "https://api.github.com/users/etscrivner/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/etscrivner/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/etscrivner/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/etscrivner/subscriptions",
        "organizations_url": "https://api.github.com/users/etscrivner/orgs",
        "repos_url": "https://api.github.com/users/etscrivner/repos",
        "events_url": "https://api.github.com/users/etscrivner/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/etscrivner/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2019-10-02T14:34:27Z",
      "updated_at": "2019-10-02T14:34:27Z",
      "author_association": "CONTRIBUTOR",
      "body": "Agree with others that I think this works as a proof-of-concept. In my opinion, this still needs more work on tests, more extensive testing, and generalization beyond 2 transaction packages (up to some maximum package size).",
      "user": {
        "login": "etscrivner",
        "id": 69561,
        "node_id": "MDQ6VXNlcjY5NTYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/69561?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/etscrivner",
        "html_url": "https://github.com/etscrivner",
        "followers_url": "https://api.github.com/users/etscrivner/followers",
        "following_url": "https://api.github.com/users/etscrivner/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/etscrivner/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/etscrivner/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/etscrivner/subscriptions",
        "organizations_url": "https://api.github.com/users/etscrivner/orgs",
        "repos_url": "https://api.github.com/users/etscrivner/repos",
        "events_url": "https://api.github.com/users/etscrivner/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/etscrivner/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#issuecomment-537522080",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/16401"
    },
    {
      "event": "reviewed",
      "id": 296364219,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mjk2MzY0MjE5",
      "url": null,
      "actor": null,
      "commit_id": "cd8f11aaaa7dd27f95af3d4cb85ff7c7607e76f9",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "This works for me as a proof of concept. Obviously the tests still need some work but thanks for the extensive commenting in the code.",
      "user": {
        "login": "fjahr",
        "id": 1322187,
        "node_id": "MDQ6VXNlcjEzMjIxODc=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1322187?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fjahr",
        "html_url": "https://github.com/fjahr",
        "followers_url": "https://api.github.com/users/fjahr/followers",
        "following_url": "https://api.github.com/users/fjahr/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fjahr/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fjahr/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fjahr/subscriptions",
        "organizations_url": "https://api.github.com/users/fjahr/orgs",
        "repos_url": "https://api.github.com/users/fjahr/repos",
        "events_url": "https://api.github.com/users/fjahr/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fjahr/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#pullrequestreview-296364219",
      "submitted_at": "2019-10-02T16:33:54Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
    },
    {
      "event": "reviewed",
      "id": 296369581,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mjk2MzY5NTgx",
      "url": null,
      "actor": null,
      "commit_id": "cd8f11aaaa7dd27f95af3d4cb85ff7c7607e76f9",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "Concept/approach ACK cd8f11aaaa7dd27f95af3d4cb85ff7c7607e76f9, tests pass here as well as rebased on master, node running since a few hours with net logging. The code documentation is helpful. Am still reviewing the code, logic, and test, particularly the checks to satisfy and the complexity introduced in `AcceptMultipleTransactions()`.\r\n\r\nSuggestion to reviewers: It may be helpful to review merged PR #16400 and [issue #14895](https://github.com/bitcoin/bitcoin/issues/14895) before this one.\r\n\r\nGiven that this PR is labelled `Draft` and the ATMP refactoring in #16400 has been merged, what are your plans going forward beyond concept/approach ACKs? For example, continue refactoring the p2p protocol for package relay computational efficiency/simplicity/multiparents, or moving forward with a standalone PoC implementation like this one?",
      "user": {
        "login": "jonatack",
        "id": 2415484,
        "node_id": "MDQ6VXNlcjI0MTU0ODQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2415484?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jonatack",
        "html_url": "https://github.com/jonatack",
        "followers_url": "https://api.github.com/users/jonatack/followers",
        "following_url": "https://api.github.com/users/jonatack/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/jonatack/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/jonatack/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/jonatack/subscriptions",
        "organizations_url": "https://api.github.com/users/jonatack/orgs",
        "repos_url": "https://api.github.com/users/jonatack/repos",
        "events_url": "https://api.github.com/users/jonatack/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/jonatack/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#pullrequestreview-296369581",
      "submitted_at": "2019-10-02T16:42:48Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
    },
    {
      "event": "reviewed",
      "id": 296401552,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mjk2NDAxNTUy",
      "url": null,
      "actor": null,
      "commit_id": "cd8f11aaaa7dd27f95af3d4cb85ff7c7607e76f9",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "pinheadmz",
        "id": 2084648,
        "node_id": "MDQ6VXNlcjIwODQ2NDg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2084648?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/pinheadmz",
        "html_url": "https://github.com/pinheadmz",
        "followers_url": "https://api.github.com/users/pinheadmz/followers",
        "following_url": "https://api.github.com/users/pinheadmz/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/pinheadmz/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/pinheadmz/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/pinheadmz/subscriptions",
        "organizations_url": "https://api.github.com/users/pinheadmz/orgs",
        "repos_url": "https://api.github.com/users/pinheadmz/repos",
        "events_url": "https://api.github.com/users/pinheadmz/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/pinheadmz/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#pullrequestreview-296401552",
      "submitted_at": "2019-10-02T17:26:42Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
    },
    {
      "event": "commented",
      "id": 537608600,
      "node_id": "MDEyOklzc3VlQ29tbWVudDUzNzYwODYwMA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/537608600",
      "actor": {
        "login": "etscrivner",
        "id": 69561,
        "node_id": "MDQ6VXNlcjY5NTYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/69561?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/etscrivner",
        "html_url": "https://github.com/etscrivner",
        "followers_url": "https://api.github.com/users/etscrivner/followers",
        "following_url": "https://api.github.com/users/etscrivner/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/etscrivner/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/etscrivner/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/etscrivner/subscriptions",
        "organizations_url": "https://api.github.com/users/etscrivner/orgs",
        "repos_url": "https://api.github.com/users/etscrivner/repos",
        "events_url": "https://api.github.com/users/etscrivner/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/etscrivner/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2019-10-02T17:55:46Z",
      "updated_at": "2019-10-02T17:55:46Z",
      "author_association": "CONTRIBUTOR",
      "body": "Add some additional tests in this gist and have also addressed the TODO item: https://gist.github.com/etscrivner/19d5f942a973940aaaeb397bc5e0e0d9",
      "user": {
        "login": "etscrivner",
        "id": 69561,
        "node_id": "MDQ6VXNlcjY5NTYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/69561?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/etscrivner",
        "html_url": "https://github.com/etscrivner",
        "followers_url": "https://api.github.com/users/etscrivner/followers",
        "following_url": "https://api.github.com/users/etscrivner/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/etscrivner/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/etscrivner/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/etscrivner/subscriptions",
        "organizations_url": "https://api.github.com/users/etscrivner/orgs",
        "repos_url": "https://api.github.com/users/etscrivner/repos",
        "events_url": "https://api.github.com/users/etscrivner/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/etscrivner/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#issuecomment-537608600",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/16401"
    },
    {
      "event": "reviewed",
      "id": 310223329,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzEwMjIzMzI5",
      "url": null,
      "actor": null,
      "commit_id": "92cc72905ab15f4474b055da95f5a45b7e8b90c8",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "Reviewed only mempool/validation change for now.\r\n\r\n> No transactions in the mempool conflict with any transactions in the package.\r\nThis is a simplification that makes the logic easier to write. Without this\r\nrequirement, we would need to do additional checks to ensure that no parent\r\ntransaction would evict a transaction from the mempool that some other child\r\ndepends on.\r\n\r\nI assume we can still RBF both parents or CPFP child in case our package txn are still stucking in the mempool? It shouldn't be an issue as after acceptance txn are normal mempool txn, assuming we don't have package garbage value for ancestors/descendants.\r\n\r\n> The ancestor/descendant size limits are calculated assuming that any mempool\r\nancestor of any candidate transaction is an ancestor of all the candidate\r\ntransactions.\r\n\r\nIt should be fine for LN as unconfirmed ancestors should be limited to 2 (commitment tx and CPFP) unless people batch their commitment txn with one CPFP.",
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#pullrequestreview-310223329",
      "submitted_at": "2019-11-01T00:53:50Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
    },
    {
      "event": "reviewed",
      "id": 310569770,
      "node_id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzEwNTY5Nzcw",
      "url": null,
      "actor": null,
      "commit_id": "1dd7de23f2336e458487f33453c4f7ac8c1a9bef",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "It should be made really clear for off-chain protocol devs to always rebroadcast the whole package instead of only the parent or the child. I'm worrying about scenarii where a a commitment tx is broadcast, don't get into the mempool neither orphan one, latter the high-fee child is broadcast at the application logic and get into the orphan, an attacker overfulfill the orphan pool to discard the child, the application logic rebroadcast the parent tx but not the CPFP assuming it's already there...\r\n\r\nThat's said, I think the P2P work on principle but could be made more robust and tests should include multiple bumped childs and orphan pool overflow.",
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#pullrequestreview-310569770",
      "submitted_at": "2019-11-01T18:23:20Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
    },
    {
      "event": "ready_for_review",
      "id": 2932673435,
      "node_id": "MDE5OlJlYWR5Rm9yUmV2aWV3RXZlbnQyOTMyNjczNDM1",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2932673435",
      "actor": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-08T20:47:53Z"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "MDY6Q29tbWl0MTE4MTkyNzpjMDY3ZDg1NTAwNGQwYjNiNWU2NmFlYTc4ZDkyYTAxYzQzNWE5NWVk",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/c067d855004d0b3b5e66aea78d92a01c435a95ed",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/c067d855004d0b3b5e66aea78d92a01c435a95ed",
      "tree": {
        "sha": "05531a6d0c631ab45da3b945ec5c80c67de95ed7",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/05531a6d0c631ab45da3b945ec5c80c67de95ed7"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/6196e930018181301b5972842ae384ea4288ff34",
          "sha": "6196e930018181301b5972842ae384ea4288ff34",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/6196e930018181301b5972842ae384ea4288ff34"
        }
      ],
      "message": "Add package-acceptance logic to mempool\n\nAccepting a single transaction to the mempool only succeeds if (among other\nthings) the feerate of the transaction is greater than both the min relay fee\nand the mempool min fee. Consequently, a transaction below the minimum fee\nmay not be accepted to the mempool, even if we later learn of a transaction\nwith a high relay fee that depends on it.\n\nThis commit adds a function that will accept a package of transactions to the\nmempool, with the following restrictions:\n\n- All package transactions must be direct parents of the final transaction.\n  This is a simple heuristic for ensuring that a candidate list of transactions\n  is in fact a package (we wouldn't want arbitrary transactions to be paying\n  for random low feerate transactions)\n\n- The feerate of the package, as a whole, exceeds the mempool min fee and the\n  min relay fee.\n\n- No transactions in the mempool conflict with any transactions in the package.\n  This is a simplification that makes the logic easier to write. Without this\n  requirement, we would need to do additional checks to ensure that no parent\n  transaction would evict a transaction from the mempool that some other child\n  depends on.\n\n- The ancestor/descendant size limits are calculated assuming that any mempool\n  ancestor of any candidate transaction is an ancestor of all the candidate\n  transactions.\n  This allows for doing simpler calculations to ensure that we're staying\n  within the mempool's package limits. If we eliminated this, we would need to\n  do much more careful package calculations for each candidate transaction and each\n  in-mempool ancestor.\n\nThis commit does not include any accessor function for utilizing this logic (eg\nby exposing this function at the p2p or rpc layer).",
      "committer": {
        "name": "Suhas Daftuar",
        "email": "sdaftuar@gmail.com",
        "date": "2020-01-08T21:10:17Z"
      },
      "author": {
        "name": "Suhas Daftuar",
        "email": "sdaftuar@gmail.com",
        "date": "2019-07-12T18:53:14Z"
      },
      "sha": "c067d855004d0b3b5e66aea78d92a01c435a95ed"
    },
    {
      "event": "labeled",
      "id": 2932965628,
      "node_id": "MDEyOkxhYmVsZWRFdmVudDI5MzI5NjU2Mjg=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2932965628",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-08T22:34:16Z",
      "label": {
        "name": "Needs rebase",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 572339979,
      "node_id": "MDEyOklzc3VlQ29tbWVudDU3MjMzOTk3OQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/572339979",
      "actor": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-09T01:35:15Z",
      "updated_at": "2020-01-09T01:35:15Z",
      "author_association": "MEMBER",
      "body": "In fact worry described [here](https://github.com/bitcoin/bitcoin/pull/16401#pullrequestreview-310569770) holds, I've modified the new test a bit to overflow the orphan pool with dumb-but-valid orphan pools and it succeeds to evict high-fee child tx easily, even with a low number of malicious orphans (200) : https://github.com/ariard/bitcoin/commit/e20ad2a44a830df7f04cf9bccf9e6791b73d2527",
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#issuecomment-572339979",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/16401"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "MDY6Q29tbWl0MTE4MTkyNzo2YTNiZGJhMDc0NmVmZTlhMzhmNTYwYmIxMTZhODQyNWUwNDEwY2I3",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "tree": {
        "sha": "531da32be675a904879d034637ca46549ba5b11b",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/531da32be675a904879d034637ca46549ba5b11b"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/c067d855004d0b3b5e66aea78d92a01c435a95ed",
          "sha": "c067d855004d0b3b5e66aea78d92a01c435a95ed",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/c067d855004d0b3b5e66aea78d92a01c435a95ed"
        }
      ],
      "message": "Implement package relay for 2-tx packages from the orphan pool\n\nExposes a simple use case for package relay -- if we receive a child\ntransaction that is missing a parent, then we request the parent from our\npeers.\n\nIf a peer responds with a transaction that is rejected from the mempool due to\nfeerate, we have an opportunity to accept that parent along with the child, if\nthe child's feerate is sufficiently high and the child is missing no other\nparents.",
      "committer": {
        "name": "Suhas Daftuar",
        "email": "sdaftuar@gmail.com",
        "date": "2020-01-09T03:45:59Z"
      },
      "author": {
        "name": "Suhas Daftuar",
        "email": "sdaftuar@gmail.com",
        "date": "2019-07-16T19:59:32Z"
      },
      "sha": "6a3bdba0746efe9a38f560bb116a8425e0410cb7"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 2933509183,
      "node_id": "MDIzOkhlYWRSZWZGb3JjZVB1c2hlZEV2ZW50MjkzMzUwOTE4Mw==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2933509183",
      "actor": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-09T03:56:03Z"
    },
    {
      "event": "commented",
      "id": 572373945,
      "node_id": "MDEyOklzc3VlQ29tbWVudDU3MjM3Mzk0NQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/572373945",
      "actor": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-09T04:01:38Z",
      "updated_at": "2020-01-09T04:01:38Z",
      "author_association": "MEMBER",
      "body": "> It should be made really clear for off-chain protocol devs to always rebroadcast the whole package instead of only the parent or the child. I'm worrying about scenarii where a a commitment tx is broadcast, don't get into the mempool neither orphan one, latter the high-fee child is broadcast at the application logic and get into the orphan, an attacker overfulfill the orphan pool to discard the child, the application logic rebroadcast the parent tx but not the CPFP assuming it's already there...\r\n\r\n@ariard It wasn't my goal in this PR to deploy a new p2p package relay scheme that is resilient to DoS attack; instead I wanted to take a smaller use case (resolving orphan transactions missing a single low fee parent) to motivate adding the package acceptance logic.  \r\n\r\nI think once we have the mempool package acceptance logic in, we could then improve the p2p layer further to allow fancier relay schemes.  (See also my comment in https://github.com/bitcoin/bitcoin/issues/14895#issuecomment-499540137.)\r\n\r\nI'll update the title of the PR to make this more clear.\r\n",
      "user": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#issuecomment-572373945",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/16401"
    },
    {
      "event": "mentioned",
      "id": 2933516607,
      "node_id": "MDE0Ok1lbnRpb25lZEV2ZW50MjkzMzUxNjYwNw==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2933516607",
      "actor": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-09T04:01:38Z"
    },
    {
      "event": "subscribed",
      "id": 2933516608,
      "node_id": "MDE1OlN1YnNjcmliZWRFdmVudDI5MzM1MTY2MDg=",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2933516608",
      "actor": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-09T04:01:38Z"
    },
    {
      "event": "renamed",
      "id": 2933518367,
      "node_id": "MDE3OlJlbmFtZWRUaXRsZUV2ZW50MjkzMzUxODM2Nw==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2933518367",
      "actor": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-09T04:02:42Z",
      "rename": {
        "from": "Package relay",
        "to": "Add package acceptance logic to mempool"
      }
    },
    {
      "event": "unlabeled",
      "id": 2933585874,
      "node_id": "MDE0OlVubGFiZWxlZEV2ZW50MjkzMzU4NTg3NA==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2933585874",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-09T04:46:14Z",
      "label": {
        "name": "Needs rebase",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 572660103,
      "node_id": "MDEyOklzc3VlQ29tbWVudDU3MjY2MDEwMw==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/572660103",
      "actor": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-09T17:10:22Z",
      "updated_at": "2020-01-09T17:10:22Z",
      "author_association": "MEMBER",
      "body": "Thanks for clarifying scope of this PR. I do think too it's good to split this project in multi-parts to focus on new mempool acceptance logic, specially what the worst width/depth of a chain of messy transactions we select as a package submission DoS bound.\r\n\r\nThat's said, we may reduce the risks of mempool CPU DoS by implementing the right measures at the p2p level like rate-limiting per-peer package reception. Also if we have different p2p package relay mechanisms (receiver-initiated, sender p2p messages, ...) we need to think how we coordinate them between different releases to avoid applications relying on the wrong ones for their uses cases and falsely assuming they are secure.",
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#issuecomment-572660103",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/16401"
    },
    {
      "event": "added_to_project",
      "id": 2961051946,
      "node_id": "MDE5OkFkZGVkVG9Qcm9qZWN0RXZlbnQyOTYxMDUxOTQ2",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2961051946",
      "actor": {
        "login": "JeremyRubin",
        "id": 886523,
        "node_id": "MDQ6VXNlcjg4NjUyMw==",
        "avatar_url": "https://avatars.githubusercontent.com/u/886523?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/JeremyRubin",
        "html_url": "https://github.com/JeremyRubin",
        "followers_url": "https://api.github.com/users/JeremyRubin/followers",
        "following_url": "https://api.github.com/users/JeremyRubin/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/JeremyRubin/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/JeremyRubin/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/JeremyRubin/subscriptions",
        "organizations_url": "https://api.github.com/users/JeremyRubin/orgs",
        "repos_url": "https://api.github.com/users/JeremyRubin/repos",
        "events_url": "https://api.github.com/users/JeremyRubin/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/JeremyRubin/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-19T18:09:14Z",
      "project_card": {
        "id": 31847347,
        "url": "https://api.github.com/projects/columns/cards/31847347",
        "project_id": 3826895,
        "project_url": "https://api.github.com/projects/3826895",
        "column_name": "Package Relay"
      }
    },
    {
      "event": "commented",
      "id": 579792532,
      "node_id": "MDEyOklzc3VlQ29tbWVudDU3OTc5MjUzMg==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/579792532",
      "actor": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-29T14:55:24Z",
      "updated_at": "2020-01-29T14:55:24Z",
      "author_association": "MEMBER",
      "body": "I'm starting to think that perhaps the use case here isn't really worth it -- I tried to split off what I thought would be a simple use case (of processing some orphan transactions as packages with their rejected parents), but it turns out to be a bit trickier than I expected, and given that we'd just throw this away if we implemented an actual package relay protocol anyway this seems like wasted effort.",
      "user": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#issuecomment-579792532",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/16401"
    },
    {
      "event": "closed",
      "id": 2989825021,
      "node_id": "MDExOkNsb3NlZEV2ZW50Mjk4OTgyNTAyMQ==",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/2989825021",
      "actor": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2020-01-29T14:55:24Z"
    },
    {
      "event": "locked",
      "id": 6073757590,
      "node_id": "LOE_lADOABII584b8fvZzwAAAAFqBi-W",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/6073757590",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2022-02-15T10:26:39Z",
      "lock_reason": "resolved"
    }
  ],
  "comments": [
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307082337",
      "pull_request_review_id": 266360368,
      "id": 307082337,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwNzA4MjMzNw==",
      "diff_hunk": "@@ -326,7 +330,8 @@ bool TestLockPointValidity(const LockPoints* lp) EXCLUSIVE_LOCKS_REQUIRED(cs_mai\n  *\n  * See consensus/consensus.h for flag definitions.\n  */\n-bool CheckSequenceLocks(const CTxMemPool& pool, const CTransaction& tx, int flags, LockPoints* lp = nullptr, bool useExistingLockPoints = false) EXCLUSIVE_LOCKS_REQUIRED(cs_main);\n+bool CheckSequenceLocks(const CTxMemPool &pool, const CTransaction& tx, int flags, LockPoints* lp = nullptr, bool useExistingLockPoints = false) EXCLUSIVE_LOCKS_REQUIRED(cs_main);\n+bool CheckSequenceLocks(CCoinsViewCache& view, const CTransaction& tx, int flags, LockPoints* lp = nullptr, bool useExistingLockPoints = false) EXCLUSIVE_LOCKS_REQUIRED(cs_main);",
      "path": "src/validation.h",
      "position": null,
      "original_position": 17,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": null,
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Moving the `&` in `CTxMemPool &pool` seems like a typo. Also you don't actually need the `view` method in the header, could just make it a static.",
      "created_at": "2019-07-25T01:24:09Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r307082337",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307082337"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 334,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307082891",
      "pull_request_review_id": 266360368,
      "id": 307082891,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwNzA4Mjg5MQ==",
      "diff_hunk": "@@ -2551,33 +2558,80 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n                 recentRejects->insert(tx.GetHash());\n             }\n         } else {\n-            assert(IsTransactionReason(state.GetReason()));\n-            if (!tx.HasWitness() && state.GetReason() != ValidationInvalidReason::TX_WITNESS_MUTATED) {\n-                // Do not use rejection cache for witness transactions or\n-                // witness-stripped transactions, as they can have been malleated.\n-                // See https://github.com/bitcoin/bitcoin/issues/8279 for details.\n-                assert(recentRejects);\n-                recentRejects->insert(tx.GetHash());\n-                if (RecursiveDynamicUsage(*ptx) < 100000) {\n-                    AddToCompactExtraTransactions(ptx);\n+            // If this tx didn't make it in due to feerate, and there is a tx\n+            // in the orphan pool -- then maybe that tx is only missing this\n+            // one parent.\n+            // Try to process the pair as a package.\n+            bool added_as_package = false;\n+            if (state.GetRejectCode() == REJECT_INSUFFICIENTFEE) {\n+                LOCK(g_cs_orphans);",
      "path": "src/net_processing.cpp",
      "position": null,
      "original_position": 56,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": null,
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "g_cs_orphans is already locked earlier in the path (`LOCK2(cs_main, g_cs_orphans)`)",
      "created_at": "2019-07-25T01:27:48Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r307082891",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307082891"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 2567,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307084354",
      "pull_request_review_id": 266360368,
      "id": 307084354,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwNzA4NDM1NA==",
      "diff_hunk": "@@ -422,21 +428,136 @@ static bool CheckInputsFromMempoolAndCache(const CTransaction& tx, CValidationSt\n     return CheckInputs(tx, state, view, true, flags, cacheSigStore, true, txdata);\n }\n \n-/**\n- * @param[out] coins_to_uncache   Return any outpoints which were not previously present in the\n- *                                coins cache, but were added as a result of validating the tx\n- *                                for mempool acceptance. This allows the caller to optionally\n- *                                remove the cache additions if the associated transaction ends\n- *                                up being rejected by the mempool.\n- */\n-static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool& pool, CValidationState& state, const CTransactionRef& ptx,\n-                              bool* pfMissingInputs, int64_t nAcceptTime, std::list<CTransactionRef>* plTxnReplaced,\n-                              bool bypass_limits, const CAmount& nAbsurdFee, std::vector<COutPoint>& coins_to_uncache, bool test_accept) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n+namespace {\n+\n+class MemPoolAccept\n {\n-    const CTransaction& tx = *ptx;\n-    const uint256 hash = tx.GetHash();\n-    AssertLockHeld(cs_main);\n-    LOCK(pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+public:\n+    MemPoolAccept(CTxMemPool& mempool) : m_pool(mempool), m_view(&m_dummy), m_viewmempool(pcoinsTip.get(), m_pool),\n+        m_limit_ancestors(gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT)),\n+        m_limit_ancestor_size(gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000),\n+        m_limit_descendants(gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT)),\n+        m_limit_descendant_size(gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000) {}\n+\n+    // We put the arguments we're handed into a struct, so we can pass them\n+    // around easier.\n+    struct ATMPArgs {\n+        const CChainParams& m_chainparams;\n+        CValidationState &m_state;\n+        bool* m_missing_inputs;\n+        const int64_t m_accept_time;\n+        std::list<CTransactionRef>* m_replaced_transactions;\n+        const bool m_bypass_limits;\n+        const CAmount& m_absurd_fee;\n+        /*\n+         * Return any outpoints which were not previously present in the coins\n+         * cache, but were added as a result of validating the tx for mempool\n+         * acceptance. This allows the caller to optionally remove the cache\n+         * additions if the associated transaction ends up being rejected by\n+         * the mempool.\n+         */\n+        std::vector<COutPoint>& m_coins_to_uncache;\n+        const bool m_test_accept;\n+    };\n+\n+    // Single transaction acceptance\n+    bool AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args) EXCLUSIVE_LOCKS_REQUIRED(cs_main);\n+\n+    // Multiple transaction acceptance\n+    bool AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args) EXCLUSIVE_LOCKS_REQUIRED(cs_main);",
      "path": "src/validation.cpp",
      "position": null,
      "original_position": 96,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": null,
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "tx_list should be `const &` afaics.",
      "created_at": "2019-07-25T01:36:56Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r307084354",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307084354"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 467,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307087216",
      "pull_request_review_id": 266360368,
      "id": 307087216,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwNzA4NzIxNg==",
      "diff_hunk": "@@ -508,348 +628,532 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         }\n     }\n \n-    {\n-        CCoinsView dummy;\n-        CCoinsViewCache view(&dummy);\n-\n-        LockPoints lp;\n-        CCoinsViewMemPool viewMemPool(pcoinsTip.get(), pool);\n-        view.SetBackend(viewMemPool);\n+    LockPoints lp;\n+    m_view.SetBackend(m_viewmempool);\n \n-        // do all inputs exist?\n-        for (const CTxIn& txin : tx.vin) {\n-            if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n-                coins_to_uncache.push_back(txin.prevout);\n-            }\n-\n-            // Note: this call may add txin.prevout to the coins cache\n-            // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n-            // later (via coins_to_uncache) if this tx turns out to be invalid.\n-            if (!view.HaveCoin(txin.prevout)) {\n-                // Are inputs missing because we already have the tx?\n-                for (size_t out = 0; out < tx.vout.size(); out++) {\n-                    // Optimistically just do efficient check of cache for outputs\n-                    if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n-                        return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n-                    }\n-                }\n-                // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n-                if (pfMissingInputs) {\n-                    *pfMissingInputs = true;\n+    // do all inputs exist?\n+    for (const CTxIn& txin : tx.vin) {\n+        if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n+            coins_to_uncache.push_back(txin.prevout);\n+        }\n+\n+        // Note: this call may add txin.prevout to the coins cache\n+        // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n+        // later (via coins_to_uncache) if this tx turns out to be invalid.\n+        if (!m_view.HaveCoin(txin.prevout)) {\n+            // Are inputs missing because we already have the tx?\n+            for (size_t out = 0; out < tx.vout.size(); out++) {\n+                // Optimistically just do efficient check of cache for outputs\n+                if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n+                    return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n                 }\n-                return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n             }\n+            // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n+            if (pfMissingInputs) {\n+                *pfMissingInputs = true;\n+            }\n+            return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n         }\n+    }\n \n-        // Bring the best block into scope\n-        view.GetBestBlock();\n+    // Bring the best block into scope\n+    m_view.GetBestBlock();\n \n-        // we have all inputs cached now, so switch back to dummy, so we don't need to keep lock on mempool\n-        view.SetBackend(dummy);\n+    // we have all inputs cached now, so switch back to dummy (to protect\n+    // against bugs where we pull more inputs from disk that miss being added\n+    // to coins_to_uncache)\n+    m_view.SetBackend(m_dummy);\n \n-        // Only accept BIP68 sequence locked transactions that can be mined in the next\n-        // block; we don't want our mempool filled up with transactions that can't\n-        // be mined yet.\n-        // Must keep pool.cs for this unless we change CheckSequenceLocks to take a\n-        // CoinsViewCache instead of create its own\n-        if (!CheckSequenceLocks(pool, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n-            return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n+    // Only accept BIP68 sequence locked transactions that can be mined in the next\n+    // block; we don't want our mempool filled up with transactions that can't\n+    // be mined yet.\n+    if (!CheckSequenceLocks(m_view, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n+        return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n \n-        CAmount nFees = 0;\n-        if (!Consensus::CheckTxInputs(tx, state, view, GetSpendHeight(view), nFees)) {\n-            return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n-        }\n+    CAmount nFees = 0;\n+    if (!Consensus::CheckTxInputs(tx, state, m_view, GetSpendHeight(m_view), nFees)) {\n+        return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n+    }\n \n-        // Check for non-standard pay-to-script-hash in inputs\n-        if (fRequireStandard && !AreInputsStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n+    // Check for non-standard pay-to-script-hash in inputs\n+    if (fRequireStandard && !AreInputsStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n \n-        // Check for non-standard witness in P2WSH\n-        if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n+    // Check for non-standard witness in P2WSH\n+    if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n \n-        int64_t nSigOpsCost = GetTransactionSigOpCost(tx, view, STANDARD_SCRIPT_VERIFY_FLAGS);\n+    int64_t nSigOpsCost = GetTransactionSigOpCost(tx, m_view, STANDARD_SCRIPT_VERIFY_FLAGS);\n \n-        // nModifiedFees includes any fee deltas from PrioritiseTransaction\n-        CAmount nModifiedFees = nFees;\n-        pool.ApplyDelta(hash, nModifiedFees);\n+    // nModifiedFees includes any fee deltas from PrioritiseTransaction\n+    nModifiedFees = nFees;\n+    m_pool.ApplyDelta(hash, nModifiedFees);\n \n-        // Keep track of transactions that spend a coinbase, which we re-scan\n-        // during reorgs to ensure COINBASE_MATURITY is still met.\n-        bool fSpendsCoinbase = false;\n-        for (const CTxIn &txin : tx.vin) {\n-            const Coin &coin = view.AccessCoin(txin.prevout);\n-            if (coin.IsCoinBase()) {\n-                fSpendsCoinbase = true;\n-                break;\n-            }\n+    // Keep track of transactions that spend a coinbase, which we re-scan\n+    // during reorgs to ensure COINBASE_MATURITY is still met.\n+    bool fSpendsCoinbase = false;\n+    for (const CTxIn &txin : tx.vin) {\n+        const Coin &coin = m_view.AccessCoin(txin.prevout);\n+        if (coin.IsCoinBase()) {\n+            fSpendsCoinbase = true;\n+            break;\n         }\n+    }\n \n-        CTxMemPoolEntry entry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n-                              fSpendsCoinbase, nSigOpsCost, lp);\n-        unsigned int nSize = entry.GetTxSize();\n+    entry.reset(new CTxMemPoolEntry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n+            fSpendsCoinbase, nSigOpsCost, lp));\n+    unsigned int nSize = entry->GetTxSize();\n \n-        if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n+    if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n                 strprintf(\"%d\", nSigOpsCost));\n \n-        CAmount mempoolRejectFee = pool.GetMinFee(gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000).GetFee(nSize);\n-        if (!bypass_limits && mempoolRejectFee > 0 && nModifiedFees < mempoolRejectFee) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool min fee not met\", strprintf(\"%d < %d\", nModifiedFees, mempoolRejectFee));\n-        }\n-\n-        // No transactions are allowed below minRelayTxFee except from disconnected blocks\n-        if (!bypass_limits && nModifiedFees < ::minRelayTxFee.GetFee(nSize)) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"min relay fee not met\", strprintf(\"%d < %d\", nModifiedFees, ::minRelayTxFee.GetFee(nSize)));\n-        }\n+    // No transactions are allowed below minRelayTxFee/mempool min fee except\n+    // from disconnected blocks\n+    if (!bypass_limits && !CheckFeeRate(nSize, nModifiedFees, state)) return false;\n \n-        if (nAbsurdFee && nFees > nAbsurdFee)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n+    if (nAbsurdFee && nFees > nAbsurdFee)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n                 REJECT_HIGHFEE, \"absurdly-high-fee\",\n                 strprintf(\"%d > %d\", nFees, nAbsurdFee));\n \n-        // Calculate in-mempool ancestors, up to a limit.\n-        CTxMemPool::setEntries setAncestors;\n-        size_t nLimitAncestors = gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT);\n-        size_t nLimitAncestorSize = gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000;\n-        size_t nLimitDescendants = gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT);\n-        size_t nLimitDescendantSize = gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000;\n-        std::string errString;\n-        if (!pool.CalculateMemPoolAncestors(entry, setAncestors, nLimitAncestors, nLimitAncestorSize, nLimitDescendants, nLimitDescendantSize, errString)) {\n-            setAncestors.clear();\n-            // If the new transaction is relatively small (up to 40k weight)\n-            // and has at most one ancestor (ie ancestor limit of 2, including\n-            // the new transaction), allow it if its parent has exactly the\n-            // descendant limit descendants.\n-            //\n-            // This allows protocols which rely on distrusting counterparties\n-            // being able to broadcast descendants of an unconfirmed transaction\n-            // to be secure by simply only having two immediately-spendable\n-            // outputs - one for each counterparty. For more info on the uses for\n-            // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n-            if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n-                    !pool.CalculateMemPoolAncestors(entry, setAncestors, 2, nLimitAncestorSize, nLimitDescendants + 1, nLimitDescendantSize + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n-            }\n-        }\n-\n-        // A transaction that spends outputs that would be replaced by it is invalid. Now\n-        // that we have the set of all ancestors we can detect this\n-        // pathological case by making sure setConflicts and setAncestors don't\n-        // intersect.\n-        for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    // Calculate in-mempool ancestors, up to a limit.\n+    std::string errString;\n+    if (!m_pool.CalculateMemPoolAncestors(*entry, setAncestors, m_limit_ancestors, m_limit_ancestor_size, m_limit_descendants, m_limit_descendant_size, errString)) {\n+        setAncestors.clear();\n+        // If the new transaction is relatively small (up to 40k weight)\n+        // and has at most one ancestor (ie ancestor limit of 2, including\n+        // the new transaction), allow it if its parent has exactly the\n+        // descendant limit descendants.\n+        //\n+        // This allows protocols which rely on distrusting counterparties\n+        // being able to broadcast descendants of an unconfirmed transaction\n+        // to be secure by simply only having two immediately-spendable\n+        // outputs - one for each counterparty. For more info on the uses for\n+        // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n+        if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n+                !m_pool.CalculateMemPoolAncestors(*entry, setAncestors, 2, m_limit_ancestor_size, m_limit_descendants + 1, m_limit_descendant_size + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n+        }\n+    }\n+\n+    // A transaction that spends outputs that would be replaced by it is invalid. Now\n+    // that we have the set of all ancestors we can detect this\n+    // pathological case by making sure setConflicts and setAncestors don't\n+    // intersect.\n+    for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    {\n+        const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n+        if (setConflicts.count(hashAncestor))\n         {\n-            const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n-            if (setConflicts.count(hashAncestor))\n-            {\n-                return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n-                                 strprintf(\"%s spends conflicting transaction %s\",\n-                                           hash.ToString(),\n-                                           hashAncestor.ToString()));\n-            }\n+            return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n+                    strprintf(\"%s spends conflicting transaction %s\",\n+                        hash.ToString(),\n+                        hashAncestor.ToString()));\n         }\n+    }\n \n-        // Check if it's economically rational to mine this transaction rather\n-        // than the ones it replaces.\n-        CAmount nConflictingFees = 0;\n-        size_t nConflictingSize = 0;\n-        uint64_t nConflictingCount = 0;\n-        CTxMemPool::setEntries allConflicting;\n-\n-        // If we don't hold the lock allConflicting might be incomplete; the\n-        // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n-        // mempool consistency for us.\n-        const bool fReplacementTransaction = setConflicts.size();\n-        if (fReplacementTransaction)\n-        {\n-            CFeeRate newFeeRate(nModifiedFees, nSize);\n-            std::set<uint256> setConflictsParents;\n-            const int maxDescendantsToVisit = 100;\n-            const CTxMemPool::setEntries setIterConflicting = pool.GetIterSet(setConflicts);\n-            for (const auto& mi : setIterConflicting) {\n-                // Don't allow the replacement to reduce the feerate of the\n-                // mempool.\n-                //\n-                // We usually don't want to accept replacements with lower\n-                // feerates than what they replaced as that would lower the\n-                // feerate of the next block. Requiring that the feerate always\n-                // be increased is also an easy-to-reason about way to prevent\n-                // DoS attacks via replacements.\n-                //\n-                // We only consider the feerates of transactions being directly\n-                // replaced, not their indirect descendants. While that does\n-                // mean high feerate children are ignored when deciding whether\n-                // or not to replace, we do require the replacement to pay more\n-                // overall fees too, mitigating most cases.\n-                CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n-                if (newFeeRate <= oldFeeRate)\n-                {\n-                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                            strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n-                                  hash.ToString(),\n-                                  newFeeRate.ToString(),\n-                                  oldFeeRate.ToString()));\n-                }\n-\n-                for (const CTxIn &txin : mi->GetTx().vin)\n-                {\n-                    setConflictsParents.insert(txin.prevout.hash);\n-                }\n+    // Check if it's economically rational to mine this transaction rather\n+    // than the ones it replaces.\n+    nConflictingFees = 0;\n+    nConflictingSize = 0;\n+    uint64_t nConflictingCount = 0;\n \n-                nConflictingCount += mi->GetCountWithDescendants();\n-            }\n-            // This potentially overestimates the number of actual descendants\n-            // but we just want to be conservative to avoid doing too much\n-            // work.\n-            if (nConflictingCount <= maxDescendantsToVisit) {\n-                // If not too many to replace, then calculate the set of\n-                // transactions that would have to be evicted\n-                for (CTxMemPool::txiter it : setIterConflicting) {\n-                    pool.CalculateDescendants(it, allConflicting);\n-                }\n-                for (CTxMemPool::txiter it : allConflicting) {\n-                    nConflictingFees += it->GetModifiedFee();\n-                    nConflictingSize += it->GetTxSize();\n-                }\n-            } else {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n-                        strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+    // If we don't hold the lock allConflicting might be incomplete; the\n+    // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n+    // mempool consistency for us.\n+    fReplacementTransaction = setConflicts.size();\n+    if (fReplacementTransaction)\n+    {\n+        CFeeRate newFeeRate(nModifiedFees, nSize);\n+        std::set<uint256> setConflictsParents;\n+        const int maxDescendantsToVisit = 100;\n+        const CTxMemPool::setEntries setIterConflicting = m_pool.GetIterSet(setConflicts);\n+        for (const auto& mi : setIterConflicting) {\n+            // Don't allow the replacement to reduce the feerate of the\n+            // mempool.\n+            //\n+            // We usually don't want to accept replacements with lower\n+            // feerates than what they replaced as that would lower the\n+            // feerate of the next block. Requiring that the feerate always\n+            // be increased is also an easy-to-reason about way to prevent\n+            // DoS attacks via replacements.\n+            //\n+            // We only consider the feerates of transactions being directly\n+            // replaced, not their indirect descendants. While that does\n+            // mean high feerate children are ignored when deciding whether\n+            // or not to replace, we do require the replacement to pay more\n+            // overall fees too, mitigating most cases.\n+            CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n+            if (newFeeRate <= oldFeeRate)\n+            {\n+                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                        strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n                             hash.ToString(),\n-                            nConflictingCount,\n-                            maxDescendantsToVisit));\n+                            newFeeRate.ToString(),\n+                            oldFeeRate.ToString()));\n             }\n \n-            for (unsigned int j = 0; j < tx.vin.size(); j++)\n+            for (const CTxIn &txin : mi->GetTx().vin)\n             {\n-                // We don't want to accept replacements that require low\n-                // feerate junk to be mined first. Ideally we'd keep track of\n-                // the ancestor feerates and make the decision based on that,\n-                // but for now requiring all new inputs to be confirmed works.\n-                if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n-                {\n-                    // Rather than check the UTXO set - potentially expensive -\n-                    // it's cheaper to just check if the new input refers to a\n-                    // tx that's in the mempool.\n-                    if (pool.exists(tx.vin[j].prevout.hash)) {\n-                        return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n-                                         strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n-                                                  hash.ToString(), j));\n-                    }\n-                }\n+                setConflictsParents.insert(txin.prevout.hash);\n             }\n \n-            // The replacement must pay greater fees than the transactions it\n-            // replaces - if we did the bandwidth used by those conflicting\n-            // transactions would not be paid for.\n-            if (nModifiedFees < nConflictingFees)\n-            {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                                 strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n-                                          hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n+            nConflictingCount += mi->GetCountWithDescendants();\n+        }\n+        // This potentially overestimates the number of actual descendants\n+        // but we just want to be conservative to avoid doing too much\n+        // work.\n+        if (nConflictingCount <= maxDescendantsToVisit) {\n+            // If not too many to replace, then calculate the set of\n+            // transactions that would have to be evicted\n+            for (CTxMemPool::txiter it : setIterConflicting) {\n+                m_pool.CalculateDescendants(it, allConflicting);\n             }\n+            for (CTxMemPool::txiter it : allConflicting) {\n+                nConflictingFees += it->GetModifiedFee();\n+                nConflictingSize += it->GetTxSize();\n+            }\n+        } else {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n+                    strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+                        hash.ToString(),\n+                        nConflictingCount,\n+                        maxDescendantsToVisit));\n+        }\n \n-            // Finally in addition to paying more fees than the conflicts the\n-            // new transaction must pay for its own bandwidth.\n-            CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n-            if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        for (unsigned int j = 0; j < tx.vin.size(); j++)\n+        {\n+            // We don't want to accept replacements that require low\n+            // feerate junk to be mined first. Ideally we'd keep track of\n+            // the ancestor feerates and make the decision based on that,\n+            // but for now requiring all new inputs to be confirmed works.\n+            if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n             {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                        strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n-                              hash.ToString(),\n-                              FormatMoney(nDeltaFees),\n-                              FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n+                // Rather than check the UTXO set - potentially expensive -\n+                // it's cheaper to just check if the new input refers to a\n+                // tx that's in the mempool.\n+                if (m_pool.exists(tx.vin[j].prevout.hash)) {\n+                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n+                            strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n+                                hash.ToString(), j));\n+                }\n             }\n         }\n \n-        constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n-\n-        // Check against previous transactions\n-        // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n-        PrecomputedTransactionData txdata(tx);\n-        if (!CheckInputs(tx, state, view, true, scriptVerifyFlags, true, false, txdata)) {\n-            // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n-            // need to turn both off, and compare against just turning off CLEANSTACK\n-            // to see if the failure is specifically due to witness validation.\n-            CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n-            if (!tx.HasWitness() && CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n-                !CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n-                // Only the witness is missing, so the transaction itself may be fine.\n-                state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n-                        state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n-            }\n-            assert(IsTransactionReason(state.GetReason()));\n-            return false; // state filled in by CheckInputs\n+        // The replacement must pay greater fees than the transactions it\n+        // replaces - if we did the bandwidth used by those conflicting\n+        // transactions would not be paid for.\n+        if (nModifiedFees < nConflictingFees)\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n+                        hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n         }\n \n-        // Check again against the current block tip's script verification\n-        // flags to cache our script execution flags. This is, of course,\n-        // useless if the next block has different script flags from the\n-        // previous one, but because the cache tracks script flags for us it\n-        // will auto-invalidate and we'll just have a few blocks of extra\n-        // misses on soft-fork activation.\n-        //\n-        // This is also useful in case of bugs in the standard flags that cause\n-        // transactions to pass as valid when they're actually invalid. For\n-        // instance the STRICTENC flag was incorrectly allowing certain\n-        // CHECKSIG NOT scripts to pass, even though they were invalid.\n-        //\n-        // There is a similar check in CreateNewBlock() to prevent creating\n-        // invalid blocks (using TestBlockValidity), however allowing such\n-        // transactions into the mempool can be exploited as a DoS attack.\n-        unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n-        if (!CheckInputsFromMempoolAndCache(tx, state, view, pool, currentBlockScriptVerifyFlags, true, txdata)) {\n-            return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n-                    __func__, hash.ToString(), FormatStateMessage(state));\n+        // Finally in addition to paying more fees than the conflicts the\n+        // new transaction must pay for its own bandwidth.\n+        CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n+        if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n+                        hash.ToString(),\n+                        FormatMoney(nDeltaFees),\n+                        FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n         }\n+    }\n+    return true;\n+}\n \n-        if (test_accept) {\n-            // Tx was accepted, but not added\n-            return true;\n+bool MemPoolAccept::PolicyScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+\n+    CValidationState &state = args.m_state;\n+\n+    constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n+\n+    // Check against previous transactions\n+    // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n+    if (!CheckInputs(tx, state, m_view, true, scriptVerifyFlags, true, false, txdata)) {\n+        // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n+        // need to turn both off, and compare against just turning off CLEANSTACK\n+        // to see if the failure is specifically due to witness validation.\n+        CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n+        if (!tx.HasWitness() && CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n+                !CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n+            // Only the witness is missing, so the transaction itself may be fine.\n+            state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n+                    state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n         }\n+        assert(IsTransactionReason(state.GetReason()));\n+        return false; // state filled in by CheckInputs\n+    }\n \n-        // Remove conflicting transactions from the mempool\n-        for (CTxMemPool::txiter it : allConflicting)\n-        {\n-            LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n-                    it->GetTx().GetHash().ToString(),\n-                    hash.ToString(),\n-                    FormatMoney(nModifiedFees - nConflictingFees),\n-                    (int)nSize - (int)nConflictingSize);\n-            if (plTxnReplaced)\n-                plTxnReplaced->push_back(it->GetSharedTx());\n+    return true;\n+}\n+\n+bool MemPoolAccept::ConsensusScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+\n+    CValidationState &state = args.m_state;\n+    const CChainParams& chainparams = args.m_chainparams;\n+\n+    // Check again against the current block tip's script verification\n+    // flags to cache our script execution flags. This is, of course,\n+    // useless if the next block has different script flags from the\n+    // previous one, but because the cache tracks script flags for us it\n+    // will auto-invalidate and we'll just have a few blocks of extra\n+    // misses on soft-fork activation.\n+    //\n+    // This is also useful in case of bugs in the standard flags that cause\n+    // transactions to pass as valid when they're actually invalid. For\n+    // instance the STRICTENC flag was incorrectly allowing certain\n+    // CHECKSIG NOT scripts to pass, even though they were invalid.\n+    //\n+    // There is a similar check in CreateNewBlock() to prevent creating\n+    // invalid blocks (using TestBlockValidity), however allowing such\n+    // transactions into the mempool can be exploited as a DoS attack.\n+    unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n+    if (!CheckInputsFromMempoolAndCache(tx, state, m_view, m_pool, currentBlockScriptVerifyFlags, true, txdata)) {\n+        return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n+                __func__, hash.ToString(), FormatStateMessage(state));\n+    }\n+\n+    return true;\n+}\n+\n+bool MemPoolAccept::Finalize(ATMPArgs& args, Workspace& ws)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+    CValidationState &state = args.m_state;\n+    const bool bypass_limits = args.m_bypass_limits;\n+\n+    CTxMemPool::setEntries& allConflicting = ws.m_all_conflicting;\n+    CTxMemPool::setEntries& setAncestors = ws.m_ancestors;\n+    const CAmount& nModifiedFees = ws.m_modified_fees;\n+    const CAmount& nConflictingFees = ws.m_conflicting_fees;\n+    const size_t& nConflictingSize = ws.m_conflicting_size;\n+    const bool fReplacementTransaction = ws.m_replacement_transaction;\n+    std::unique_ptr<CTxMemPoolEntry>& entry = ws.m_entry;\n+\n+    // Remove conflicting transactions from the mempool\n+    for (CTxMemPool::txiter it : allConflicting)\n+    {\n+        LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n+                it->GetTx().GetHash().ToString(),\n+                hash.ToString(),\n+                FormatMoney(nModifiedFees - nConflictingFees),\n+                (int)entry->GetTxSize() - (int)nConflictingSize);\n+        if (args.m_replaced_transactions)\n+            args.m_replaced_transactions->push_back(it->GetSharedTx());\n+    }\n+    m_pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+\n+    // This transaction should only count for fee estimation if:\n+    // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n+    // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n+    // - the node is not behind\n+    // - the transaction is not dependent on any other transactions in the mempool\n+    bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && m_pool.HasNoInputsOf(tx);\n+\n+    // Store transaction in memory\n+    m_pool.addUnchecked(*entry, setAncestors, validForFeeEstimation);\n+\n+    // trim mempool and check if tx was trimmed\n+    if (!bypass_limits) {\n+        LimitMempoolSize(m_pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n+        if (!m_pool.exists(hash))\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    }\n+    return true;\n+}\n+\n+bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+\n+    Workspace workspace(ptx);\n+\n+    if (!PreChecks(args, workspace)) return false;\n+\n+    // Only compute the precomputed transaction data if we need to verify\n+    // scripts (ie, other policy checks pass)\n+    PrecomputedTransactionData txdata(*ptx);\n+\n+    if (!PolicyScriptChecks(args, workspace, txdata)) return false;\n+\n+    if (!ConsensusScriptChecks(args, workspace, txdata)) return false;\n+\n+    // Tx was accepted, but not added\n+    if (args.m_test_accept) return true;\n+\n+    if (!Finalize(args, workspace)) return false;\n+\n+    GetMainSignals().TransactionAddedToMempool(ptx);\n+\n+    return true;\n+}\n+\n+\n+bool MemPoolAccept::AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    // We will disable the individual transaction fee-rate checks for all\n+    // parents of the final transaction.\n+    ATMPArgs args_bypass_limits { args.m_chainparams, args.m_state, args.m_missing_inputs, args.m_accept_time, args.m_replaced_transactions, /*m_bypass_limits*/ true, args.m_absurd_fee, args.m_coins_to_uncache, args.m_test_accept };",
      "path": "src/validation.cpp",
      "position": null,
      "original_position": 860,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": null,
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Adding a `Workspace::m_cpfpable` bool set to true for all but the last tx, and setting `const bool bypass_limits = args.bypass_limits || ws.cpfpable` seems better to me, fwiw.",
      "created_at": "2019-07-25T01:54:08Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r307087216",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307087216"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1011,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307087452",
      "pull_request_review_id": 266360368,
      "id": 307087452,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwNzA4NzQ1Mg==",
      "diff_hunk": "@@ -508,348 +628,532 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         }\n     }\n \n-    {\n-        CCoinsView dummy;\n-        CCoinsViewCache view(&dummy);\n-\n-        LockPoints lp;\n-        CCoinsViewMemPool viewMemPool(pcoinsTip.get(), pool);\n-        view.SetBackend(viewMemPool);\n+    LockPoints lp;\n+    m_view.SetBackend(m_viewmempool);\n \n-        // do all inputs exist?\n-        for (const CTxIn& txin : tx.vin) {\n-            if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n-                coins_to_uncache.push_back(txin.prevout);\n-            }\n-\n-            // Note: this call may add txin.prevout to the coins cache\n-            // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n-            // later (via coins_to_uncache) if this tx turns out to be invalid.\n-            if (!view.HaveCoin(txin.prevout)) {\n-                // Are inputs missing because we already have the tx?\n-                for (size_t out = 0; out < tx.vout.size(); out++) {\n-                    // Optimistically just do efficient check of cache for outputs\n-                    if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n-                        return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n-                    }\n-                }\n-                // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n-                if (pfMissingInputs) {\n-                    *pfMissingInputs = true;\n+    // do all inputs exist?\n+    for (const CTxIn& txin : tx.vin) {\n+        if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n+            coins_to_uncache.push_back(txin.prevout);\n+        }\n+\n+        // Note: this call may add txin.prevout to the coins cache\n+        // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n+        // later (via coins_to_uncache) if this tx turns out to be invalid.\n+        if (!m_view.HaveCoin(txin.prevout)) {\n+            // Are inputs missing because we already have the tx?\n+            for (size_t out = 0; out < tx.vout.size(); out++) {\n+                // Optimistically just do efficient check of cache for outputs\n+                if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n+                    return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n                 }\n-                return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n             }\n+            // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n+            if (pfMissingInputs) {\n+                *pfMissingInputs = true;\n+            }\n+            return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n         }\n+    }\n \n-        // Bring the best block into scope\n-        view.GetBestBlock();\n+    // Bring the best block into scope\n+    m_view.GetBestBlock();\n \n-        // we have all inputs cached now, so switch back to dummy, so we don't need to keep lock on mempool\n-        view.SetBackend(dummy);\n+    // we have all inputs cached now, so switch back to dummy (to protect\n+    // against bugs where we pull more inputs from disk that miss being added\n+    // to coins_to_uncache)\n+    m_view.SetBackend(m_dummy);\n \n-        // Only accept BIP68 sequence locked transactions that can be mined in the next\n-        // block; we don't want our mempool filled up with transactions that can't\n-        // be mined yet.\n-        // Must keep pool.cs for this unless we change CheckSequenceLocks to take a\n-        // CoinsViewCache instead of create its own\n-        if (!CheckSequenceLocks(pool, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n-            return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n+    // Only accept BIP68 sequence locked transactions that can be mined in the next\n+    // block; we don't want our mempool filled up with transactions that can't\n+    // be mined yet.\n+    if (!CheckSequenceLocks(m_view, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n+        return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n \n-        CAmount nFees = 0;\n-        if (!Consensus::CheckTxInputs(tx, state, view, GetSpendHeight(view), nFees)) {\n-            return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n-        }\n+    CAmount nFees = 0;\n+    if (!Consensus::CheckTxInputs(tx, state, m_view, GetSpendHeight(m_view), nFees)) {\n+        return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n+    }\n \n-        // Check for non-standard pay-to-script-hash in inputs\n-        if (fRequireStandard && !AreInputsStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n+    // Check for non-standard pay-to-script-hash in inputs\n+    if (fRequireStandard && !AreInputsStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n \n-        // Check for non-standard witness in P2WSH\n-        if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n+    // Check for non-standard witness in P2WSH\n+    if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n \n-        int64_t nSigOpsCost = GetTransactionSigOpCost(tx, view, STANDARD_SCRIPT_VERIFY_FLAGS);\n+    int64_t nSigOpsCost = GetTransactionSigOpCost(tx, m_view, STANDARD_SCRIPT_VERIFY_FLAGS);\n \n-        // nModifiedFees includes any fee deltas from PrioritiseTransaction\n-        CAmount nModifiedFees = nFees;\n-        pool.ApplyDelta(hash, nModifiedFees);\n+    // nModifiedFees includes any fee deltas from PrioritiseTransaction\n+    nModifiedFees = nFees;\n+    m_pool.ApplyDelta(hash, nModifiedFees);\n \n-        // Keep track of transactions that spend a coinbase, which we re-scan\n-        // during reorgs to ensure COINBASE_MATURITY is still met.\n-        bool fSpendsCoinbase = false;\n-        for (const CTxIn &txin : tx.vin) {\n-            const Coin &coin = view.AccessCoin(txin.prevout);\n-            if (coin.IsCoinBase()) {\n-                fSpendsCoinbase = true;\n-                break;\n-            }\n+    // Keep track of transactions that spend a coinbase, which we re-scan\n+    // during reorgs to ensure COINBASE_MATURITY is still met.\n+    bool fSpendsCoinbase = false;\n+    for (const CTxIn &txin : tx.vin) {\n+        const Coin &coin = m_view.AccessCoin(txin.prevout);\n+        if (coin.IsCoinBase()) {\n+            fSpendsCoinbase = true;\n+            break;\n         }\n+    }\n \n-        CTxMemPoolEntry entry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n-                              fSpendsCoinbase, nSigOpsCost, lp);\n-        unsigned int nSize = entry.GetTxSize();\n+    entry.reset(new CTxMemPoolEntry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n+            fSpendsCoinbase, nSigOpsCost, lp));\n+    unsigned int nSize = entry->GetTxSize();\n \n-        if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n+    if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n                 strprintf(\"%d\", nSigOpsCost));\n \n-        CAmount mempoolRejectFee = pool.GetMinFee(gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000).GetFee(nSize);\n-        if (!bypass_limits && mempoolRejectFee > 0 && nModifiedFees < mempoolRejectFee) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool min fee not met\", strprintf(\"%d < %d\", nModifiedFees, mempoolRejectFee));\n-        }\n-\n-        // No transactions are allowed below minRelayTxFee except from disconnected blocks\n-        if (!bypass_limits && nModifiedFees < ::minRelayTxFee.GetFee(nSize)) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"min relay fee not met\", strprintf(\"%d < %d\", nModifiedFees, ::minRelayTxFee.GetFee(nSize)));\n-        }\n+    // No transactions are allowed below minRelayTxFee/mempool min fee except\n+    // from disconnected blocks\n+    if (!bypass_limits && !CheckFeeRate(nSize, nModifiedFees, state)) return false;\n \n-        if (nAbsurdFee && nFees > nAbsurdFee)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n+    if (nAbsurdFee && nFees > nAbsurdFee)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n                 REJECT_HIGHFEE, \"absurdly-high-fee\",\n                 strprintf(\"%d > %d\", nFees, nAbsurdFee));\n \n-        // Calculate in-mempool ancestors, up to a limit.\n-        CTxMemPool::setEntries setAncestors;\n-        size_t nLimitAncestors = gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT);\n-        size_t nLimitAncestorSize = gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000;\n-        size_t nLimitDescendants = gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT);\n-        size_t nLimitDescendantSize = gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000;\n-        std::string errString;\n-        if (!pool.CalculateMemPoolAncestors(entry, setAncestors, nLimitAncestors, nLimitAncestorSize, nLimitDescendants, nLimitDescendantSize, errString)) {\n-            setAncestors.clear();\n-            // If the new transaction is relatively small (up to 40k weight)\n-            // and has at most one ancestor (ie ancestor limit of 2, including\n-            // the new transaction), allow it if its parent has exactly the\n-            // descendant limit descendants.\n-            //\n-            // This allows protocols which rely on distrusting counterparties\n-            // being able to broadcast descendants of an unconfirmed transaction\n-            // to be secure by simply only having two immediately-spendable\n-            // outputs - one for each counterparty. For more info on the uses for\n-            // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n-            if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n-                    !pool.CalculateMemPoolAncestors(entry, setAncestors, 2, nLimitAncestorSize, nLimitDescendants + 1, nLimitDescendantSize + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n-            }\n-        }\n-\n-        // A transaction that spends outputs that would be replaced by it is invalid. Now\n-        // that we have the set of all ancestors we can detect this\n-        // pathological case by making sure setConflicts and setAncestors don't\n-        // intersect.\n-        for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    // Calculate in-mempool ancestors, up to a limit.\n+    std::string errString;\n+    if (!m_pool.CalculateMemPoolAncestors(*entry, setAncestors, m_limit_ancestors, m_limit_ancestor_size, m_limit_descendants, m_limit_descendant_size, errString)) {\n+        setAncestors.clear();\n+        // If the new transaction is relatively small (up to 40k weight)\n+        // and has at most one ancestor (ie ancestor limit of 2, including\n+        // the new transaction), allow it if its parent has exactly the\n+        // descendant limit descendants.\n+        //\n+        // This allows protocols which rely on distrusting counterparties\n+        // being able to broadcast descendants of an unconfirmed transaction\n+        // to be secure by simply only having two immediately-spendable\n+        // outputs - one for each counterparty. For more info on the uses for\n+        // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n+        if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n+                !m_pool.CalculateMemPoolAncestors(*entry, setAncestors, 2, m_limit_ancestor_size, m_limit_descendants + 1, m_limit_descendant_size + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n+        }\n+    }\n+\n+    // A transaction that spends outputs that would be replaced by it is invalid. Now\n+    // that we have the set of all ancestors we can detect this\n+    // pathological case by making sure setConflicts and setAncestors don't\n+    // intersect.\n+    for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    {\n+        const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n+        if (setConflicts.count(hashAncestor))\n         {\n-            const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n-            if (setConflicts.count(hashAncestor))\n-            {\n-                return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n-                                 strprintf(\"%s spends conflicting transaction %s\",\n-                                           hash.ToString(),\n-                                           hashAncestor.ToString()));\n-            }\n+            return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n+                    strprintf(\"%s spends conflicting transaction %s\",\n+                        hash.ToString(),\n+                        hashAncestor.ToString()));\n         }\n+    }\n \n-        // Check if it's economically rational to mine this transaction rather\n-        // than the ones it replaces.\n-        CAmount nConflictingFees = 0;\n-        size_t nConflictingSize = 0;\n-        uint64_t nConflictingCount = 0;\n-        CTxMemPool::setEntries allConflicting;\n-\n-        // If we don't hold the lock allConflicting might be incomplete; the\n-        // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n-        // mempool consistency for us.\n-        const bool fReplacementTransaction = setConflicts.size();\n-        if (fReplacementTransaction)\n-        {\n-            CFeeRate newFeeRate(nModifiedFees, nSize);\n-            std::set<uint256> setConflictsParents;\n-            const int maxDescendantsToVisit = 100;\n-            const CTxMemPool::setEntries setIterConflicting = pool.GetIterSet(setConflicts);\n-            for (const auto& mi : setIterConflicting) {\n-                // Don't allow the replacement to reduce the feerate of the\n-                // mempool.\n-                //\n-                // We usually don't want to accept replacements with lower\n-                // feerates than what they replaced as that would lower the\n-                // feerate of the next block. Requiring that the feerate always\n-                // be increased is also an easy-to-reason about way to prevent\n-                // DoS attacks via replacements.\n-                //\n-                // We only consider the feerates of transactions being directly\n-                // replaced, not their indirect descendants. While that does\n-                // mean high feerate children are ignored when deciding whether\n-                // or not to replace, we do require the replacement to pay more\n-                // overall fees too, mitigating most cases.\n-                CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n-                if (newFeeRate <= oldFeeRate)\n-                {\n-                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                            strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n-                                  hash.ToString(),\n-                                  newFeeRate.ToString(),\n-                                  oldFeeRate.ToString()));\n-                }\n-\n-                for (const CTxIn &txin : mi->GetTx().vin)\n-                {\n-                    setConflictsParents.insert(txin.prevout.hash);\n-                }\n+    // Check if it's economically rational to mine this transaction rather\n+    // than the ones it replaces.\n+    nConflictingFees = 0;\n+    nConflictingSize = 0;\n+    uint64_t nConflictingCount = 0;\n \n-                nConflictingCount += mi->GetCountWithDescendants();\n-            }\n-            // This potentially overestimates the number of actual descendants\n-            // but we just want to be conservative to avoid doing too much\n-            // work.\n-            if (nConflictingCount <= maxDescendantsToVisit) {\n-                // If not too many to replace, then calculate the set of\n-                // transactions that would have to be evicted\n-                for (CTxMemPool::txiter it : setIterConflicting) {\n-                    pool.CalculateDescendants(it, allConflicting);\n-                }\n-                for (CTxMemPool::txiter it : allConflicting) {\n-                    nConflictingFees += it->GetModifiedFee();\n-                    nConflictingSize += it->GetTxSize();\n-                }\n-            } else {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n-                        strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+    // If we don't hold the lock allConflicting might be incomplete; the\n+    // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n+    // mempool consistency for us.\n+    fReplacementTransaction = setConflicts.size();\n+    if (fReplacementTransaction)\n+    {\n+        CFeeRate newFeeRate(nModifiedFees, nSize);\n+        std::set<uint256> setConflictsParents;\n+        const int maxDescendantsToVisit = 100;\n+        const CTxMemPool::setEntries setIterConflicting = m_pool.GetIterSet(setConflicts);\n+        for (const auto& mi : setIterConflicting) {\n+            // Don't allow the replacement to reduce the feerate of the\n+            // mempool.\n+            //\n+            // We usually don't want to accept replacements with lower\n+            // feerates than what they replaced as that would lower the\n+            // feerate of the next block. Requiring that the feerate always\n+            // be increased is also an easy-to-reason about way to prevent\n+            // DoS attacks via replacements.\n+            //\n+            // We only consider the feerates of transactions being directly\n+            // replaced, not their indirect descendants. While that does\n+            // mean high feerate children are ignored when deciding whether\n+            // or not to replace, we do require the replacement to pay more\n+            // overall fees too, mitigating most cases.\n+            CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n+            if (newFeeRate <= oldFeeRate)\n+            {\n+                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                        strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n                             hash.ToString(),\n-                            nConflictingCount,\n-                            maxDescendantsToVisit));\n+                            newFeeRate.ToString(),\n+                            oldFeeRate.ToString()));\n             }\n \n-            for (unsigned int j = 0; j < tx.vin.size(); j++)\n+            for (const CTxIn &txin : mi->GetTx().vin)\n             {\n-                // We don't want to accept replacements that require low\n-                // feerate junk to be mined first. Ideally we'd keep track of\n-                // the ancestor feerates and make the decision based on that,\n-                // but for now requiring all new inputs to be confirmed works.\n-                if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n-                {\n-                    // Rather than check the UTXO set - potentially expensive -\n-                    // it's cheaper to just check if the new input refers to a\n-                    // tx that's in the mempool.\n-                    if (pool.exists(tx.vin[j].prevout.hash)) {\n-                        return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n-                                         strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n-                                                  hash.ToString(), j));\n-                    }\n-                }\n+                setConflictsParents.insert(txin.prevout.hash);\n             }\n \n-            // The replacement must pay greater fees than the transactions it\n-            // replaces - if we did the bandwidth used by those conflicting\n-            // transactions would not be paid for.\n-            if (nModifiedFees < nConflictingFees)\n-            {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                                 strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n-                                          hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n+            nConflictingCount += mi->GetCountWithDescendants();\n+        }\n+        // This potentially overestimates the number of actual descendants\n+        // but we just want to be conservative to avoid doing too much\n+        // work.\n+        if (nConflictingCount <= maxDescendantsToVisit) {\n+            // If not too many to replace, then calculate the set of\n+            // transactions that would have to be evicted\n+            for (CTxMemPool::txiter it : setIterConflicting) {\n+                m_pool.CalculateDescendants(it, allConflicting);\n             }\n+            for (CTxMemPool::txiter it : allConflicting) {\n+                nConflictingFees += it->GetModifiedFee();\n+                nConflictingSize += it->GetTxSize();\n+            }\n+        } else {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n+                    strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+                        hash.ToString(),\n+                        nConflictingCount,\n+                        maxDescendantsToVisit));\n+        }\n \n-            // Finally in addition to paying more fees than the conflicts the\n-            // new transaction must pay for its own bandwidth.\n-            CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n-            if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        for (unsigned int j = 0; j < tx.vin.size(); j++)\n+        {\n+            // We don't want to accept replacements that require low\n+            // feerate junk to be mined first. Ideally we'd keep track of\n+            // the ancestor feerates and make the decision based on that,\n+            // but for now requiring all new inputs to be confirmed works.\n+            if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n             {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                        strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n-                              hash.ToString(),\n-                              FormatMoney(nDeltaFees),\n-                              FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n+                // Rather than check the UTXO set - potentially expensive -\n+                // it's cheaper to just check if the new input refers to a\n+                // tx that's in the mempool.\n+                if (m_pool.exists(tx.vin[j].prevout.hash)) {\n+                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n+                            strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n+                                hash.ToString(), j));\n+                }\n             }\n         }\n \n-        constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n-\n-        // Check against previous transactions\n-        // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n-        PrecomputedTransactionData txdata(tx);\n-        if (!CheckInputs(tx, state, view, true, scriptVerifyFlags, true, false, txdata)) {\n-            // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n-            // need to turn both off, and compare against just turning off CLEANSTACK\n-            // to see if the failure is specifically due to witness validation.\n-            CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n-            if (!tx.HasWitness() && CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n-                !CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n-                // Only the witness is missing, so the transaction itself may be fine.\n-                state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n-                        state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n-            }\n-            assert(IsTransactionReason(state.GetReason()));\n-            return false; // state filled in by CheckInputs\n+        // The replacement must pay greater fees than the transactions it\n+        // replaces - if we did the bandwidth used by those conflicting\n+        // transactions would not be paid for.\n+        if (nModifiedFees < nConflictingFees)\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n+                        hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n         }\n \n-        // Check again against the current block tip's script verification\n-        // flags to cache our script execution flags. This is, of course,\n-        // useless if the next block has different script flags from the\n-        // previous one, but because the cache tracks script flags for us it\n-        // will auto-invalidate and we'll just have a few blocks of extra\n-        // misses on soft-fork activation.\n-        //\n-        // This is also useful in case of bugs in the standard flags that cause\n-        // transactions to pass as valid when they're actually invalid. For\n-        // instance the STRICTENC flag was incorrectly allowing certain\n-        // CHECKSIG NOT scripts to pass, even though they were invalid.\n-        //\n-        // There is a similar check in CreateNewBlock() to prevent creating\n-        // invalid blocks (using TestBlockValidity), however allowing such\n-        // transactions into the mempool can be exploited as a DoS attack.\n-        unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n-        if (!CheckInputsFromMempoolAndCache(tx, state, view, pool, currentBlockScriptVerifyFlags, true, txdata)) {\n-            return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n-                    __func__, hash.ToString(), FormatStateMessage(state));\n+        // Finally in addition to paying more fees than the conflicts the\n+        // new transaction must pay for its own bandwidth.\n+        CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n+        if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n+                        hash.ToString(),\n+                        FormatMoney(nDeltaFees),\n+                        FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n         }\n+    }\n+    return true;\n+}\n \n-        if (test_accept) {\n-            // Tx was accepted, but not added\n-            return true;\n+bool MemPoolAccept::PolicyScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+\n+    CValidationState &state = args.m_state;\n+\n+    constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n+\n+    // Check against previous transactions\n+    // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n+    if (!CheckInputs(tx, state, m_view, true, scriptVerifyFlags, true, false, txdata)) {\n+        // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n+        // need to turn both off, and compare against just turning off CLEANSTACK\n+        // to see if the failure is specifically due to witness validation.\n+        CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n+        if (!tx.HasWitness() && CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n+                !CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n+            // Only the witness is missing, so the transaction itself may be fine.\n+            state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n+                    state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n         }\n+        assert(IsTransactionReason(state.GetReason()));\n+        return false; // state filled in by CheckInputs\n+    }\n \n-        // Remove conflicting transactions from the mempool\n-        for (CTxMemPool::txiter it : allConflicting)\n-        {\n-            LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n-                    it->GetTx().GetHash().ToString(),\n-                    hash.ToString(),\n-                    FormatMoney(nModifiedFees - nConflictingFees),\n-                    (int)nSize - (int)nConflictingSize);\n-            if (plTxnReplaced)\n-                plTxnReplaced->push_back(it->GetSharedTx());\n+    return true;\n+}\n+\n+bool MemPoolAccept::ConsensusScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+\n+    CValidationState &state = args.m_state;\n+    const CChainParams& chainparams = args.m_chainparams;\n+\n+    // Check again against the current block tip's script verification\n+    // flags to cache our script execution flags. This is, of course,\n+    // useless if the next block has different script flags from the\n+    // previous one, but because the cache tracks script flags for us it\n+    // will auto-invalidate and we'll just have a few blocks of extra\n+    // misses on soft-fork activation.\n+    //\n+    // This is also useful in case of bugs in the standard flags that cause\n+    // transactions to pass as valid when they're actually invalid. For\n+    // instance the STRICTENC flag was incorrectly allowing certain\n+    // CHECKSIG NOT scripts to pass, even though they were invalid.\n+    //\n+    // There is a similar check in CreateNewBlock() to prevent creating\n+    // invalid blocks (using TestBlockValidity), however allowing such\n+    // transactions into the mempool can be exploited as a DoS attack.\n+    unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n+    if (!CheckInputsFromMempoolAndCache(tx, state, m_view, m_pool, currentBlockScriptVerifyFlags, true, txdata)) {\n+        return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n+                __func__, hash.ToString(), FormatStateMessage(state));\n+    }\n+\n+    return true;\n+}\n+\n+bool MemPoolAccept::Finalize(ATMPArgs& args, Workspace& ws)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+    CValidationState &state = args.m_state;\n+    const bool bypass_limits = args.m_bypass_limits;\n+\n+    CTxMemPool::setEntries& allConflicting = ws.m_all_conflicting;\n+    CTxMemPool::setEntries& setAncestors = ws.m_ancestors;\n+    const CAmount& nModifiedFees = ws.m_modified_fees;\n+    const CAmount& nConflictingFees = ws.m_conflicting_fees;\n+    const size_t& nConflictingSize = ws.m_conflicting_size;\n+    const bool fReplacementTransaction = ws.m_replacement_transaction;\n+    std::unique_ptr<CTxMemPoolEntry>& entry = ws.m_entry;\n+\n+    // Remove conflicting transactions from the mempool\n+    for (CTxMemPool::txiter it : allConflicting)\n+    {\n+        LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n+                it->GetTx().GetHash().ToString(),\n+                hash.ToString(),\n+                FormatMoney(nModifiedFees - nConflictingFees),\n+                (int)entry->GetTxSize() - (int)nConflictingSize);\n+        if (args.m_replaced_transactions)\n+            args.m_replaced_transactions->push_back(it->GetSharedTx());\n+    }\n+    m_pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+\n+    // This transaction should only count for fee estimation if:\n+    // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n+    // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n+    // - the node is not behind\n+    // - the transaction is not dependent on any other transactions in the mempool\n+    bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && m_pool.HasNoInputsOf(tx);\n+\n+    // Store transaction in memory\n+    m_pool.addUnchecked(*entry, setAncestors, validForFeeEstimation);\n+\n+    // trim mempool and check if tx was trimmed\n+    if (!bypass_limits) {\n+        LimitMempoolSize(m_pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n+        if (!m_pool.exists(hash))\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    }\n+    return true;\n+}\n+\n+bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+\n+    Workspace workspace(ptx);\n+\n+    if (!PreChecks(args, workspace)) return false;\n+\n+    // Only compute the precomputed transaction data if we need to verify\n+    // scripts (ie, other policy checks pass)\n+    PrecomputedTransactionData txdata(*ptx);\n+\n+    if (!PolicyScriptChecks(args, workspace, txdata)) return false;\n+\n+    if (!ConsensusScriptChecks(args, workspace, txdata)) return false;\n+\n+    // Tx was accepted, but not added\n+    if (args.m_test_accept) return true;\n+\n+    if (!Finalize(args, workspace)) return false;\n+\n+    GetMainSignals().TransactionAddedToMempool(ptx);\n+\n+    return true;\n+}\n+\n+\n+bool MemPoolAccept::AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    // We will disable the individual transaction fee-rate checks for all\n+    // parents of the final transaction.\n+    ATMPArgs args_bypass_limits { args.m_chainparams, args.m_state, args.m_missing_inputs, args.m_accept_time, args.m_replaced_transactions, /*m_bypass_limits*/ true, args.m_absurd_fee, args.m_coins_to_uncache, args.m_test_accept };\n+    std::list<Workspace> tx_workspaces;\n+\n+    for (const CTransactionRef& ptx : tx_list) {\n+        tx_workspaces.emplace_back(Workspace(ptx));",
      "path": "src/validation.cpp",
      "position": null,
      "original_position": 864,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": null,
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "adding `Workspace& ws = tx_workspaces.back();` maybe makes this loop a bit tidier?",
      "created_at": "2019-07-25T01:55:34Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r307087452",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307087452"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1015,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307090151",
      "pull_request_review_id": 266360368,
      "id": 307090151,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwNzA5MDE1MQ==",
      "diff_hunk": "@@ -508,348 +628,532 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         }\n     }\n \n-    {\n-        CCoinsView dummy;\n-        CCoinsViewCache view(&dummy);\n-\n-        LockPoints lp;\n-        CCoinsViewMemPool viewMemPool(pcoinsTip.get(), pool);\n-        view.SetBackend(viewMemPool);\n+    LockPoints lp;\n+    m_view.SetBackend(m_viewmempool);\n \n-        // do all inputs exist?\n-        for (const CTxIn& txin : tx.vin) {\n-            if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n-                coins_to_uncache.push_back(txin.prevout);\n-            }\n-\n-            // Note: this call may add txin.prevout to the coins cache\n-            // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n-            // later (via coins_to_uncache) if this tx turns out to be invalid.\n-            if (!view.HaveCoin(txin.prevout)) {\n-                // Are inputs missing because we already have the tx?\n-                for (size_t out = 0; out < tx.vout.size(); out++) {\n-                    // Optimistically just do efficient check of cache for outputs\n-                    if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n-                        return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n-                    }\n-                }\n-                // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n-                if (pfMissingInputs) {\n-                    *pfMissingInputs = true;\n+    // do all inputs exist?\n+    for (const CTxIn& txin : tx.vin) {\n+        if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n+            coins_to_uncache.push_back(txin.prevout);\n+        }\n+\n+        // Note: this call may add txin.prevout to the coins cache\n+        // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n+        // later (via coins_to_uncache) if this tx turns out to be invalid.\n+        if (!m_view.HaveCoin(txin.prevout)) {\n+            // Are inputs missing because we already have the tx?\n+            for (size_t out = 0; out < tx.vout.size(); out++) {\n+                // Optimistically just do efficient check of cache for outputs\n+                if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n+                    return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n                 }\n-                return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n             }\n+            // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n+            if (pfMissingInputs) {\n+                *pfMissingInputs = true;\n+            }\n+            return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n         }\n+    }\n \n-        // Bring the best block into scope\n-        view.GetBestBlock();\n+    // Bring the best block into scope\n+    m_view.GetBestBlock();\n \n-        // we have all inputs cached now, so switch back to dummy, so we don't need to keep lock on mempool\n-        view.SetBackend(dummy);\n+    // we have all inputs cached now, so switch back to dummy (to protect\n+    // against bugs where we pull more inputs from disk that miss being added\n+    // to coins_to_uncache)\n+    m_view.SetBackend(m_dummy);\n \n-        // Only accept BIP68 sequence locked transactions that can be mined in the next\n-        // block; we don't want our mempool filled up with transactions that can't\n-        // be mined yet.\n-        // Must keep pool.cs for this unless we change CheckSequenceLocks to take a\n-        // CoinsViewCache instead of create its own\n-        if (!CheckSequenceLocks(pool, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n-            return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n+    // Only accept BIP68 sequence locked transactions that can be mined in the next\n+    // block; we don't want our mempool filled up with transactions that can't\n+    // be mined yet.\n+    if (!CheckSequenceLocks(m_view, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n+        return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n \n-        CAmount nFees = 0;\n-        if (!Consensus::CheckTxInputs(tx, state, view, GetSpendHeight(view), nFees)) {\n-            return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n-        }\n+    CAmount nFees = 0;\n+    if (!Consensus::CheckTxInputs(tx, state, m_view, GetSpendHeight(m_view), nFees)) {\n+        return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n+    }\n \n-        // Check for non-standard pay-to-script-hash in inputs\n-        if (fRequireStandard && !AreInputsStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n+    // Check for non-standard pay-to-script-hash in inputs\n+    if (fRequireStandard && !AreInputsStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n \n-        // Check for non-standard witness in P2WSH\n-        if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n+    // Check for non-standard witness in P2WSH\n+    if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n \n-        int64_t nSigOpsCost = GetTransactionSigOpCost(tx, view, STANDARD_SCRIPT_VERIFY_FLAGS);\n+    int64_t nSigOpsCost = GetTransactionSigOpCost(tx, m_view, STANDARD_SCRIPT_VERIFY_FLAGS);\n \n-        // nModifiedFees includes any fee deltas from PrioritiseTransaction\n-        CAmount nModifiedFees = nFees;\n-        pool.ApplyDelta(hash, nModifiedFees);\n+    // nModifiedFees includes any fee deltas from PrioritiseTransaction\n+    nModifiedFees = nFees;\n+    m_pool.ApplyDelta(hash, nModifiedFees);\n \n-        // Keep track of transactions that spend a coinbase, which we re-scan\n-        // during reorgs to ensure COINBASE_MATURITY is still met.\n-        bool fSpendsCoinbase = false;\n-        for (const CTxIn &txin : tx.vin) {\n-            const Coin &coin = view.AccessCoin(txin.prevout);\n-            if (coin.IsCoinBase()) {\n-                fSpendsCoinbase = true;\n-                break;\n-            }\n+    // Keep track of transactions that spend a coinbase, which we re-scan\n+    // during reorgs to ensure COINBASE_MATURITY is still met.\n+    bool fSpendsCoinbase = false;\n+    for (const CTxIn &txin : tx.vin) {\n+        const Coin &coin = m_view.AccessCoin(txin.prevout);\n+        if (coin.IsCoinBase()) {\n+            fSpendsCoinbase = true;\n+            break;\n         }\n+    }\n \n-        CTxMemPoolEntry entry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n-                              fSpendsCoinbase, nSigOpsCost, lp);\n-        unsigned int nSize = entry.GetTxSize();\n+    entry.reset(new CTxMemPoolEntry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n+            fSpendsCoinbase, nSigOpsCost, lp));\n+    unsigned int nSize = entry->GetTxSize();\n \n-        if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n+    if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n                 strprintf(\"%d\", nSigOpsCost));\n \n-        CAmount mempoolRejectFee = pool.GetMinFee(gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000).GetFee(nSize);\n-        if (!bypass_limits && mempoolRejectFee > 0 && nModifiedFees < mempoolRejectFee) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool min fee not met\", strprintf(\"%d < %d\", nModifiedFees, mempoolRejectFee));\n-        }\n-\n-        // No transactions are allowed below minRelayTxFee except from disconnected blocks\n-        if (!bypass_limits && nModifiedFees < ::minRelayTxFee.GetFee(nSize)) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"min relay fee not met\", strprintf(\"%d < %d\", nModifiedFees, ::minRelayTxFee.GetFee(nSize)));\n-        }\n+    // No transactions are allowed below minRelayTxFee/mempool min fee except\n+    // from disconnected blocks\n+    if (!bypass_limits && !CheckFeeRate(nSize, nModifiedFees, state)) return false;\n \n-        if (nAbsurdFee && nFees > nAbsurdFee)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n+    if (nAbsurdFee && nFees > nAbsurdFee)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n                 REJECT_HIGHFEE, \"absurdly-high-fee\",\n                 strprintf(\"%d > %d\", nFees, nAbsurdFee));\n \n-        // Calculate in-mempool ancestors, up to a limit.\n-        CTxMemPool::setEntries setAncestors;\n-        size_t nLimitAncestors = gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT);\n-        size_t nLimitAncestorSize = gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000;\n-        size_t nLimitDescendants = gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT);\n-        size_t nLimitDescendantSize = gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000;\n-        std::string errString;\n-        if (!pool.CalculateMemPoolAncestors(entry, setAncestors, nLimitAncestors, nLimitAncestorSize, nLimitDescendants, nLimitDescendantSize, errString)) {\n-            setAncestors.clear();\n-            // If the new transaction is relatively small (up to 40k weight)\n-            // and has at most one ancestor (ie ancestor limit of 2, including\n-            // the new transaction), allow it if its parent has exactly the\n-            // descendant limit descendants.\n-            //\n-            // This allows protocols which rely on distrusting counterparties\n-            // being able to broadcast descendants of an unconfirmed transaction\n-            // to be secure by simply only having two immediately-spendable\n-            // outputs - one for each counterparty. For more info on the uses for\n-            // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n-            if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n-                    !pool.CalculateMemPoolAncestors(entry, setAncestors, 2, nLimitAncestorSize, nLimitDescendants + 1, nLimitDescendantSize + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n-            }\n-        }\n-\n-        // A transaction that spends outputs that would be replaced by it is invalid. Now\n-        // that we have the set of all ancestors we can detect this\n-        // pathological case by making sure setConflicts and setAncestors don't\n-        // intersect.\n-        for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    // Calculate in-mempool ancestors, up to a limit.\n+    std::string errString;\n+    if (!m_pool.CalculateMemPoolAncestors(*entry, setAncestors, m_limit_ancestors, m_limit_ancestor_size, m_limit_descendants, m_limit_descendant_size, errString)) {\n+        setAncestors.clear();\n+        // If the new transaction is relatively small (up to 40k weight)\n+        // and has at most one ancestor (ie ancestor limit of 2, including\n+        // the new transaction), allow it if its parent has exactly the\n+        // descendant limit descendants.\n+        //\n+        // This allows protocols which rely on distrusting counterparties\n+        // being able to broadcast descendants of an unconfirmed transaction\n+        // to be secure by simply only having two immediately-spendable\n+        // outputs - one for each counterparty. For more info on the uses for\n+        // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n+        if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n+                !m_pool.CalculateMemPoolAncestors(*entry, setAncestors, 2, m_limit_ancestor_size, m_limit_descendants + 1, m_limit_descendant_size + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n+        }\n+    }\n+\n+    // A transaction that spends outputs that would be replaced by it is invalid. Now\n+    // that we have the set of all ancestors we can detect this\n+    // pathological case by making sure setConflicts and setAncestors don't\n+    // intersect.\n+    for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    {\n+        const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n+        if (setConflicts.count(hashAncestor))\n         {\n-            const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n-            if (setConflicts.count(hashAncestor))\n-            {\n-                return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n-                                 strprintf(\"%s spends conflicting transaction %s\",\n-                                           hash.ToString(),\n-                                           hashAncestor.ToString()));\n-            }\n+            return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n+                    strprintf(\"%s spends conflicting transaction %s\",\n+                        hash.ToString(),\n+                        hashAncestor.ToString()));\n         }\n+    }\n \n-        // Check if it's economically rational to mine this transaction rather\n-        // than the ones it replaces.\n-        CAmount nConflictingFees = 0;\n-        size_t nConflictingSize = 0;\n-        uint64_t nConflictingCount = 0;\n-        CTxMemPool::setEntries allConflicting;\n-\n-        // If we don't hold the lock allConflicting might be incomplete; the\n-        // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n-        // mempool consistency for us.\n-        const bool fReplacementTransaction = setConflicts.size();\n-        if (fReplacementTransaction)\n-        {\n-            CFeeRate newFeeRate(nModifiedFees, nSize);\n-            std::set<uint256> setConflictsParents;\n-            const int maxDescendantsToVisit = 100;\n-            const CTxMemPool::setEntries setIterConflicting = pool.GetIterSet(setConflicts);\n-            for (const auto& mi : setIterConflicting) {\n-                // Don't allow the replacement to reduce the feerate of the\n-                // mempool.\n-                //\n-                // We usually don't want to accept replacements with lower\n-                // feerates than what they replaced as that would lower the\n-                // feerate of the next block. Requiring that the feerate always\n-                // be increased is also an easy-to-reason about way to prevent\n-                // DoS attacks via replacements.\n-                //\n-                // We only consider the feerates of transactions being directly\n-                // replaced, not their indirect descendants. While that does\n-                // mean high feerate children are ignored when deciding whether\n-                // or not to replace, we do require the replacement to pay more\n-                // overall fees too, mitigating most cases.\n-                CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n-                if (newFeeRate <= oldFeeRate)\n-                {\n-                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                            strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n-                                  hash.ToString(),\n-                                  newFeeRate.ToString(),\n-                                  oldFeeRate.ToString()));\n-                }\n-\n-                for (const CTxIn &txin : mi->GetTx().vin)\n-                {\n-                    setConflictsParents.insert(txin.prevout.hash);\n-                }\n+    // Check if it's economically rational to mine this transaction rather\n+    // than the ones it replaces.\n+    nConflictingFees = 0;\n+    nConflictingSize = 0;\n+    uint64_t nConflictingCount = 0;\n \n-                nConflictingCount += mi->GetCountWithDescendants();\n-            }\n-            // This potentially overestimates the number of actual descendants\n-            // but we just want to be conservative to avoid doing too much\n-            // work.\n-            if (nConflictingCount <= maxDescendantsToVisit) {\n-                // If not too many to replace, then calculate the set of\n-                // transactions that would have to be evicted\n-                for (CTxMemPool::txiter it : setIterConflicting) {\n-                    pool.CalculateDescendants(it, allConflicting);\n-                }\n-                for (CTxMemPool::txiter it : allConflicting) {\n-                    nConflictingFees += it->GetModifiedFee();\n-                    nConflictingSize += it->GetTxSize();\n-                }\n-            } else {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n-                        strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+    // If we don't hold the lock allConflicting might be incomplete; the\n+    // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n+    // mempool consistency for us.\n+    fReplacementTransaction = setConflicts.size();\n+    if (fReplacementTransaction)\n+    {\n+        CFeeRate newFeeRate(nModifiedFees, nSize);\n+        std::set<uint256> setConflictsParents;\n+        const int maxDescendantsToVisit = 100;\n+        const CTxMemPool::setEntries setIterConflicting = m_pool.GetIterSet(setConflicts);\n+        for (const auto& mi : setIterConflicting) {\n+            // Don't allow the replacement to reduce the feerate of the\n+            // mempool.\n+            //\n+            // We usually don't want to accept replacements with lower\n+            // feerates than what they replaced as that would lower the\n+            // feerate of the next block. Requiring that the feerate always\n+            // be increased is also an easy-to-reason about way to prevent\n+            // DoS attacks via replacements.\n+            //\n+            // We only consider the feerates of transactions being directly\n+            // replaced, not their indirect descendants. While that does\n+            // mean high feerate children are ignored when deciding whether\n+            // or not to replace, we do require the replacement to pay more\n+            // overall fees too, mitigating most cases.\n+            CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n+            if (newFeeRate <= oldFeeRate)\n+            {\n+                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                        strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n                             hash.ToString(),\n-                            nConflictingCount,\n-                            maxDescendantsToVisit));\n+                            newFeeRate.ToString(),\n+                            oldFeeRate.ToString()));\n             }\n \n-            for (unsigned int j = 0; j < tx.vin.size(); j++)\n+            for (const CTxIn &txin : mi->GetTx().vin)\n             {\n-                // We don't want to accept replacements that require low\n-                // feerate junk to be mined first. Ideally we'd keep track of\n-                // the ancestor feerates and make the decision based on that,\n-                // but for now requiring all new inputs to be confirmed works.\n-                if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n-                {\n-                    // Rather than check the UTXO set - potentially expensive -\n-                    // it's cheaper to just check if the new input refers to a\n-                    // tx that's in the mempool.\n-                    if (pool.exists(tx.vin[j].prevout.hash)) {\n-                        return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n-                                         strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n-                                                  hash.ToString(), j));\n-                    }\n-                }\n+                setConflictsParents.insert(txin.prevout.hash);\n             }\n \n-            // The replacement must pay greater fees than the transactions it\n-            // replaces - if we did the bandwidth used by those conflicting\n-            // transactions would not be paid for.\n-            if (nModifiedFees < nConflictingFees)\n-            {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                                 strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n-                                          hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n+            nConflictingCount += mi->GetCountWithDescendants();\n+        }\n+        // This potentially overestimates the number of actual descendants\n+        // but we just want to be conservative to avoid doing too much\n+        // work.\n+        if (nConflictingCount <= maxDescendantsToVisit) {\n+            // If not too many to replace, then calculate the set of\n+            // transactions that would have to be evicted\n+            for (CTxMemPool::txiter it : setIterConflicting) {\n+                m_pool.CalculateDescendants(it, allConflicting);\n             }\n+            for (CTxMemPool::txiter it : allConflicting) {\n+                nConflictingFees += it->GetModifiedFee();\n+                nConflictingSize += it->GetTxSize();\n+            }\n+        } else {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n+                    strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+                        hash.ToString(),\n+                        nConflictingCount,\n+                        maxDescendantsToVisit));\n+        }\n \n-            // Finally in addition to paying more fees than the conflicts the\n-            // new transaction must pay for its own bandwidth.\n-            CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n-            if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        for (unsigned int j = 0; j < tx.vin.size(); j++)\n+        {\n+            // We don't want to accept replacements that require low\n+            // feerate junk to be mined first. Ideally we'd keep track of\n+            // the ancestor feerates and make the decision based on that,\n+            // but for now requiring all new inputs to be confirmed works.\n+            if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n             {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                        strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n-                              hash.ToString(),\n-                              FormatMoney(nDeltaFees),\n-                              FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n+                // Rather than check the UTXO set - potentially expensive -\n+                // it's cheaper to just check if the new input refers to a\n+                // tx that's in the mempool.\n+                if (m_pool.exists(tx.vin[j].prevout.hash)) {\n+                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n+                            strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n+                                hash.ToString(), j));\n+                }\n             }\n         }\n \n-        constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n-\n-        // Check against previous transactions\n-        // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n-        PrecomputedTransactionData txdata(tx);\n-        if (!CheckInputs(tx, state, view, true, scriptVerifyFlags, true, false, txdata)) {\n-            // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n-            // need to turn both off, and compare against just turning off CLEANSTACK\n-            // to see if the failure is specifically due to witness validation.\n-            CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n-            if (!tx.HasWitness() && CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n-                !CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n-                // Only the witness is missing, so the transaction itself may be fine.\n-                state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n-                        state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n-            }\n-            assert(IsTransactionReason(state.GetReason()));\n-            return false; // state filled in by CheckInputs\n+        // The replacement must pay greater fees than the transactions it\n+        // replaces - if we did the bandwidth used by those conflicting\n+        // transactions would not be paid for.\n+        if (nModifiedFees < nConflictingFees)\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n+                        hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n         }\n \n-        // Check again against the current block tip's script verification\n-        // flags to cache our script execution flags. This is, of course,\n-        // useless if the next block has different script flags from the\n-        // previous one, but because the cache tracks script flags for us it\n-        // will auto-invalidate and we'll just have a few blocks of extra\n-        // misses on soft-fork activation.\n-        //\n-        // This is also useful in case of bugs in the standard flags that cause\n-        // transactions to pass as valid when they're actually invalid. For\n-        // instance the STRICTENC flag was incorrectly allowing certain\n-        // CHECKSIG NOT scripts to pass, even though they were invalid.\n-        //\n-        // There is a similar check in CreateNewBlock() to prevent creating\n-        // invalid blocks (using TestBlockValidity), however allowing such\n-        // transactions into the mempool can be exploited as a DoS attack.\n-        unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n-        if (!CheckInputsFromMempoolAndCache(tx, state, view, pool, currentBlockScriptVerifyFlags, true, txdata)) {\n-            return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n-                    __func__, hash.ToString(), FormatStateMessage(state));\n+        // Finally in addition to paying more fees than the conflicts the\n+        // new transaction must pay for its own bandwidth.\n+        CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n+        if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n+                        hash.ToString(),\n+                        FormatMoney(nDeltaFees),\n+                        FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n         }\n+    }\n+    return true;\n+}\n \n-        if (test_accept) {\n-            // Tx was accepted, but not added\n-            return true;\n+bool MemPoolAccept::PolicyScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+\n+    CValidationState &state = args.m_state;\n+\n+    constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n+\n+    // Check against previous transactions\n+    // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n+    if (!CheckInputs(tx, state, m_view, true, scriptVerifyFlags, true, false, txdata)) {\n+        // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n+        // need to turn both off, and compare against just turning off CLEANSTACK\n+        // to see if the failure is specifically due to witness validation.\n+        CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n+        if (!tx.HasWitness() && CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n+                !CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n+            // Only the witness is missing, so the transaction itself may be fine.\n+            state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n+                    state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n         }\n+        assert(IsTransactionReason(state.GetReason()));\n+        return false; // state filled in by CheckInputs\n+    }\n \n-        // Remove conflicting transactions from the mempool\n-        for (CTxMemPool::txiter it : allConflicting)\n-        {\n-            LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n-                    it->GetTx().GetHash().ToString(),\n-                    hash.ToString(),\n-                    FormatMoney(nModifiedFees - nConflictingFees),\n-                    (int)nSize - (int)nConflictingSize);\n-            if (plTxnReplaced)\n-                plTxnReplaced->push_back(it->GetSharedTx());\n+    return true;\n+}\n+\n+bool MemPoolAccept::ConsensusScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+\n+    CValidationState &state = args.m_state;\n+    const CChainParams& chainparams = args.m_chainparams;\n+\n+    // Check again against the current block tip's script verification\n+    // flags to cache our script execution flags. This is, of course,\n+    // useless if the next block has different script flags from the\n+    // previous one, but because the cache tracks script flags for us it\n+    // will auto-invalidate and we'll just have a few blocks of extra\n+    // misses on soft-fork activation.\n+    //\n+    // This is also useful in case of bugs in the standard flags that cause\n+    // transactions to pass as valid when they're actually invalid. For\n+    // instance the STRICTENC flag was incorrectly allowing certain\n+    // CHECKSIG NOT scripts to pass, even though they were invalid.\n+    //\n+    // There is a similar check in CreateNewBlock() to prevent creating\n+    // invalid blocks (using TestBlockValidity), however allowing such\n+    // transactions into the mempool can be exploited as a DoS attack.\n+    unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n+    if (!CheckInputsFromMempoolAndCache(tx, state, m_view, m_pool, currentBlockScriptVerifyFlags, true, txdata)) {\n+        return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n+                __func__, hash.ToString(), FormatStateMessage(state));\n+    }\n+\n+    return true;\n+}\n+\n+bool MemPoolAccept::Finalize(ATMPArgs& args, Workspace& ws)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+    CValidationState &state = args.m_state;\n+    const bool bypass_limits = args.m_bypass_limits;\n+\n+    CTxMemPool::setEntries& allConflicting = ws.m_all_conflicting;\n+    CTxMemPool::setEntries& setAncestors = ws.m_ancestors;\n+    const CAmount& nModifiedFees = ws.m_modified_fees;\n+    const CAmount& nConflictingFees = ws.m_conflicting_fees;\n+    const size_t& nConflictingSize = ws.m_conflicting_size;\n+    const bool fReplacementTransaction = ws.m_replacement_transaction;\n+    std::unique_ptr<CTxMemPoolEntry>& entry = ws.m_entry;\n+\n+    // Remove conflicting transactions from the mempool\n+    for (CTxMemPool::txiter it : allConflicting)\n+    {\n+        LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n+                it->GetTx().GetHash().ToString(),\n+                hash.ToString(),\n+                FormatMoney(nModifiedFees - nConflictingFees),\n+                (int)entry->GetTxSize() - (int)nConflictingSize);\n+        if (args.m_replaced_transactions)\n+            args.m_replaced_transactions->push_back(it->GetSharedTx());\n+    }\n+    m_pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+\n+    // This transaction should only count for fee estimation if:\n+    // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n+    // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n+    // - the node is not behind\n+    // - the transaction is not dependent on any other transactions in the mempool\n+    bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && m_pool.HasNoInputsOf(tx);\n+\n+    // Store transaction in memory\n+    m_pool.addUnchecked(*entry, setAncestors, validForFeeEstimation);\n+\n+    // trim mempool and check if tx was trimmed\n+    if (!bypass_limits) {\n+        LimitMempoolSize(m_pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n+        if (!m_pool.exists(hash))\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    }\n+    return true;\n+}\n+\n+bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+\n+    Workspace workspace(ptx);\n+\n+    if (!PreChecks(args, workspace)) return false;\n+\n+    // Only compute the precomputed transaction data if we need to verify\n+    // scripts (ie, other policy checks pass)\n+    PrecomputedTransactionData txdata(*ptx);\n+\n+    if (!PolicyScriptChecks(args, workspace, txdata)) return false;\n+\n+    if (!ConsensusScriptChecks(args, workspace, txdata)) return false;\n+\n+    // Tx was accepted, but not added\n+    if (args.m_test_accept) return true;\n+\n+    if (!Finalize(args, workspace)) return false;\n+\n+    GetMainSignals().TransactionAddedToMempool(ptx);\n+\n+    return true;\n+}\n+\n+\n+bool MemPoolAccept::AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    // We will disable the individual transaction fee-rate checks for all\n+    // parents of the final transaction.\n+    ATMPArgs args_bypass_limits { args.m_chainparams, args.m_state, args.m_missing_inputs, args.m_accept_time, args.m_replaced_transactions, /*m_bypass_limits*/ true, args.m_absurd_fee, args.m_coins_to_uncache, args.m_test_accept };\n+    std::list<Workspace> tx_workspaces;\n+\n+    for (const CTransactionRef& ptx : tx_list) {\n+        tx_workspaces.emplace_back(Workspace(ptx));\n+        // The last transaction must be validated for making it past the fee\n+        // checks on its own, to prevent packages from including low-fee,\n+        // unnecessary children that are attached to higher fee parents.\n+        if (!PreChecks((ptx == tx_list.back() ? args : args_bypass_limits), tx_workspaces.back())) return false;\n+\n+        // For now, do not allow replacements in package transactions. If we\n+        // relax this, we would need to check that no child transaction depends\n+        // on any in-mempool transaction that conflicts with any package\n+        // transaction.\n+        if (!tx_workspaces.back().m_conflicts.empty()) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"rbf-disallowed-in-package\", strprintf(\"mempool conflicts with tx %s\", ptx->GetHash().ToString()));\n         }\n-        pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+        // Add this transaction to our coinsview, so that subsequent\n+        // transactions in this package will have their inputs available.\n+        m_viewmempool.AddPotentialTransaction(ptx);\n+    }\n+\n+    // Check overall package feerate\n+    size_t total_size=0;\n+    CAmount total_fee=0;\n+    uint64_t total_count = tx_list.size();\n+    for (const Workspace& ws : tx_workspaces) {\n+        total_size += ws.m_entry->GetTxSize();\n+        total_fee += ws.m_modified_fees;\n+    }\n+    if (!CheckFeeRate(total_size, total_fee, args.m_state)) return false;\n+\n+    // The ancestor/descendant limit calculations in PreChecks() will be overly\n+    // permissive, because not all ancestors will be known as we descend down\n+    // the package. Thus the ancestor checks done by\n+    // CalculateMemPoolAncestors() will be incomplete. If any ancestor or\n+    // descendant limit is violated in one of those checks, however, we know\n+    // the package will not be accepted when we include all ancestors, as the\n+    // ancestor/descendant size/counts only go up as we add more ancestors to\n+    // each transaction.\n+    // We will end up needing to recalculate setAncestors for each transaction\n+    // prior to calling Finalize, but we should do the correct package-size\n+    // calculations before we call ScriptChecks(), to avoid CPU-DoS.\n \n-        // This transaction should only count for fee estimation if:\n-        // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n-        // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n-        // - the node is not behind\n-        // - the transaction is not dependent on any other transactions in the mempool\n-        bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && pool.HasNoInputsOf(tx);\n+    // For now, do something conservative -- assume that the union of ancestors\n+    // of each transaction is an ancestor of every transaction, for package\n+    // size purposes.\n+    CTxMemPool::setEntries all_ancestors;\n+    for (const Workspace& ws : tx_workspaces) {\n+        all_ancestors.insert(ws.m_ancestors.begin(), ws.m_ancestors.end());\n+    }\n \n-        // Store transaction in memory\n-        pool.addUnchecked(entry, setAncestors, validForFeeEstimation);\n+    if (total_count + all_ancestors.size() > m_limit_ancestors) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor count limit [package: %u limit: %u]\", total_count + all_ancestors.size(), m_limit_ancestors));\n+    }\n \n-        // trim mempool and check if tx was trimmed\n-        if (!bypass_limits) {\n-            LimitMempoolSize(pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n-            if (!pool.exists(hash))\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    // Check the package limits for every ancestor, assuming the whole package\n+    // descends from each.\n+    size_t ancestor_size = total_size;\n+    for (auto tx_iter : all_ancestors) {\n+        if (tx_iter->GetSizeWithDescendants() + total_size > m_limit_descendant_size) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendant_size));\n+        }\n+        if (tx_iter->GetCountWithDescendants() + total_count > m_limit_descendants) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendants));\n         }\n+        ancestor_size += tx_iter->GetTxSize();\n     }\n \n-    GetMainSignals().TransactionAddedToMempool(ptx);\n+    // In case we have no in-mempool ancestors, we must check the transaction\n+    // package itself.\n+    if (total_size > m_limit_descendant_size) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_list.front()->GetHash().ToString(), m_limit_descendant_size));\n+    }\n+    if (ancestor_size > m_limit_ancestor_size) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor size limit for tx %s [limit: %u]\", tx_list.back()->GetHash().ToString(), m_limit_ancestor_size));\n+    }\n \n+    // Make sure all transactions are ancestors of the last one.\n+    // For now, just check that the last transaction has all prior transactions\n+    // as direct inputs. We can relax this in the future for bigger packages.",
      "path": "src/validation.cpp",
      "position": 232,
      "original_position": 955,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": null,
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "This check could be done first, before even setting up the workspaces, as far as I can see.",
      "created_at": "2019-07-25T02:12:17Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r307090151",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307090151"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1132,
      "original_line": 1132,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307090985",
      "pull_request_review_id": 266360368,
      "id": 307090985,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwNzA5MDk4NQ==",
      "diff_hunk": "@@ -508,348 +628,532 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         }\n     }\n \n-    {\n-        CCoinsView dummy;\n-        CCoinsViewCache view(&dummy);\n-\n-        LockPoints lp;\n-        CCoinsViewMemPool viewMemPool(pcoinsTip.get(), pool);\n-        view.SetBackend(viewMemPool);\n+    LockPoints lp;\n+    m_view.SetBackend(m_viewmempool);\n \n-        // do all inputs exist?\n-        for (const CTxIn& txin : tx.vin) {\n-            if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n-                coins_to_uncache.push_back(txin.prevout);\n-            }\n-\n-            // Note: this call may add txin.prevout to the coins cache\n-            // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n-            // later (via coins_to_uncache) if this tx turns out to be invalid.\n-            if (!view.HaveCoin(txin.prevout)) {\n-                // Are inputs missing because we already have the tx?\n-                for (size_t out = 0; out < tx.vout.size(); out++) {\n-                    // Optimistically just do efficient check of cache for outputs\n-                    if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n-                        return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n-                    }\n-                }\n-                // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n-                if (pfMissingInputs) {\n-                    *pfMissingInputs = true;\n+    // do all inputs exist?\n+    for (const CTxIn& txin : tx.vin) {\n+        if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n+            coins_to_uncache.push_back(txin.prevout);\n+        }\n+\n+        // Note: this call may add txin.prevout to the coins cache\n+        // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n+        // later (via coins_to_uncache) if this tx turns out to be invalid.\n+        if (!m_view.HaveCoin(txin.prevout)) {\n+            // Are inputs missing because we already have the tx?\n+            for (size_t out = 0; out < tx.vout.size(); out++) {\n+                // Optimistically just do efficient check of cache for outputs\n+                if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n+                    return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n                 }\n-                return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n             }\n+            // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n+            if (pfMissingInputs) {\n+                *pfMissingInputs = true;\n+            }\n+            return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n         }\n+    }\n \n-        // Bring the best block into scope\n-        view.GetBestBlock();\n+    // Bring the best block into scope\n+    m_view.GetBestBlock();\n \n-        // we have all inputs cached now, so switch back to dummy, so we don't need to keep lock on mempool\n-        view.SetBackend(dummy);\n+    // we have all inputs cached now, so switch back to dummy (to protect\n+    // against bugs where we pull more inputs from disk that miss being added\n+    // to coins_to_uncache)\n+    m_view.SetBackend(m_dummy);\n \n-        // Only accept BIP68 sequence locked transactions that can be mined in the next\n-        // block; we don't want our mempool filled up with transactions that can't\n-        // be mined yet.\n-        // Must keep pool.cs for this unless we change CheckSequenceLocks to take a\n-        // CoinsViewCache instead of create its own\n-        if (!CheckSequenceLocks(pool, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n-            return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n+    // Only accept BIP68 sequence locked transactions that can be mined in the next\n+    // block; we don't want our mempool filled up with transactions that can't\n+    // be mined yet.\n+    if (!CheckSequenceLocks(m_view, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n+        return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n \n-        CAmount nFees = 0;\n-        if (!Consensus::CheckTxInputs(tx, state, view, GetSpendHeight(view), nFees)) {\n-            return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n-        }\n+    CAmount nFees = 0;\n+    if (!Consensus::CheckTxInputs(tx, state, m_view, GetSpendHeight(m_view), nFees)) {\n+        return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n+    }\n \n-        // Check for non-standard pay-to-script-hash in inputs\n-        if (fRequireStandard && !AreInputsStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n+    // Check for non-standard pay-to-script-hash in inputs\n+    if (fRequireStandard && !AreInputsStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n \n-        // Check for non-standard witness in P2WSH\n-        if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n+    // Check for non-standard witness in P2WSH\n+    if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n \n-        int64_t nSigOpsCost = GetTransactionSigOpCost(tx, view, STANDARD_SCRIPT_VERIFY_FLAGS);\n+    int64_t nSigOpsCost = GetTransactionSigOpCost(tx, m_view, STANDARD_SCRIPT_VERIFY_FLAGS);\n \n-        // nModifiedFees includes any fee deltas from PrioritiseTransaction\n-        CAmount nModifiedFees = nFees;\n-        pool.ApplyDelta(hash, nModifiedFees);\n+    // nModifiedFees includes any fee deltas from PrioritiseTransaction\n+    nModifiedFees = nFees;\n+    m_pool.ApplyDelta(hash, nModifiedFees);\n \n-        // Keep track of transactions that spend a coinbase, which we re-scan\n-        // during reorgs to ensure COINBASE_MATURITY is still met.\n-        bool fSpendsCoinbase = false;\n-        for (const CTxIn &txin : tx.vin) {\n-            const Coin &coin = view.AccessCoin(txin.prevout);\n-            if (coin.IsCoinBase()) {\n-                fSpendsCoinbase = true;\n-                break;\n-            }\n+    // Keep track of transactions that spend a coinbase, which we re-scan\n+    // during reorgs to ensure COINBASE_MATURITY is still met.\n+    bool fSpendsCoinbase = false;\n+    for (const CTxIn &txin : tx.vin) {\n+        const Coin &coin = m_view.AccessCoin(txin.prevout);\n+        if (coin.IsCoinBase()) {\n+            fSpendsCoinbase = true;\n+            break;\n         }\n+    }\n \n-        CTxMemPoolEntry entry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n-                              fSpendsCoinbase, nSigOpsCost, lp);\n-        unsigned int nSize = entry.GetTxSize();\n+    entry.reset(new CTxMemPoolEntry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n+            fSpendsCoinbase, nSigOpsCost, lp));\n+    unsigned int nSize = entry->GetTxSize();\n \n-        if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n+    if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n                 strprintf(\"%d\", nSigOpsCost));\n \n-        CAmount mempoolRejectFee = pool.GetMinFee(gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000).GetFee(nSize);\n-        if (!bypass_limits && mempoolRejectFee > 0 && nModifiedFees < mempoolRejectFee) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool min fee not met\", strprintf(\"%d < %d\", nModifiedFees, mempoolRejectFee));\n-        }\n-\n-        // No transactions are allowed below minRelayTxFee except from disconnected blocks\n-        if (!bypass_limits && nModifiedFees < ::minRelayTxFee.GetFee(nSize)) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"min relay fee not met\", strprintf(\"%d < %d\", nModifiedFees, ::minRelayTxFee.GetFee(nSize)));\n-        }\n+    // No transactions are allowed below minRelayTxFee/mempool min fee except\n+    // from disconnected blocks\n+    if (!bypass_limits && !CheckFeeRate(nSize, nModifiedFees, state)) return false;\n \n-        if (nAbsurdFee && nFees > nAbsurdFee)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n+    if (nAbsurdFee && nFees > nAbsurdFee)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n                 REJECT_HIGHFEE, \"absurdly-high-fee\",\n                 strprintf(\"%d > %d\", nFees, nAbsurdFee));\n \n-        // Calculate in-mempool ancestors, up to a limit.\n-        CTxMemPool::setEntries setAncestors;\n-        size_t nLimitAncestors = gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT);\n-        size_t nLimitAncestorSize = gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000;\n-        size_t nLimitDescendants = gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT);\n-        size_t nLimitDescendantSize = gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000;\n-        std::string errString;\n-        if (!pool.CalculateMemPoolAncestors(entry, setAncestors, nLimitAncestors, nLimitAncestorSize, nLimitDescendants, nLimitDescendantSize, errString)) {\n-            setAncestors.clear();\n-            // If the new transaction is relatively small (up to 40k weight)\n-            // and has at most one ancestor (ie ancestor limit of 2, including\n-            // the new transaction), allow it if its parent has exactly the\n-            // descendant limit descendants.\n-            //\n-            // This allows protocols which rely on distrusting counterparties\n-            // being able to broadcast descendants of an unconfirmed transaction\n-            // to be secure by simply only having two immediately-spendable\n-            // outputs - one for each counterparty. For more info on the uses for\n-            // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n-            if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n-                    !pool.CalculateMemPoolAncestors(entry, setAncestors, 2, nLimitAncestorSize, nLimitDescendants + 1, nLimitDescendantSize + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n-            }\n-        }\n-\n-        // A transaction that spends outputs that would be replaced by it is invalid. Now\n-        // that we have the set of all ancestors we can detect this\n-        // pathological case by making sure setConflicts and setAncestors don't\n-        // intersect.\n-        for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    // Calculate in-mempool ancestors, up to a limit.\n+    std::string errString;\n+    if (!m_pool.CalculateMemPoolAncestors(*entry, setAncestors, m_limit_ancestors, m_limit_ancestor_size, m_limit_descendants, m_limit_descendant_size, errString)) {\n+        setAncestors.clear();\n+        // If the new transaction is relatively small (up to 40k weight)\n+        // and has at most one ancestor (ie ancestor limit of 2, including\n+        // the new transaction), allow it if its parent has exactly the\n+        // descendant limit descendants.\n+        //\n+        // This allows protocols which rely on distrusting counterparties\n+        // being able to broadcast descendants of an unconfirmed transaction\n+        // to be secure by simply only having two immediately-spendable\n+        // outputs - one for each counterparty. For more info on the uses for\n+        // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n+        if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n+                !m_pool.CalculateMemPoolAncestors(*entry, setAncestors, 2, m_limit_ancestor_size, m_limit_descendants + 1, m_limit_descendant_size + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n+        }\n+    }\n+\n+    // A transaction that spends outputs that would be replaced by it is invalid. Now\n+    // that we have the set of all ancestors we can detect this\n+    // pathological case by making sure setConflicts and setAncestors don't\n+    // intersect.\n+    for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    {\n+        const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n+        if (setConflicts.count(hashAncestor))\n         {\n-            const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n-            if (setConflicts.count(hashAncestor))\n-            {\n-                return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n-                                 strprintf(\"%s spends conflicting transaction %s\",\n-                                           hash.ToString(),\n-                                           hashAncestor.ToString()));\n-            }\n+            return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n+                    strprintf(\"%s spends conflicting transaction %s\",\n+                        hash.ToString(),\n+                        hashAncestor.ToString()));\n         }\n+    }\n \n-        // Check if it's economically rational to mine this transaction rather\n-        // than the ones it replaces.\n-        CAmount nConflictingFees = 0;\n-        size_t nConflictingSize = 0;\n-        uint64_t nConflictingCount = 0;\n-        CTxMemPool::setEntries allConflicting;\n-\n-        // If we don't hold the lock allConflicting might be incomplete; the\n-        // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n-        // mempool consistency for us.\n-        const bool fReplacementTransaction = setConflicts.size();\n-        if (fReplacementTransaction)\n-        {\n-            CFeeRate newFeeRate(nModifiedFees, nSize);\n-            std::set<uint256> setConflictsParents;\n-            const int maxDescendantsToVisit = 100;\n-            const CTxMemPool::setEntries setIterConflicting = pool.GetIterSet(setConflicts);\n-            for (const auto& mi : setIterConflicting) {\n-                // Don't allow the replacement to reduce the feerate of the\n-                // mempool.\n-                //\n-                // We usually don't want to accept replacements with lower\n-                // feerates than what they replaced as that would lower the\n-                // feerate of the next block. Requiring that the feerate always\n-                // be increased is also an easy-to-reason about way to prevent\n-                // DoS attacks via replacements.\n-                //\n-                // We only consider the feerates of transactions being directly\n-                // replaced, not their indirect descendants. While that does\n-                // mean high feerate children are ignored when deciding whether\n-                // or not to replace, we do require the replacement to pay more\n-                // overall fees too, mitigating most cases.\n-                CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n-                if (newFeeRate <= oldFeeRate)\n-                {\n-                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                            strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n-                                  hash.ToString(),\n-                                  newFeeRate.ToString(),\n-                                  oldFeeRate.ToString()));\n-                }\n-\n-                for (const CTxIn &txin : mi->GetTx().vin)\n-                {\n-                    setConflictsParents.insert(txin.prevout.hash);\n-                }\n+    // Check if it's economically rational to mine this transaction rather\n+    // than the ones it replaces.\n+    nConflictingFees = 0;\n+    nConflictingSize = 0;\n+    uint64_t nConflictingCount = 0;\n \n-                nConflictingCount += mi->GetCountWithDescendants();\n-            }\n-            // This potentially overestimates the number of actual descendants\n-            // but we just want to be conservative to avoid doing too much\n-            // work.\n-            if (nConflictingCount <= maxDescendantsToVisit) {\n-                // If not too many to replace, then calculate the set of\n-                // transactions that would have to be evicted\n-                for (CTxMemPool::txiter it : setIterConflicting) {\n-                    pool.CalculateDescendants(it, allConflicting);\n-                }\n-                for (CTxMemPool::txiter it : allConflicting) {\n-                    nConflictingFees += it->GetModifiedFee();\n-                    nConflictingSize += it->GetTxSize();\n-                }\n-            } else {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n-                        strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+    // If we don't hold the lock allConflicting might be incomplete; the\n+    // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n+    // mempool consistency for us.\n+    fReplacementTransaction = setConflicts.size();\n+    if (fReplacementTransaction)\n+    {\n+        CFeeRate newFeeRate(nModifiedFees, nSize);\n+        std::set<uint256> setConflictsParents;\n+        const int maxDescendantsToVisit = 100;\n+        const CTxMemPool::setEntries setIterConflicting = m_pool.GetIterSet(setConflicts);\n+        for (const auto& mi : setIterConflicting) {\n+            // Don't allow the replacement to reduce the feerate of the\n+            // mempool.\n+            //\n+            // We usually don't want to accept replacements with lower\n+            // feerates than what they replaced as that would lower the\n+            // feerate of the next block. Requiring that the feerate always\n+            // be increased is also an easy-to-reason about way to prevent\n+            // DoS attacks via replacements.\n+            //\n+            // We only consider the feerates of transactions being directly\n+            // replaced, not their indirect descendants. While that does\n+            // mean high feerate children are ignored when deciding whether\n+            // or not to replace, we do require the replacement to pay more\n+            // overall fees too, mitigating most cases.\n+            CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n+            if (newFeeRate <= oldFeeRate)\n+            {\n+                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                        strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n                             hash.ToString(),\n-                            nConflictingCount,\n-                            maxDescendantsToVisit));\n+                            newFeeRate.ToString(),\n+                            oldFeeRate.ToString()));\n             }\n \n-            for (unsigned int j = 0; j < tx.vin.size(); j++)\n+            for (const CTxIn &txin : mi->GetTx().vin)\n             {\n-                // We don't want to accept replacements that require low\n-                // feerate junk to be mined first. Ideally we'd keep track of\n-                // the ancestor feerates and make the decision based on that,\n-                // but for now requiring all new inputs to be confirmed works.\n-                if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n-                {\n-                    // Rather than check the UTXO set - potentially expensive -\n-                    // it's cheaper to just check if the new input refers to a\n-                    // tx that's in the mempool.\n-                    if (pool.exists(tx.vin[j].prevout.hash)) {\n-                        return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n-                                         strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n-                                                  hash.ToString(), j));\n-                    }\n-                }\n+                setConflictsParents.insert(txin.prevout.hash);\n             }\n \n-            // The replacement must pay greater fees than the transactions it\n-            // replaces - if we did the bandwidth used by those conflicting\n-            // transactions would not be paid for.\n-            if (nModifiedFees < nConflictingFees)\n-            {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                                 strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n-                                          hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n+            nConflictingCount += mi->GetCountWithDescendants();\n+        }\n+        // This potentially overestimates the number of actual descendants\n+        // but we just want to be conservative to avoid doing too much\n+        // work.\n+        if (nConflictingCount <= maxDescendantsToVisit) {\n+            // If not too many to replace, then calculate the set of\n+            // transactions that would have to be evicted\n+            for (CTxMemPool::txiter it : setIterConflicting) {\n+                m_pool.CalculateDescendants(it, allConflicting);\n             }\n+            for (CTxMemPool::txiter it : allConflicting) {\n+                nConflictingFees += it->GetModifiedFee();\n+                nConflictingSize += it->GetTxSize();\n+            }\n+        } else {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n+                    strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+                        hash.ToString(),\n+                        nConflictingCount,\n+                        maxDescendantsToVisit));\n+        }\n \n-            // Finally in addition to paying more fees than the conflicts the\n-            // new transaction must pay for its own bandwidth.\n-            CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n-            if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        for (unsigned int j = 0; j < tx.vin.size(); j++)\n+        {\n+            // We don't want to accept replacements that require low\n+            // feerate junk to be mined first. Ideally we'd keep track of\n+            // the ancestor feerates and make the decision based on that,\n+            // but for now requiring all new inputs to be confirmed works.\n+            if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n             {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                        strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n-                              hash.ToString(),\n-                              FormatMoney(nDeltaFees),\n-                              FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n+                // Rather than check the UTXO set - potentially expensive -\n+                // it's cheaper to just check if the new input refers to a\n+                // tx that's in the mempool.\n+                if (m_pool.exists(tx.vin[j].prevout.hash)) {\n+                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n+                            strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n+                                hash.ToString(), j));\n+                }\n             }\n         }\n \n-        constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n-\n-        // Check against previous transactions\n-        // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n-        PrecomputedTransactionData txdata(tx);\n-        if (!CheckInputs(tx, state, view, true, scriptVerifyFlags, true, false, txdata)) {\n-            // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n-            // need to turn both off, and compare against just turning off CLEANSTACK\n-            // to see if the failure is specifically due to witness validation.\n-            CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n-            if (!tx.HasWitness() && CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n-                !CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n-                // Only the witness is missing, so the transaction itself may be fine.\n-                state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n-                        state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n-            }\n-            assert(IsTransactionReason(state.GetReason()));\n-            return false; // state filled in by CheckInputs\n+        // The replacement must pay greater fees than the transactions it\n+        // replaces - if we did the bandwidth used by those conflicting\n+        // transactions would not be paid for.\n+        if (nModifiedFees < nConflictingFees)\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n+                        hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n         }\n \n-        // Check again against the current block tip's script verification\n-        // flags to cache our script execution flags. This is, of course,\n-        // useless if the next block has different script flags from the\n-        // previous one, but because the cache tracks script flags for us it\n-        // will auto-invalidate and we'll just have a few blocks of extra\n-        // misses on soft-fork activation.\n-        //\n-        // This is also useful in case of bugs in the standard flags that cause\n-        // transactions to pass as valid when they're actually invalid. For\n-        // instance the STRICTENC flag was incorrectly allowing certain\n-        // CHECKSIG NOT scripts to pass, even though they were invalid.\n-        //\n-        // There is a similar check in CreateNewBlock() to prevent creating\n-        // invalid blocks (using TestBlockValidity), however allowing such\n-        // transactions into the mempool can be exploited as a DoS attack.\n-        unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n-        if (!CheckInputsFromMempoolAndCache(tx, state, view, pool, currentBlockScriptVerifyFlags, true, txdata)) {\n-            return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n-                    __func__, hash.ToString(), FormatStateMessage(state));\n+        // Finally in addition to paying more fees than the conflicts the\n+        // new transaction must pay for its own bandwidth.\n+        CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n+        if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n+                        hash.ToString(),\n+                        FormatMoney(nDeltaFees),\n+                        FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n         }\n+    }\n+    return true;\n+}\n \n-        if (test_accept) {\n-            // Tx was accepted, but not added\n-            return true;\n+bool MemPoolAccept::PolicyScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+\n+    CValidationState &state = args.m_state;\n+\n+    constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n+\n+    // Check against previous transactions\n+    // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n+    if (!CheckInputs(tx, state, m_view, true, scriptVerifyFlags, true, false, txdata)) {\n+        // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n+        // need to turn both off, and compare against just turning off CLEANSTACK\n+        // to see if the failure is specifically due to witness validation.\n+        CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n+        if (!tx.HasWitness() && CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n+                !CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n+            // Only the witness is missing, so the transaction itself may be fine.\n+            state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n+                    state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n         }\n+        assert(IsTransactionReason(state.GetReason()));\n+        return false; // state filled in by CheckInputs\n+    }\n \n-        // Remove conflicting transactions from the mempool\n-        for (CTxMemPool::txiter it : allConflicting)\n-        {\n-            LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n-                    it->GetTx().GetHash().ToString(),\n-                    hash.ToString(),\n-                    FormatMoney(nModifiedFees - nConflictingFees),\n-                    (int)nSize - (int)nConflictingSize);\n-            if (plTxnReplaced)\n-                plTxnReplaced->push_back(it->GetSharedTx());\n+    return true;\n+}\n+\n+bool MemPoolAccept::ConsensusScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+\n+    CValidationState &state = args.m_state;\n+    const CChainParams& chainparams = args.m_chainparams;\n+\n+    // Check again against the current block tip's script verification\n+    // flags to cache our script execution flags. This is, of course,\n+    // useless if the next block has different script flags from the\n+    // previous one, but because the cache tracks script flags for us it\n+    // will auto-invalidate and we'll just have a few blocks of extra\n+    // misses on soft-fork activation.\n+    //\n+    // This is also useful in case of bugs in the standard flags that cause\n+    // transactions to pass as valid when they're actually invalid. For\n+    // instance the STRICTENC flag was incorrectly allowing certain\n+    // CHECKSIG NOT scripts to pass, even though they were invalid.\n+    //\n+    // There is a similar check in CreateNewBlock() to prevent creating\n+    // invalid blocks (using TestBlockValidity), however allowing such\n+    // transactions into the mempool can be exploited as a DoS attack.\n+    unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n+    if (!CheckInputsFromMempoolAndCache(tx, state, m_view, m_pool, currentBlockScriptVerifyFlags, true, txdata)) {\n+        return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n+                __func__, hash.ToString(), FormatStateMessage(state));\n+    }\n+\n+    return true;\n+}\n+\n+bool MemPoolAccept::Finalize(ATMPArgs& args, Workspace& ws)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+    CValidationState &state = args.m_state;\n+    const bool bypass_limits = args.m_bypass_limits;\n+\n+    CTxMemPool::setEntries& allConflicting = ws.m_all_conflicting;\n+    CTxMemPool::setEntries& setAncestors = ws.m_ancestors;\n+    const CAmount& nModifiedFees = ws.m_modified_fees;\n+    const CAmount& nConflictingFees = ws.m_conflicting_fees;\n+    const size_t& nConflictingSize = ws.m_conflicting_size;\n+    const bool fReplacementTransaction = ws.m_replacement_transaction;\n+    std::unique_ptr<CTxMemPoolEntry>& entry = ws.m_entry;\n+\n+    // Remove conflicting transactions from the mempool\n+    for (CTxMemPool::txiter it : allConflicting)\n+    {\n+        LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n+                it->GetTx().GetHash().ToString(),\n+                hash.ToString(),\n+                FormatMoney(nModifiedFees - nConflictingFees),\n+                (int)entry->GetTxSize() - (int)nConflictingSize);\n+        if (args.m_replaced_transactions)\n+            args.m_replaced_transactions->push_back(it->GetSharedTx());\n+    }\n+    m_pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+\n+    // This transaction should only count for fee estimation if:\n+    // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n+    // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n+    // - the node is not behind\n+    // - the transaction is not dependent on any other transactions in the mempool\n+    bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && m_pool.HasNoInputsOf(tx);\n+\n+    // Store transaction in memory\n+    m_pool.addUnchecked(*entry, setAncestors, validForFeeEstimation);\n+\n+    // trim mempool and check if tx was trimmed\n+    if (!bypass_limits) {\n+        LimitMempoolSize(m_pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n+        if (!m_pool.exists(hash))\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    }\n+    return true;\n+}\n+\n+bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+\n+    Workspace workspace(ptx);\n+\n+    if (!PreChecks(args, workspace)) return false;\n+\n+    // Only compute the precomputed transaction data if we need to verify\n+    // scripts (ie, other policy checks pass)\n+    PrecomputedTransactionData txdata(*ptx);\n+\n+    if (!PolicyScriptChecks(args, workspace, txdata)) return false;\n+\n+    if (!ConsensusScriptChecks(args, workspace, txdata)) return false;\n+\n+    // Tx was accepted, but not added\n+    if (args.m_test_accept) return true;\n+\n+    if (!Finalize(args, workspace)) return false;\n+\n+    GetMainSignals().TransactionAddedToMempool(ptx);\n+\n+    return true;\n+}\n+\n+\n+bool MemPoolAccept::AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    // We will disable the individual transaction fee-rate checks for all\n+    // parents of the final transaction.\n+    ATMPArgs args_bypass_limits { args.m_chainparams, args.m_state, args.m_missing_inputs, args.m_accept_time, args.m_replaced_transactions, /*m_bypass_limits*/ true, args.m_absurd_fee, args.m_coins_to_uncache, args.m_test_accept };\n+    std::list<Workspace> tx_workspaces;\n+\n+    for (const CTransactionRef& ptx : tx_list) {\n+        tx_workspaces.emplace_back(Workspace(ptx));\n+        // The last transaction must be validated for making it past the fee\n+        // checks on its own, to prevent packages from including low-fee,\n+        // unnecessary children that are attached to higher fee parents.\n+        if (!PreChecks((ptx == tx_list.back() ? args : args_bypass_limits), tx_workspaces.back())) return false;\n+\n+        // For now, do not allow replacements in package transactions. If we\n+        // relax this, we would need to check that no child transaction depends\n+        // on any in-mempool transaction that conflicts with any package\n+        // transaction.\n+        if (!tx_workspaces.back().m_conflicts.empty()) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"rbf-disallowed-in-package\", strprintf(\"mempool conflicts with tx %s\", ptx->GetHash().ToString()));\n         }\n-        pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+        // Add this transaction to our coinsview, so that subsequent\n+        // transactions in this package will have their inputs available.\n+        m_viewmempool.AddPotentialTransaction(ptx);\n+    }\n+\n+    // Check overall package feerate\n+    size_t total_size=0;\n+    CAmount total_fee=0;\n+    uint64_t total_count = tx_list.size();\n+    for (const Workspace& ws : tx_workspaces) {\n+        total_size += ws.m_entry->GetTxSize();\n+        total_fee += ws.m_modified_fees;\n+    }\n+    if (!CheckFeeRate(total_size, total_fee, args.m_state)) return false;\n+\n+    // The ancestor/descendant limit calculations in PreChecks() will be overly\n+    // permissive, because not all ancestors will be known as we descend down\n+    // the package. Thus the ancestor checks done by\n+    // CalculateMemPoolAncestors() will be incomplete. If any ancestor or\n+    // descendant limit is violated in one of those checks, however, we know\n+    // the package will not be accepted when we include all ancestors, as the\n+    // ancestor/descendant size/counts only go up as we add more ancestors to\n+    // each transaction.\n+    // We will end up needing to recalculate setAncestors for each transaction\n+    // prior to calling Finalize, but we should do the correct package-size\n+    // calculations before we call ScriptChecks(), to avoid CPU-DoS.\n \n-        // This transaction should only count for fee estimation if:\n-        // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n-        // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n-        // - the node is not behind\n-        // - the transaction is not dependent on any other transactions in the mempool\n-        bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && pool.HasNoInputsOf(tx);\n+    // For now, do something conservative -- assume that the union of ancestors\n+    // of each transaction is an ancestor of every transaction, for package\n+    // size purposes.\n+    CTxMemPool::setEntries all_ancestors;\n+    for (const Workspace& ws : tx_workspaces) {\n+        all_ancestors.insert(ws.m_ancestors.begin(), ws.m_ancestors.end());\n+    }\n \n-        // Store transaction in memory\n-        pool.addUnchecked(entry, setAncestors, validForFeeEstimation);\n+    if (total_count + all_ancestors.size() > m_limit_ancestors) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor count limit [package: %u limit: %u]\", total_count + all_ancestors.size(), m_limit_ancestors));\n+    }\n \n-        // trim mempool and check if tx was trimmed\n-        if (!bypass_limits) {\n-            LimitMempoolSize(pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n-            if (!pool.exists(hash))\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    // Check the package limits for every ancestor, assuming the whole package\n+    // descends from each.\n+    size_t ancestor_size = total_size;\n+    for (auto tx_iter : all_ancestors) {\n+        if (tx_iter->GetSizeWithDescendants() + total_size > m_limit_descendant_size) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendant_size));\n+        }\n+        if (tx_iter->GetCountWithDescendants() + total_count > m_limit_descendants) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendants));\n         }\n+        ancestor_size += tx_iter->GetTxSize();\n     }\n \n-    GetMainSignals().TransactionAddedToMempool(ptx);\n+    // In case we have no in-mempool ancestors, we must check the transaction\n+    // package itself.\n+    if (total_size > m_limit_descendant_size) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_list.front()->GetHash().ToString(), m_limit_descendant_size));\n+    }\n+    if (ancestor_size > m_limit_ancestor_size) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor size limit for tx %s [limit: %u]\", tx_list.back()->GetHash().ToString(), m_limit_ancestor_size));\n+    }\n \n+    // Make sure all transactions are ancestors of the last one.\n+    // For now, just check that the last transaction has all prior transactions\n+    // as direct inputs. We can relax this in the future for bigger packages.\n+    std::set<uint256> last_tx_parents;\n+    for (auto input : tx_list.back()->vin) {\n+        last_tx_parents.insert(input.prevout.hash);\n+    }\n+    for (auto ptx : tx_list) {\n+        if (ptx == tx_list.back()) break;\n+        if (last_tx_parents.count(ptx->GetHash()) == 0) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"non-standard-package-chain\", \"only direct parents are allowed in package\");\n+        }\n+    }\n+\n+    // Do the script checks after all policy checks are done\n+    std::vector<PrecomputedTransactionData> txdata;\n+    txdata.reserve(tx_list.size());\n+    for (auto wit = tx_workspaces.begin(); wit != tx_workspaces.end(); ++wit) {\n+        txdata.emplace_back(*wit->m_ptx);\n+        // We can just use the same ATMPArgs for each invocation, as\n+        // PolicyScriptChecks() ignores bypass_limits.\n+        if (!PolicyScriptChecks(args, *wit, txdata.back())) return false;\n+    }\n+\n+    // This package should be accepted except possibly for failing in\n+    // TrimToSize(), which we can't exercise without actually adding to the\n+    // mempool and seeing what would happen. Note that we are not adding\n+    // these transactions to the script cache, unlike in the single-tx case.\n+    if (args.m_test_accept) return true;\n+\n+    // Add everything to the mempool, and make sure the last transaction makes\n+    // it in.\n+    size_t i=0;\n+    for (auto wit = tx_workspaces.begin(); wit != tx_workspaces.end(); ++wit, ++i) {\n+        // Recheck the scripts with consensus flags and cache script execution\n+        // success. We have to wait until all the inputs are in the mempool or\n+        // in the utxo set (for now) before we can invoke this. This should\n+        // not fail unless there's a logic bug in our script validation, but if\n+        // it somehow were to fail on some child tx, we would potentially be\n+        // allowing parents into the mempool with this logic.\n+        if (!ConsensusScriptChecks(args, *wit, txdata[i])) return false;",
      "path": "src/validation.cpp",
      "position": 268,
      "original_position": 993,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": null,
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "This seems like it would be a good case for the `CHECK` macro from #16136 (if it logged failures, anyway)...",
      "created_at": "2019-07-25T02:17:43Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r307090985",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307090985"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1168,
      "original_line": 1168,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307091065",
      "pull_request_review_id": 266360368,
      "id": 307091065,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwNzA5MTA2NQ==",
      "diff_hunk": "@@ -508,348 +628,532 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         }\n     }\n \n-    {\n-        CCoinsView dummy;\n-        CCoinsViewCache view(&dummy);\n-\n-        LockPoints lp;\n-        CCoinsViewMemPool viewMemPool(pcoinsTip.get(), pool);\n-        view.SetBackend(viewMemPool);\n+    LockPoints lp;\n+    m_view.SetBackend(m_viewmempool);\n \n-        // do all inputs exist?\n-        for (const CTxIn& txin : tx.vin) {\n-            if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n-                coins_to_uncache.push_back(txin.prevout);\n-            }\n-\n-            // Note: this call may add txin.prevout to the coins cache\n-            // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n-            // later (via coins_to_uncache) if this tx turns out to be invalid.\n-            if (!view.HaveCoin(txin.prevout)) {\n-                // Are inputs missing because we already have the tx?\n-                for (size_t out = 0; out < tx.vout.size(); out++) {\n-                    // Optimistically just do efficient check of cache for outputs\n-                    if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n-                        return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n-                    }\n-                }\n-                // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n-                if (pfMissingInputs) {\n-                    *pfMissingInputs = true;\n+    // do all inputs exist?\n+    for (const CTxIn& txin : tx.vin) {\n+        if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n+            coins_to_uncache.push_back(txin.prevout);\n+        }\n+\n+        // Note: this call may add txin.prevout to the coins cache\n+        // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n+        // later (via coins_to_uncache) if this tx turns out to be invalid.\n+        if (!m_view.HaveCoin(txin.prevout)) {\n+            // Are inputs missing because we already have the tx?\n+            for (size_t out = 0; out < tx.vout.size(); out++) {\n+                // Optimistically just do efficient check of cache for outputs\n+                if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n+                    return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n                 }\n-                return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n             }\n+            // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n+            if (pfMissingInputs) {\n+                *pfMissingInputs = true;\n+            }\n+            return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n         }\n+    }\n \n-        // Bring the best block into scope\n-        view.GetBestBlock();\n+    // Bring the best block into scope\n+    m_view.GetBestBlock();\n \n-        // we have all inputs cached now, so switch back to dummy, so we don't need to keep lock on mempool\n-        view.SetBackend(dummy);\n+    // we have all inputs cached now, so switch back to dummy (to protect\n+    // against bugs where we pull more inputs from disk that miss being added\n+    // to coins_to_uncache)\n+    m_view.SetBackend(m_dummy);\n \n-        // Only accept BIP68 sequence locked transactions that can be mined in the next\n-        // block; we don't want our mempool filled up with transactions that can't\n-        // be mined yet.\n-        // Must keep pool.cs for this unless we change CheckSequenceLocks to take a\n-        // CoinsViewCache instead of create its own\n-        if (!CheckSequenceLocks(pool, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n-            return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n+    // Only accept BIP68 sequence locked transactions that can be mined in the next\n+    // block; we don't want our mempool filled up with transactions that can't\n+    // be mined yet.\n+    if (!CheckSequenceLocks(m_view, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n+        return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n \n-        CAmount nFees = 0;\n-        if (!Consensus::CheckTxInputs(tx, state, view, GetSpendHeight(view), nFees)) {\n-            return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n-        }\n+    CAmount nFees = 0;\n+    if (!Consensus::CheckTxInputs(tx, state, m_view, GetSpendHeight(m_view), nFees)) {\n+        return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n+    }\n \n-        // Check for non-standard pay-to-script-hash in inputs\n-        if (fRequireStandard && !AreInputsStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n+    // Check for non-standard pay-to-script-hash in inputs\n+    if (fRequireStandard && !AreInputsStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n \n-        // Check for non-standard witness in P2WSH\n-        if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n+    // Check for non-standard witness in P2WSH\n+    if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n \n-        int64_t nSigOpsCost = GetTransactionSigOpCost(tx, view, STANDARD_SCRIPT_VERIFY_FLAGS);\n+    int64_t nSigOpsCost = GetTransactionSigOpCost(tx, m_view, STANDARD_SCRIPT_VERIFY_FLAGS);\n \n-        // nModifiedFees includes any fee deltas from PrioritiseTransaction\n-        CAmount nModifiedFees = nFees;\n-        pool.ApplyDelta(hash, nModifiedFees);\n+    // nModifiedFees includes any fee deltas from PrioritiseTransaction\n+    nModifiedFees = nFees;\n+    m_pool.ApplyDelta(hash, nModifiedFees);\n \n-        // Keep track of transactions that spend a coinbase, which we re-scan\n-        // during reorgs to ensure COINBASE_MATURITY is still met.\n-        bool fSpendsCoinbase = false;\n-        for (const CTxIn &txin : tx.vin) {\n-            const Coin &coin = view.AccessCoin(txin.prevout);\n-            if (coin.IsCoinBase()) {\n-                fSpendsCoinbase = true;\n-                break;\n-            }\n+    // Keep track of transactions that spend a coinbase, which we re-scan\n+    // during reorgs to ensure COINBASE_MATURITY is still met.\n+    bool fSpendsCoinbase = false;\n+    for (const CTxIn &txin : tx.vin) {\n+        const Coin &coin = m_view.AccessCoin(txin.prevout);\n+        if (coin.IsCoinBase()) {\n+            fSpendsCoinbase = true;\n+            break;\n         }\n+    }\n \n-        CTxMemPoolEntry entry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n-                              fSpendsCoinbase, nSigOpsCost, lp);\n-        unsigned int nSize = entry.GetTxSize();\n+    entry.reset(new CTxMemPoolEntry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n+            fSpendsCoinbase, nSigOpsCost, lp));\n+    unsigned int nSize = entry->GetTxSize();\n \n-        if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n+    if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n                 strprintf(\"%d\", nSigOpsCost));\n \n-        CAmount mempoolRejectFee = pool.GetMinFee(gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000).GetFee(nSize);\n-        if (!bypass_limits && mempoolRejectFee > 0 && nModifiedFees < mempoolRejectFee) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool min fee not met\", strprintf(\"%d < %d\", nModifiedFees, mempoolRejectFee));\n-        }\n-\n-        // No transactions are allowed below minRelayTxFee except from disconnected blocks\n-        if (!bypass_limits && nModifiedFees < ::minRelayTxFee.GetFee(nSize)) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"min relay fee not met\", strprintf(\"%d < %d\", nModifiedFees, ::minRelayTxFee.GetFee(nSize)));\n-        }\n+    // No transactions are allowed below minRelayTxFee/mempool min fee except\n+    // from disconnected blocks\n+    if (!bypass_limits && !CheckFeeRate(nSize, nModifiedFees, state)) return false;\n \n-        if (nAbsurdFee && nFees > nAbsurdFee)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n+    if (nAbsurdFee && nFees > nAbsurdFee)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n                 REJECT_HIGHFEE, \"absurdly-high-fee\",\n                 strprintf(\"%d > %d\", nFees, nAbsurdFee));\n \n-        // Calculate in-mempool ancestors, up to a limit.\n-        CTxMemPool::setEntries setAncestors;\n-        size_t nLimitAncestors = gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT);\n-        size_t nLimitAncestorSize = gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000;\n-        size_t nLimitDescendants = gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT);\n-        size_t nLimitDescendantSize = gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000;\n-        std::string errString;\n-        if (!pool.CalculateMemPoolAncestors(entry, setAncestors, nLimitAncestors, nLimitAncestorSize, nLimitDescendants, nLimitDescendantSize, errString)) {\n-            setAncestors.clear();\n-            // If the new transaction is relatively small (up to 40k weight)\n-            // and has at most one ancestor (ie ancestor limit of 2, including\n-            // the new transaction), allow it if its parent has exactly the\n-            // descendant limit descendants.\n-            //\n-            // This allows protocols which rely on distrusting counterparties\n-            // being able to broadcast descendants of an unconfirmed transaction\n-            // to be secure by simply only having two immediately-spendable\n-            // outputs - one for each counterparty. For more info on the uses for\n-            // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n-            if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n-                    !pool.CalculateMemPoolAncestors(entry, setAncestors, 2, nLimitAncestorSize, nLimitDescendants + 1, nLimitDescendantSize + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n-            }\n-        }\n-\n-        // A transaction that spends outputs that would be replaced by it is invalid. Now\n-        // that we have the set of all ancestors we can detect this\n-        // pathological case by making sure setConflicts and setAncestors don't\n-        // intersect.\n-        for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    // Calculate in-mempool ancestors, up to a limit.\n+    std::string errString;\n+    if (!m_pool.CalculateMemPoolAncestors(*entry, setAncestors, m_limit_ancestors, m_limit_ancestor_size, m_limit_descendants, m_limit_descendant_size, errString)) {\n+        setAncestors.clear();\n+        // If the new transaction is relatively small (up to 40k weight)\n+        // and has at most one ancestor (ie ancestor limit of 2, including\n+        // the new transaction), allow it if its parent has exactly the\n+        // descendant limit descendants.\n+        //\n+        // This allows protocols which rely on distrusting counterparties\n+        // being able to broadcast descendants of an unconfirmed transaction\n+        // to be secure by simply only having two immediately-spendable\n+        // outputs - one for each counterparty. For more info on the uses for\n+        // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n+        if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n+                !m_pool.CalculateMemPoolAncestors(*entry, setAncestors, 2, m_limit_ancestor_size, m_limit_descendants + 1, m_limit_descendant_size + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n+        }\n+    }\n+\n+    // A transaction that spends outputs that would be replaced by it is invalid. Now\n+    // that we have the set of all ancestors we can detect this\n+    // pathological case by making sure setConflicts and setAncestors don't\n+    // intersect.\n+    for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    {\n+        const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n+        if (setConflicts.count(hashAncestor))\n         {\n-            const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n-            if (setConflicts.count(hashAncestor))\n-            {\n-                return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n-                                 strprintf(\"%s spends conflicting transaction %s\",\n-                                           hash.ToString(),\n-                                           hashAncestor.ToString()));\n-            }\n+            return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n+                    strprintf(\"%s spends conflicting transaction %s\",\n+                        hash.ToString(),\n+                        hashAncestor.ToString()));\n         }\n+    }\n \n-        // Check if it's economically rational to mine this transaction rather\n-        // than the ones it replaces.\n-        CAmount nConflictingFees = 0;\n-        size_t nConflictingSize = 0;\n-        uint64_t nConflictingCount = 0;\n-        CTxMemPool::setEntries allConflicting;\n-\n-        // If we don't hold the lock allConflicting might be incomplete; the\n-        // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n-        // mempool consistency for us.\n-        const bool fReplacementTransaction = setConflicts.size();\n-        if (fReplacementTransaction)\n-        {\n-            CFeeRate newFeeRate(nModifiedFees, nSize);\n-            std::set<uint256> setConflictsParents;\n-            const int maxDescendantsToVisit = 100;\n-            const CTxMemPool::setEntries setIterConflicting = pool.GetIterSet(setConflicts);\n-            for (const auto& mi : setIterConflicting) {\n-                // Don't allow the replacement to reduce the feerate of the\n-                // mempool.\n-                //\n-                // We usually don't want to accept replacements with lower\n-                // feerates than what they replaced as that would lower the\n-                // feerate of the next block. Requiring that the feerate always\n-                // be increased is also an easy-to-reason about way to prevent\n-                // DoS attacks via replacements.\n-                //\n-                // We only consider the feerates of transactions being directly\n-                // replaced, not their indirect descendants. While that does\n-                // mean high feerate children are ignored when deciding whether\n-                // or not to replace, we do require the replacement to pay more\n-                // overall fees too, mitigating most cases.\n-                CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n-                if (newFeeRate <= oldFeeRate)\n-                {\n-                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                            strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n-                                  hash.ToString(),\n-                                  newFeeRate.ToString(),\n-                                  oldFeeRate.ToString()));\n-                }\n-\n-                for (const CTxIn &txin : mi->GetTx().vin)\n-                {\n-                    setConflictsParents.insert(txin.prevout.hash);\n-                }\n+    // Check if it's economically rational to mine this transaction rather\n+    // than the ones it replaces.\n+    nConflictingFees = 0;\n+    nConflictingSize = 0;\n+    uint64_t nConflictingCount = 0;\n \n-                nConflictingCount += mi->GetCountWithDescendants();\n-            }\n-            // This potentially overestimates the number of actual descendants\n-            // but we just want to be conservative to avoid doing too much\n-            // work.\n-            if (nConflictingCount <= maxDescendantsToVisit) {\n-                // If not too many to replace, then calculate the set of\n-                // transactions that would have to be evicted\n-                for (CTxMemPool::txiter it : setIterConflicting) {\n-                    pool.CalculateDescendants(it, allConflicting);\n-                }\n-                for (CTxMemPool::txiter it : allConflicting) {\n-                    nConflictingFees += it->GetModifiedFee();\n-                    nConflictingSize += it->GetTxSize();\n-                }\n-            } else {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n-                        strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+    // If we don't hold the lock allConflicting might be incomplete; the\n+    // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n+    // mempool consistency for us.\n+    fReplacementTransaction = setConflicts.size();\n+    if (fReplacementTransaction)\n+    {\n+        CFeeRate newFeeRate(nModifiedFees, nSize);\n+        std::set<uint256> setConflictsParents;\n+        const int maxDescendantsToVisit = 100;\n+        const CTxMemPool::setEntries setIterConflicting = m_pool.GetIterSet(setConflicts);\n+        for (const auto& mi : setIterConflicting) {\n+            // Don't allow the replacement to reduce the feerate of the\n+            // mempool.\n+            //\n+            // We usually don't want to accept replacements with lower\n+            // feerates than what they replaced as that would lower the\n+            // feerate of the next block. Requiring that the feerate always\n+            // be increased is also an easy-to-reason about way to prevent\n+            // DoS attacks via replacements.\n+            //\n+            // We only consider the feerates of transactions being directly\n+            // replaced, not their indirect descendants. While that does\n+            // mean high feerate children are ignored when deciding whether\n+            // or not to replace, we do require the replacement to pay more\n+            // overall fees too, mitigating most cases.\n+            CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n+            if (newFeeRate <= oldFeeRate)\n+            {\n+                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                        strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n                             hash.ToString(),\n-                            nConflictingCount,\n-                            maxDescendantsToVisit));\n+                            newFeeRate.ToString(),\n+                            oldFeeRate.ToString()));\n             }\n \n-            for (unsigned int j = 0; j < tx.vin.size(); j++)\n+            for (const CTxIn &txin : mi->GetTx().vin)\n             {\n-                // We don't want to accept replacements that require low\n-                // feerate junk to be mined first. Ideally we'd keep track of\n-                // the ancestor feerates and make the decision based on that,\n-                // but for now requiring all new inputs to be confirmed works.\n-                if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n-                {\n-                    // Rather than check the UTXO set - potentially expensive -\n-                    // it's cheaper to just check if the new input refers to a\n-                    // tx that's in the mempool.\n-                    if (pool.exists(tx.vin[j].prevout.hash)) {\n-                        return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n-                                         strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n-                                                  hash.ToString(), j));\n-                    }\n-                }\n+                setConflictsParents.insert(txin.prevout.hash);\n             }\n \n-            // The replacement must pay greater fees than the transactions it\n-            // replaces - if we did the bandwidth used by those conflicting\n-            // transactions would not be paid for.\n-            if (nModifiedFees < nConflictingFees)\n-            {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                                 strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n-                                          hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n+            nConflictingCount += mi->GetCountWithDescendants();\n+        }\n+        // This potentially overestimates the number of actual descendants\n+        // but we just want to be conservative to avoid doing too much\n+        // work.\n+        if (nConflictingCount <= maxDescendantsToVisit) {\n+            // If not too many to replace, then calculate the set of\n+            // transactions that would have to be evicted\n+            for (CTxMemPool::txiter it : setIterConflicting) {\n+                m_pool.CalculateDescendants(it, allConflicting);\n             }\n+            for (CTxMemPool::txiter it : allConflicting) {\n+                nConflictingFees += it->GetModifiedFee();\n+                nConflictingSize += it->GetTxSize();\n+            }\n+        } else {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n+                    strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+                        hash.ToString(),\n+                        nConflictingCount,\n+                        maxDescendantsToVisit));\n+        }\n \n-            // Finally in addition to paying more fees than the conflicts the\n-            // new transaction must pay for its own bandwidth.\n-            CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n-            if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        for (unsigned int j = 0; j < tx.vin.size(); j++)\n+        {\n+            // We don't want to accept replacements that require low\n+            // feerate junk to be mined first. Ideally we'd keep track of\n+            // the ancestor feerates and make the decision based on that,\n+            // but for now requiring all new inputs to be confirmed works.\n+            if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n             {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                        strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n-                              hash.ToString(),\n-                              FormatMoney(nDeltaFees),\n-                              FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n+                // Rather than check the UTXO set - potentially expensive -\n+                // it's cheaper to just check if the new input refers to a\n+                // tx that's in the mempool.\n+                if (m_pool.exists(tx.vin[j].prevout.hash)) {\n+                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n+                            strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n+                                hash.ToString(), j));\n+                }\n             }\n         }\n \n-        constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n-\n-        // Check against previous transactions\n-        // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n-        PrecomputedTransactionData txdata(tx);\n-        if (!CheckInputs(tx, state, view, true, scriptVerifyFlags, true, false, txdata)) {\n-            // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n-            // need to turn both off, and compare against just turning off CLEANSTACK\n-            // to see if the failure is specifically due to witness validation.\n-            CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n-            if (!tx.HasWitness() && CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n-                !CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n-                // Only the witness is missing, so the transaction itself may be fine.\n-                state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n-                        state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n-            }\n-            assert(IsTransactionReason(state.GetReason()));\n-            return false; // state filled in by CheckInputs\n+        // The replacement must pay greater fees than the transactions it\n+        // replaces - if we did the bandwidth used by those conflicting\n+        // transactions would not be paid for.\n+        if (nModifiedFees < nConflictingFees)\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n+                        hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n         }\n \n-        // Check again against the current block tip's script verification\n-        // flags to cache our script execution flags. This is, of course,\n-        // useless if the next block has different script flags from the\n-        // previous one, but because the cache tracks script flags for us it\n-        // will auto-invalidate and we'll just have a few blocks of extra\n-        // misses on soft-fork activation.\n-        //\n-        // This is also useful in case of bugs in the standard flags that cause\n-        // transactions to pass as valid when they're actually invalid. For\n-        // instance the STRICTENC flag was incorrectly allowing certain\n-        // CHECKSIG NOT scripts to pass, even though they were invalid.\n-        //\n-        // There is a similar check in CreateNewBlock() to prevent creating\n-        // invalid blocks (using TestBlockValidity), however allowing such\n-        // transactions into the mempool can be exploited as a DoS attack.\n-        unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n-        if (!CheckInputsFromMempoolAndCache(tx, state, view, pool, currentBlockScriptVerifyFlags, true, txdata)) {\n-            return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n-                    __func__, hash.ToString(), FormatStateMessage(state));\n+        // Finally in addition to paying more fees than the conflicts the\n+        // new transaction must pay for its own bandwidth.\n+        CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n+        if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n+                        hash.ToString(),\n+                        FormatMoney(nDeltaFees),\n+                        FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n         }\n+    }\n+    return true;\n+}\n \n-        if (test_accept) {\n-            // Tx was accepted, but not added\n-            return true;\n+bool MemPoolAccept::PolicyScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+\n+    CValidationState &state = args.m_state;\n+\n+    constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n+\n+    // Check against previous transactions\n+    // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n+    if (!CheckInputs(tx, state, m_view, true, scriptVerifyFlags, true, false, txdata)) {\n+        // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n+        // need to turn both off, and compare against just turning off CLEANSTACK\n+        // to see if the failure is specifically due to witness validation.\n+        CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n+        if (!tx.HasWitness() && CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n+                !CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n+            // Only the witness is missing, so the transaction itself may be fine.\n+            state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n+                    state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n         }\n+        assert(IsTransactionReason(state.GetReason()));\n+        return false; // state filled in by CheckInputs\n+    }\n \n-        // Remove conflicting transactions from the mempool\n-        for (CTxMemPool::txiter it : allConflicting)\n-        {\n-            LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n-                    it->GetTx().GetHash().ToString(),\n-                    hash.ToString(),\n-                    FormatMoney(nModifiedFees - nConflictingFees),\n-                    (int)nSize - (int)nConflictingSize);\n-            if (plTxnReplaced)\n-                plTxnReplaced->push_back(it->GetSharedTx());\n+    return true;\n+}\n+\n+bool MemPoolAccept::ConsensusScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+\n+    CValidationState &state = args.m_state;\n+    const CChainParams& chainparams = args.m_chainparams;\n+\n+    // Check again against the current block tip's script verification\n+    // flags to cache our script execution flags. This is, of course,\n+    // useless if the next block has different script flags from the\n+    // previous one, but because the cache tracks script flags for us it\n+    // will auto-invalidate and we'll just have a few blocks of extra\n+    // misses on soft-fork activation.\n+    //\n+    // This is also useful in case of bugs in the standard flags that cause\n+    // transactions to pass as valid when they're actually invalid. For\n+    // instance the STRICTENC flag was incorrectly allowing certain\n+    // CHECKSIG NOT scripts to pass, even though they were invalid.\n+    //\n+    // There is a similar check in CreateNewBlock() to prevent creating\n+    // invalid blocks (using TestBlockValidity), however allowing such\n+    // transactions into the mempool can be exploited as a DoS attack.\n+    unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n+    if (!CheckInputsFromMempoolAndCache(tx, state, m_view, m_pool, currentBlockScriptVerifyFlags, true, txdata)) {\n+        return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n+                __func__, hash.ToString(), FormatStateMessage(state));\n+    }\n+\n+    return true;\n+}\n+\n+bool MemPoolAccept::Finalize(ATMPArgs& args, Workspace& ws)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+    CValidationState &state = args.m_state;\n+    const bool bypass_limits = args.m_bypass_limits;\n+\n+    CTxMemPool::setEntries& allConflicting = ws.m_all_conflicting;\n+    CTxMemPool::setEntries& setAncestors = ws.m_ancestors;\n+    const CAmount& nModifiedFees = ws.m_modified_fees;\n+    const CAmount& nConflictingFees = ws.m_conflicting_fees;\n+    const size_t& nConflictingSize = ws.m_conflicting_size;\n+    const bool fReplacementTransaction = ws.m_replacement_transaction;\n+    std::unique_ptr<CTxMemPoolEntry>& entry = ws.m_entry;\n+\n+    // Remove conflicting transactions from the mempool\n+    for (CTxMemPool::txiter it : allConflicting)\n+    {\n+        LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n+                it->GetTx().GetHash().ToString(),\n+                hash.ToString(),\n+                FormatMoney(nModifiedFees - nConflictingFees),\n+                (int)entry->GetTxSize() - (int)nConflictingSize);\n+        if (args.m_replaced_transactions)\n+            args.m_replaced_transactions->push_back(it->GetSharedTx());\n+    }\n+    m_pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+\n+    // This transaction should only count for fee estimation if:\n+    // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n+    // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n+    // - the node is not behind\n+    // - the transaction is not dependent on any other transactions in the mempool\n+    bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && m_pool.HasNoInputsOf(tx);\n+\n+    // Store transaction in memory\n+    m_pool.addUnchecked(*entry, setAncestors, validForFeeEstimation);\n+\n+    // trim mempool and check if tx was trimmed\n+    if (!bypass_limits) {\n+        LimitMempoolSize(m_pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n+        if (!m_pool.exists(hash))\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    }\n+    return true;\n+}\n+\n+bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+\n+    Workspace workspace(ptx);\n+\n+    if (!PreChecks(args, workspace)) return false;\n+\n+    // Only compute the precomputed transaction data if we need to verify\n+    // scripts (ie, other policy checks pass)\n+    PrecomputedTransactionData txdata(*ptx);\n+\n+    if (!PolicyScriptChecks(args, workspace, txdata)) return false;\n+\n+    if (!ConsensusScriptChecks(args, workspace, txdata)) return false;\n+\n+    // Tx was accepted, but not added\n+    if (args.m_test_accept) return true;\n+\n+    if (!Finalize(args, workspace)) return false;\n+\n+    GetMainSignals().TransactionAddedToMempool(ptx);\n+\n+    return true;\n+}\n+\n+\n+bool MemPoolAccept::AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    // We will disable the individual transaction fee-rate checks for all\n+    // parents of the final transaction.\n+    ATMPArgs args_bypass_limits { args.m_chainparams, args.m_state, args.m_missing_inputs, args.m_accept_time, args.m_replaced_transactions, /*m_bypass_limits*/ true, args.m_absurd_fee, args.m_coins_to_uncache, args.m_test_accept };\n+    std::list<Workspace> tx_workspaces;\n+\n+    for (const CTransactionRef& ptx : tx_list) {\n+        tx_workspaces.emplace_back(Workspace(ptx));\n+        // The last transaction must be validated for making it past the fee\n+        // checks on its own, to prevent packages from including low-fee,\n+        // unnecessary children that are attached to higher fee parents.\n+        if (!PreChecks((ptx == tx_list.back() ? args : args_bypass_limits), tx_workspaces.back())) return false;\n+\n+        // For now, do not allow replacements in package transactions. If we\n+        // relax this, we would need to check that no child transaction depends\n+        // on any in-mempool transaction that conflicts with any package\n+        // transaction.\n+        if (!tx_workspaces.back().m_conflicts.empty()) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"rbf-disallowed-in-package\", strprintf(\"mempool conflicts with tx %s\", ptx->GetHash().ToString()));\n         }\n-        pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+        // Add this transaction to our coinsview, so that subsequent\n+        // transactions in this package will have their inputs available.\n+        m_viewmempool.AddPotentialTransaction(ptx);\n+    }\n+\n+    // Check overall package feerate\n+    size_t total_size=0;\n+    CAmount total_fee=0;\n+    uint64_t total_count = tx_list.size();\n+    for (const Workspace& ws : tx_workspaces) {\n+        total_size += ws.m_entry->GetTxSize();\n+        total_fee += ws.m_modified_fees;\n+    }\n+    if (!CheckFeeRate(total_size, total_fee, args.m_state)) return false;\n+\n+    // The ancestor/descendant limit calculations in PreChecks() will be overly\n+    // permissive, because not all ancestors will be known as we descend down\n+    // the package. Thus the ancestor checks done by\n+    // CalculateMemPoolAncestors() will be incomplete. If any ancestor or\n+    // descendant limit is violated in one of those checks, however, we know\n+    // the package will not be accepted when we include all ancestors, as the\n+    // ancestor/descendant size/counts only go up as we add more ancestors to\n+    // each transaction.\n+    // We will end up needing to recalculate setAncestors for each transaction\n+    // prior to calling Finalize, but we should do the correct package-size\n+    // calculations before we call ScriptChecks(), to avoid CPU-DoS.\n \n-        // This transaction should only count for fee estimation if:\n-        // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n-        // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n-        // - the node is not behind\n-        // - the transaction is not dependent on any other transactions in the mempool\n-        bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && pool.HasNoInputsOf(tx);\n+    // For now, do something conservative -- assume that the union of ancestors\n+    // of each transaction is an ancestor of every transaction, for package\n+    // size purposes.\n+    CTxMemPool::setEntries all_ancestors;\n+    for (const Workspace& ws : tx_workspaces) {\n+        all_ancestors.insert(ws.m_ancestors.begin(), ws.m_ancestors.end());\n+    }\n \n-        // Store transaction in memory\n-        pool.addUnchecked(entry, setAncestors, validForFeeEstimation);\n+    if (total_count + all_ancestors.size() > m_limit_ancestors) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor count limit [package: %u limit: %u]\", total_count + all_ancestors.size(), m_limit_ancestors));\n+    }\n \n-        // trim mempool and check if tx was trimmed\n-        if (!bypass_limits) {\n-            LimitMempoolSize(pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n-            if (!pool.exists(hash))\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    // Check the package limits for every ancestor, assuming the whole package\n+    // descends from each.\n+    size_t ancestor_size = total_size;\n+    for (auto tx_iter : all_ancestors) {\n+        if (tx_iter->GetSizeWithDescendants() + total_size > m_limit_descendant_size) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendant_size));\n+        }\n+        if (tx_iter->GetCountWithDescendants() + total_count > m_limit_descendants) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendants));\n         }\n+        ancestor_size += tx_iter->GetTxSize();\n     }\n \n-    GetMainSignals().TransactionAddedToMempool(ptx);\n+    // In case we have no in-mempool ancestors, we must check the transaction\n+    // package itself.\n+    if (total_size > m_limit_descendant_size) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_list.front()->GetHash().ToString(), m_limit_descendant_size));\n+    }\n+    if (ancestor_size > m_limit_ancestor_size) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor size limit for tx %s [limit: %u]\", tx_list.back()->GetHash().ToString(), m_limit_ancestor_size));\n+    }\n \n+    // Make sure all transactions are ancestors of the last one.\n+    // For now, just check that the last transaction has all prior transactions\n+    // as direct inputs. We can relax this in the future for bigger packages.\n+    std::set<uint256> last_tx_parents;\n+    for (auto input : tx_list.back()->vin) {\n+        last_tx_parents.insert(input.prevout.hash);\n+    }\n+    for (auto ptx : tx_list) {\n+        if (ptx == tx_list.back()) break;\n+        if (last_tx_parents.count(ptx->GetHash()) == 0) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"non-standard-package-chain\", \"only direct parents are allowed in package\");\n+        }\n+    }\n+\n+    // Do the script checks after all policy checks are done\n+    std::vector<PrecomputedTransactionData> txdata;\n+    txdata.reserve(tx_list.size());\n+    for (auto wit = tx_workspaces.begin(); wit != tx_workspaces.end(); ++wit) {\n+        txdata.emplace_back(*wit->m_ptx);\n+        // We can just use the same ATMPArgs for each invocation, as\n+        // PolicyScriptChecks() ignores bypass_limits.\n+        if (!PolicyScriptChecks(args, *wit, txdata.back())) return false;\n+    }\n+\n+    // This package should be accepted except possibly for failing in\n+    // TrimToSize(), which we can't exercise without actually adding to the\n+    // mempool and seeing what would happen. Note that we are not adding\n+    // these transactions to the script cache, unlike in the single-tx case.\n+    if (args.m_test_accept) return true;\n+\n+    // Add everything to the mempool, and make sure the last transaction makes\n+    // it in.\n+    size_t i=0;\n+    for (auto wit = tx_workspaces.begin(); wit != tx_workspaces.end(); ++wit, ++i) {",
      "path": "src/validation.cpp",
      "position": 261,
      "original_position": 986,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": null,
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Would be nice if C++11 had a \"zip\" iterator... FWIW, you could do this as:\r\n\r\n```\r\nstruct WorkspaceAndTxData { Workspace ws; PrecomputedTransactionData* ptxdata; };\r\nstd::list<WorkspaceAndTxData> tx_workspaces;\r\n...\r\nfor (auto& wstxd : tx_workspaces) {\r\n    txdata.emplace_back(*wstxd.ws.m_ptx);\r\n    wstxd.ptxdata = &txdata.back();\r\n}\r\n```\r\n\r\nand only have to loop over `tx_workspaces`, but it's probably not worth the hassle.",
      "created_at": "2019-07-25T02:18:13Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r307091065",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307091065"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1161,
      "original_line": 1161,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307092986",
      "pull_request_review_id": 266360368,
      "id": 307092986,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwNzA5Mjk4Ng==",
      "diff_hunk": "@@ -508,348 +628,532 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         }\n     }\n \n-    {\n-        CCoinsView dummy;\n-        CCoinsViewCache view(&dummy);\n-\n-        LockPoints lp;\n-        CCoinsViewMemPool viewMemPool(pcoinsTip.get(), pool);\n-        view.SetBackend(viewMemPool);\n+    LockPoints lp;\n+    m_view.SetBackend(m_viewmempool);\n \n-        // do all inputs exist?\n-        for (const CTxIn& txin : tx.vin) {\n-            if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n-                coins_to_uncache.push_back(txin.prevout);\n-            }\n-\n-            // Note: this call may add txin.prevout to the coins cache\n-            // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n-            // later (via coins_to_uncache) if this tx turns out to be invalid.\n-            if (!view.HaveCoin(txin.prevout)) {\n-                // Are inputs missing because we already have the tx?\n-                for (size_t out = 0; out < tx.vout.size(); out++) {\n-                    // Optimistically just do efficient check of cache for outputs\n-                    if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n-                        return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n-                    }\n-                }\n-                // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n-                if (pfMissingInputs) {\n-                    *pfMissingInputs = true;\n+    // do all inputs exist?\n+    for (const CTxIn& txin : tx.vin) {\n+        if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n+            coins_to_uncache.push_back(txin.prevout);\n+        }\n+\n+        // Note: this call may add txin.prevout to the coins cache\n+        // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n+        // later (via coins_to_uncache) if this tx turns out to be invalid.\n+        if (!m_view.HaveCoin(txin.prevout)) {\n+            // Are inputs missing because we already have the tx?\n+            for (size_t out = 0; out < tx.vout.size(); out++) {\n+                // Optimistically just do efficient check of cache for outputs\n+                if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n+                    return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n                 }\n-                return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n             }\n+            // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n+            if (pfMissingInputs) {\n+                *pfMissingInputs = true;\n+            }\n+            return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n         }\n+    }\n \n-        // Bring the best block into scope\n-        view.GetBestBlock();\n+    // Bring the best block into scope\n+    m_view.GetBestBlock();\n \n-        // we have all inputs cached now, so switch back to dummy, so we don't need to keep lock on mempool\n-        view.SetBackend(dummy);\n+    // we have all inputs cached now, so switch back to dummy (to protect\n+    // against bugs where we pull more inputs from disk that miss being added\n+    // to coins_to_uncache)\n+    m_view.SetBackend(m_dummy);\n \n-        // Only accept BIP68 sequence locked transactions that can be mined in the next\n-        // block; we don't want our mempool filled up with transactions that can't\n-        // be mined yet.\n-        // Must keep pool.cs for this unless we change CheckSequenceLocks to take a\n-        // CoinsViewCache instead of create its own\n-        if (!CheckSequenceLocks(pool, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n-            return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n+    // Only accept BIP68 sequence locked transactions that can be mined in the next\n+    // block; we don't want our mempool filled up with transactions that can't\n+    // be mined yet.\n+    if (!CheckSequenceLocks(m_view, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n+        return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n \n-        CAmount nFees = 0;\n-        if (!Consensus::CheckTxInputs(tx, state, view, GetSpendHeight(view), nFees)) {\n-            return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n-        }\n+    CAmount nFees = 0;\n+    if (!Consensus::CheckTxInputs(tx, state, m_view, GetSpendHeight(m_view), nFees)) {\n+        return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n+    }\n \n-        // Check for non-standard pay-to-script-hash in inputs\n-        if (fRequireStandard && !AreInputsStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n+    // Check for non-standard pay-to-script-hash in inputs\n+    if (fRequireStandard && !AreInputsStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n \n-        // Check for non-standard witness in P2WSH\n-        if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n+    // Check for non-standard witness in P2WSH\n+    if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n \n-        int64_t nSigOpsCost = GetTransactionSigOpCost(tx, view, STANDARD_SCRIPT_VERIFY_FLAGS);\n+    int64_t nSigOpsCost = GetTransactionSigOpCost(tx, m_view, STANDARD_SCRIPT_VERIFY_FLAGS);\n \n-        // nModifiedFees includes any fee deltas from PrioritiseTransaction\n-        CAmount nModifiedFees = nFees;\n-        pool.ApplyDelta(hash, nModifiedFees);\n+    // nModifiedFees includes any fee deltas from PrioritiseTransaction\n+    nModifiedFees = nFees;\n+    m_pool.ApplyDelta(hash, nModifiedFees);\n \n-        // Keep track of transactions that spend a coinbase, which we re-scan\n-        // during reorgs to ensure COINBASE_MATURITY is still met.\n-        bool fSpendsCoinbase = false;\n-        for (const CTxIn &txin : tx.vin) {\n-            const Coin &coin = view.AccessCoin(txin.prevout);\n-            if (coin.IsCoinBase()) {\n-                fSpendsCoinbase = true;\n-                break;\n-            }\n+    // Keep track of transactions that spend a coinbase, which we re-scan\n+    // during reorgs to ensure COINBASE_MATURITY is still met.\n+    bool fSpendsCoinbase = false;\n+    for (const CTxIn &txin : tx.vin) {\n+        const Coin &coin = m_view.AccessCoin(txin.prevout);\n+        if (coin.IsCoinBase()) {\n+            fSpendsCoinbase = true;\n+            break;\n         }\n+    }\n \n-        CTxMemPoolEntry entry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n-                              fSpendsCoinbase, nSigOpsCost, lp);\n-        unsigned int nSize = entry.GetTxSize();\n+    entry.reset(new CTxMemPoolEntry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n+            fSpendsCoinbase, nSigOpsCost, lp));\n+    unsigned int nSize = entry->GetTxSize();\n \n-        if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n+    if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n                 strprintf(\"%d\", nSigOpsCost));\n \n-        CAmount mempoolRejectFee = pool.GetMinFee(gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000).GetFee(nSize);\n-        if (!bypass_limits && mempoolRejectFee > 0 && nModifiedFees < mempoolRejectFee) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool min fee not met\", strprintf(\"%d < %d\", nModifiedFees, mempoolRejectFee));\n-        }\n-\n-        // No transactions are allowed below minRelayTxFee except from disconnected blocks\n-        if (!bypass_limits && nModifiedFees < ::minRelayTxFee.GetFee(nSize)) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"min relay fee not met\", strprintf(\"%d < %d\", nModifiedFees, ::minRelayTxFee.GetFee(nSize)));\n-        }\n+    // No transactions are allowed below minRelayTxFee/mempool min fee except\n+    // from disconnected blocks\n+    if (!bypass_limits && !CheckFeeRate(nSize, nModifiedFees, state)) return false;\n \n-        if (nAbsurdFee && nFees > nAbsurdFee)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n+    if (nAbsurdFee && nFees > nAbsurdFee)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n                 REJECT_HIGHFEE, \"absurdly-high-fee\",\n                 strprintf(\"%d > %d\", nFees, nAbsurdFee));\n \n-        // Calculate in-mempool ancestors, up to a limit.\n-        CTxMemPool::setEntries setAncestors;\n-        size_t nLimitAncestors = gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT);\n-        size_t nLimitAncestorSize = gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000;\n-        size_t nLimitDescendants = gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT);\n-        size_t nLimitDescendantSize = gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000;\n-        std::string errString;\n-        if (!pool.CalculateMemPoolAncestors(entry, setAncestors, nLimitAncestors, nLimitAncestorSize, nLimitDescendants, nLimitDescendantSize, errString)) {\n-            setAncestors.clear();\n-            // If the new transaction is relatively small (up to 40k weight)\n-            // and has at most one ancestor (ie ancestor limit of 2, including\n-            // the new transaction), allow it if its parent has exactly the\n-            // descendant limit descendants.\n-            //\n-            // This allows protocols which rely on distrusting counterparties\n-            // being able to broadcast descendants of an unconfirmed transaction\n-            // to be secure by simply only having two immediately-spendable\n-            // outputs - one for each counterparty. For more info on the uses for\n-            // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n-            if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n-                    !pool.CalculateMemPoolAncestors(entry, setAncestors, 2, nLimitAncestorSize, nLimitDescendants + 1, nLimitDescendantSize + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n-            }\n-        }\n-\n-        // A transaction that spends outputs that would be replaced by it is invalid. Now\n-        // that we have the set of all ancestors we can detect this\n-        // pathological case by making sure setConflicts and setAncestors don't\n-        // intersect.\n-        for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    // Calculate in-mempool ancestors, up to a limit.\n+    std::string errString;\n+    if (!m_pool.CalculateMemPoolAncestors(*entry, setAncestors, m_limit_ancestors, m_limit_ancestor_size, m_limit_descendants, m_limit_descendant_size, errString)) {\n+        setAncestors.clear();\n+        // If the new transaction is relatively small (up to 40k weight)\n+        // and has at most one ancestor (ie ancestor limit of 2, including\n+        // the new transaction), allow it if its parent has exactly the\n+        // descendant limit descendants.\n+        //\n+        // This allows protocols which rely on distrusting counterparties\n+        // being able to broadcast descendants of an unconfirmed transaction\n+        // to be secure by simply only having two immediately-spendable\n+        // outputs - one for each counterparty. For more info on the uses for\n+        // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n+        if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n+                !m_pool.CalculateMemPoolAncestors(*entry, setAncestors, 2, m_limit_ancestor_size, m_limit_descendants + 1, m_limit_descendant_size + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n+        }\n+    }\n+\n+    // A transaction that spends outputs that would be replaced by it is invalid. Now\n+    // that we have the set of all ancestors we can detect this\n+    // pathological case by making sure setConflicts and setAncestors don't\n+    // intersect.\n+    for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    {\n+        const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n+        if (setConflicts.count(hashAncestor))\n         {\n-            const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n-            if (setConflicts.count(hashAncestor))\n-            {\n-                return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n-                                 strprintf(\"%s spends conflicting transaction %s\",\n-                                           hash.ToString(),\n-                                           hashAncestor.ToString()));\n-            }\n+            return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n+                    strprintf(\"%s spends conflicting transaction %s\",\n+                        hash.ToString(),\n+                        hashAncestor.ToString()));\n         }\n+    }\n \n-        // Check if it's economically rational to mine this transaction rather\n-        // than the ones it replaces.\n-        CAmount nConflictingFees = 0;\n-        size_t nConflictingSize = 0;\n-        uint64_t nConflictingCount = 0;\n-        CTxMemPool::setEntries allConflicting;\n-\n-        // If we don't hold the lock allConflicting might be incomplete; the\n-        // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n-        // mempool consistency for us.\n-        const bool fReplacementTransaction = setConflicts.size();\n-        if (fReplacementTransaction)\n-        {\n-            CFeeRate newFeeRate(nModifiedFees, nSize);\n-            std::set<uint256> setConflictsParents;\n-            const int maxDescendantsToVisit = 100;\n-            const CTxMemPool::setEntries setIterConflicting = pool.GetIterSet(setConflicts);\n-            for (const auto& mi : setIterConflicting) {\n-                // Don't allow the replacement to reduce the feerate of the\n-                // mempool.\n-                //\n-                // We usually don't want to accept replacements with lower\n-                // feerates than what they replaced as that would lower the\n-                // feerate of the next block. Requiring that the feerate always\n-                // be increased is also an easy-to-reason about way to prevent\n-                // DoS attacks via replacements.\n-                //\n-                // We only consider the feerates of transactions being directly\n-                // replaced, not their indirect descendants. While that does\n-                // mean high feerate children are ignored when deciding whether\n-                // or not to replace, we do require the replacement to pay more\n-                // overall fees too, mitigating most cases.\n-                CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n-                if (newFeeRate <= oldFeeRate)\n-                {\n-                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                            strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n-                                  hash.ToString(),\n-                                  newFeeRate.ToString(),\n-                                  oldFeeRate.ToString()));\n-                }\n-\n-                for (const CTxIn &txin : mi->GetTx().vin)\n-                {\n-                    setConflictsParents.insert(txin.prevout.hash);\n-                }\n+    // Check if it's economically rational to mine this transaction rather\n+    // than the ones it replaces.\n+    nConflictingFees = 0;\n+    nConflictingSize = 0;\n+    uint64_t nConflictingCount = 0;\n \n-                nConflictingCount += mi->GetCountWithDescendants();\n-            }\n-            // This potentially overestimates the number of actual descendants\n-            // but we just want to be conservative to avoid doing too much\n-            // work.\n-            if (nConflictingCount <= maxDescendantsToVisit) {\n-                // If not too many to replace, then calculate the set of\n-                // transactions that would have to be evicted\n-                for (CTxMemPool::txiter it : setIterConflicting) {\n-                    pool.CalculateDescendants(it, allConflicting);\n-                }\n-                for (CTxMemPool::txiter it : allConflicting) {\n-                    nConflictingFees += it->GetModifiedFee();\n-                    nConflictingSize += it->GetTxSize();\n-                }\n-            } else {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n-                        strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+    // If we don't hold the lock allConflicting might be incomplete; the\n+    // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n+    // mempool consistency for us.\n+    fReplacementTransaction = setConflicts.size();\n+    if (fReplacementTransaction)\n+    {\n+        CFeeRate newFeeRate(nModifiedFees, nSize);\n+        std::set<uint256> setConflictsParents;\n+        const int maxDescendantsToVisit = 100;\n+        const CTxMemPool::setEntries setIterConflicting = m_pool.GetIterSet(setConflicts);\n+        for (const auto& mi : setIterConflicting) {\n+            // Don't allow the replacement to reduce the feerate of the\n+            // mempool.\n+            //\n+            // We usually don't want to accept replacements with lower\n+            // feerates than what they replaced as that would lower the\n+            // feerate of the next block. Requiring that the feerate always\n+            // be increased is also an easy-to-reason about way to prevent\n+            // DoS attacks via replacements.\n+            //\n+            // We only consider the feerates of transactions being directly\n+            // replaced, not their indirect descendants. While that does\n+            // mean high feerate children are ignored when deciding whether\n+            // or not to replace, we do require the replacement to pay more\n+            // overall fees too, mitigating most cases.\n+            CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n+            if (newFeeRate <= oldFeeRate)\n+            {\n+                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                        strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n                             hash.ToString(),\n-                            nConflictingCount,\n-                            maxDescendantsToVisit));\n+                            newFeeRate.ToString(),\n+                            oldFeeRate.ToString()));\n             }\n \n-            for (unsigned int j = 0; j < tx.vin.size(); j++)\n+            for (const CTxIn &txin : mi->GetTx().vin)\n             {\n-                // We don't want to accept replacements that require low\n-                // feerate junk to be mined first. Ideally we'd keep track of\n-                // the ancestor feerates and make the decision based on that,\n-                // but for now requiring all new inputs to be confirmed works.\n-                if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n-                {\n-                    // Rather than check the UTXO set - potentially expensive -\n-                    // it's cheaper to just check if the new input refers to a\n-                    // tx that's in the mempool.\n-                    if (pool.exists(tx.vin[j].prevout.hash)) {\n-                        return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n-                                         strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n-                                                  hash.ToString(), j));\n-                    }\n-                }\n+                setConflictsParents.insert(txin.prevout.hash);\n             }\n \n-            // The replacement must pay greater fees than the transactions it\n-            // replaces - if we did the bandwidth used by those conflicting\n-            // transactions would not be paid for.\n-            if (nModifiedFees < nConflictingFees)\n-            {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                                 strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n-                                          hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n+            nConflictingCount += mi->GetCountWithDescendants();\n+        }\n+        // This potentially overestimates the number of actual descendants\n+        // but we just want to be conservative to avoid doing too much\n+        // work.\n+        if (nConflictingCount <= maxDescendantsToVisit) {\n+            // If not too many to replace, then calculate the set of\n+            // transactions that would have to be evicted\n+            for (CTxMemPool::txiter it : setIterConflicting) {\n+                m_pool.CalculateDescendants(it, allConflicting);\n             }\n+            for (CTxMemPool::txiter it : allConflicting) {\n+                nConflictingFees += it->GetModifiedFee();\n+                nConflictingSize += it->GetTxSize();\n+            }\n+        } else {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n+                    strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+                        hash.ToString(),\n+                        nConflictingCount,\n+                        maxDescendantsToVisit));\n+        }\n \n-            // Finally in addition to paying more fees than the conflicts the\n-            // new transaction must pay for its own bandwidth.\n-            CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n-            if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        for (unsigned int j = 0; j < tx.vin.size(); j++)\n+        {\n+            // We don't want to accept replacements that require low\n+            // feerate junk to be mined first. Ideally we'd keep track of\n+            // the ancestor feerates and make the decision based on that,\n+            // but for now requiring all new inputs to be confirmed works.\n+            if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n             {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                        strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n-                              hash.ToString(),\n-                              FormatMoney(nDeltaFees),\n-                              FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n+                // Rather than check the UTXO set - potentially expensive -\n+                // it's cheaper to just check if the new input refers to a\n+                // tx that's in the mempool.\n+                if (m_pool.exists(tx.vin[j].prevout.hash)) {\n+                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n+                            strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n+                                hash.ToString(), j));\n+                }\n             }\n         }\n \n-        constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n-\n-        // Check against previous transactions\n-        // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n-        PrecomputedTransactionData txdata(tx);\n-        if (!CheckInputs(tx, state, view, true, scriptVerifyFlags, true, false, txdata)) {\n-            // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n-            // need to turn both off, and compare against just turning off CLEANSTACK\n-            // to see if the failure is specifically due to witness validation.\n-            CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n-            if (!tx.HasWitness() && CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n-                !CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n-                // Only the witness is missing, so the transaction itself may be fine.\n-                state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n-                        state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n-            }\n-            assert(IsTransactionReason(state.GetReason()));\n-            return false; // state filled in by CheckInputs\n+        // The replacement must pay greater fees than the transactions it\n+        // replaces - if we did the bandwidth used by those conflicting\n+        // transactions would not be paid for.\n+        if (nModifiedFees < nConflictingFees)\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n+                        hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n         }\n \n-        // Check again against the current block tip's script verification\n-        // flags to cache our script execution flags. This is, of course,\n-        // useless if the next block has different script flags from the\n-        // previous one, but because the cache tracks script flags for us it\n-        // will auto-invalidate and we'll just have a few blocks of extra\n-        // misses on soft-fork activation.\n-        //\n-        // This is also useful in case of bugs in the standard flags that cause\n-        // transactions to pass as valid when they're actually invalid. For\n-        // instance the STRICTENC flag was incorrectly allowing certain\n-        // CHECKSIG NOT scripts to pass, even though they were invalid.\n-        //\n-        // There is a similar check in CreateNewBlock() to prevent creating\n-        // invalid blocks (using TestBlockValidity), however allowing such\n-        // transactions into the mempool can be exploited as a DoS attack.\n-        unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n-        if (!CheckInputsFromMempoolAndCache(tx, state, view, pool, currentBlockScriptVerifyFlags, true, txdata)) {\n-            return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n-                    __func__, hash.ToString(), FormatStateMessage(state));\n+        // Finally in addition to paying more fees than the conflicts the\n+        // new transaction must pay for its own bandwidth.\n+        CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n+        if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n+                        hash.ToString(),\n+                        FormatMoney(nDeltaFees),\n+                        FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n         }\n+    }\n+    return true;\n+}\n \n-        if (test_accept) {\n-            // Tx was accepted, but not added\n-            return true;\n+bool MemPoolAccept::PolicyScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+\n+    CValidationState &state = args.m_state;\n+\n+    constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n+\n+    // Check against previous transactions\n+    // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n+    if (!CheckInputs(tx, state, m_view, true, scriptVerifyFlags, true, false, txdata)) {\n+        // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n+        // need to turn both off, and compare against just turning off CLEANSTACK\n+        // to see if the failure is specifically due to witness validation.\n+        CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n+        if (!tx.HasWitness() && CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n+                !CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n+            // Only the witness is missing, so the transaction itself may be fine.\n+            state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n+                    state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n         }\n+        assert(IsTransactionReason(state.GetReason()));\n+        return false; // state filled in by CheckInputs\n+    }\n \n-        // Remove conflicting transactions from the mempool\n-        for (CTxMemPool::txiter it : allConflicting)\n-        {\n-            LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n-                    it->GetTx().GetHash().ToString(),\n-                    hash.ToString(),\n-                    FormatMoney(nModifiedFees - nConflictingFees),\n-                    (int)nSize - (int)nConflictingSize);\n-            if (plTxnReplaced)\n-                plTxnReplaced->push_back(it->GetSharedTx());\n+    return true;\n+}\n+\n+bool MemPoolAccept::ConsensusScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+\n+    CValidationState &state = args.m_state;\n+    const CChainParams& chainparams = args.m_chainparams;\n+\n+    // Check again against the current block tip's script verification\n+    // flags to cache our script execution flags. This is, of course,\n+    // useless if the next block has different script flags from the\n+    // previous one, but because the cache tracks script flags for us it\n+    // will auto-invalidate and we'll just have a few blocks of extra\n+    // misses on soft-fork activation.\n+    //\n+    // This is also useful in case of bugs in the standard flags that cause\n+    // transactions to pass as valid when they're actually invalid. For\n+    // instance the STRICTENC flag was incorrectly allowing certain\n+    // CHECKSIG NOT scripts to pass, even though they were invalid.\n+    //\n+    // There is a similar check in CreateNewBlock() to prevent creating\n+    // invalid blocks (using TestBlockValidity), however allowing such\n+    // transactions into the mempool can be exploited as a DoS attack.\n+    unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n+    if (!CheckInputsFromMempoolAndCache(tx, state, m_view, m_pool, currentBlockScriptVerifyFlags, true, txdata)) {\n+        return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n+                __func__, hash.ToString(), FormatStateMessage(state));\n+    }\n+\n+    return true;\n+}\n+\n+bool MemPoolAccept::Finalize(ATMPArgs& args, Workspace& ws)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+    CValidationState &state = args.m_state;\n+    const bool bypass_limits = args.m_bypass_limits;\n+\n+    CTxMemPool::setEntries& allConflicting = ws.m_all_conflicting;\n+    CTxMemPool::setEntries& setAncestors = ws.m_ancestors;\n+    const CAmount& nModifiedFees = ws.m_modified_fees;\n+    const CAmount& nConflictingFees = ws.m_conflicting_fees;\n+    const size_t& nConflictingSize = ws.m_conflicting_size;\n+    const bool fReplacementTransaction = ws.m_replacement_transaction;\n+    std::unique_ptr<CTxMemPoolEntry>& entry = ws.m_entry;\n+\n+    // Remove conflicting transactions from the mempool\n+    for (CTxMemPool::txiter it : allConflicting)\n+    {\n+        LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n+                it->GetTx().GetHash().ToString(),\n+                hash.ToString(),\n+                FormatMoney(nModifiedFees - nConflictingFees),\n+                (int)entry->GetTxSize() - (int)nConflictingSize);\n+        if (args.m_replaced_transactions)\n+            args.m_replaced_transactions->push_back(it->GetSharedTx());\n+    }\n+    m_pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+\n+    // This transaction should only count for fee estimation if:\n+    // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n+    // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n+    // - the node is not behind\n+    // - the transaction is not dependent on any other transactions in the mempool\n+    bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && m_pool.HasNoInputsOf(tx);\n+\n+    // Store transaction in memory\n+    m_pool.addUnchecked(*entry, setAncestors, validForFeeEstimation);\n+\n+    // trim mempool and check if tx was trimmed\n+    if (!bypass_limits) {\n+        LimitMempoolSize(m_pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n+        if (!m_pool.exists(hash))\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    }\n+    return true;\n+}\n+\n+bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+\n+    Workspace workspace(ptx);\n+\n+    if (!PreChecks(args, workspace)) return false;\n+\n+    // Only compute the precomputed transaction data if we need to verify\n+    // scripts (ie, other policy checks pass)\n+    PrecomputedTransactionData txdata(*ptx);\n+\n+    if (!PolicyScriptChecks(args, workspace, txdata)) return false;\n+\n+    if (!ConsensusScriptChecks(args, workspace, txdata)) return false;\n+\n+    // Tx was accepted, but not added\n+    if (args.m_test_accept) return true;\n+\n+    if (!Finalize(args, workspace)) return false;\n+\n+    GetMainSignals().TransactionAddedToMempool(ptx);\n+\n+    return true;\n+}\n+\n+\n+bool MemPoolAccept::AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    // We will disable the individual transaction fee-rate checks for all\n+    // parents of the final transaction.\n+    ATMPArgs args_bypass_limits { args.m_chainparams, args.m_state, args.m_missing_inputs, args.m_accept_time, args.m_replaced_transactions, /*m_bypass_limits*/ true, args.m_absurd_fee, args.m_coins_to_uncache, args.m_test_accept };\n+    std::list<Workspace> tx_workspaces;\n+\n+    for (const CTransactionRef& ptx : tx_list) {\n+        tx_workspaces.emplace_back(Workspace(ptx));\n+        // The last transaction must be validated for making it past the fee\n+        // checks on its own, to prevent packages from including low-fee,\n+        // unnecessary children that are attached to higher fee parents.\n+        if (!PreChecks((ptx == tx_list.back() ? args : args_bypass_limits), tx_workspaces.back())) return false;\n+\n+        // For now, do not allow replacements in package transactions. If we\n+        // relax this, we would need to check that no child transaction depends\n+        // on any in-mempool transaction that conflicts with any package\n+        // transaction.\n+        if (!tx_workspaces.back().m_conflicts.empty()) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"rbf-disallowed-in-package\", strprintf(\"mempool conflicts with tx %s\", ptx->GetHash().ToString()));\n         }\n-        pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+        // Add this transaction to our coinsview, so that subsequent\n+        // transactions in this package will have their inputs available.\n+        m_viewmempool.AddPotentialTransaction(ptx);\n+    }\n+\n+    // Check overall package feerate\n+    size_t total_size=0;\n+    CAmount total_fee=0;\n+    uint64_t total_count = tx_list.size();\n+    for (const Workspace& ws : tx_workspaces) {\n+        total_size += ws.m_entry->GetTxSize();\n+        total_fee += ws.m_modified_fees;\n+    }\n+    if (!CheckFeeRate(total_size, total_fee, args.m_state)) return false;\n+\n+    // The ancestor/descendant limit calculations in PreChecks() will be overly\n+    // permissive, because not all ancestors will be known as we descend down\n+    // the package. Thus the ancestor checks done by\n+    // CalculateMemPoolAncestors() will be incomplete. If any ancestor or\n+    // descendant limit is violated in one of those checks, however, we know\n+    // the package will not be accepted when we include all ancestors, as the\n+    // ancestor/descendant size/counts only go up as we add more ancestors to\n+    // each transaction.\n+    // We will end up needing to recalculate setAncestors for each transaction\n+    // prior to calling Finalize, but we should do the correct package-size\n+    // calculations before we call ScriptChecks(), to avoid CPU-DoS.\n \n-        // This transaction should only count for fee estimation if:\n-        // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n-        // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n-        // - the node is not behind\n-        // - the transaction is not dependent on any other transactions in the mempool\n-        bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && pool.HasNoInputsOf(tx);\n+    // For now, do something conservative -- assume that the union of ancestors\n+    // of each transaction is an ancestor of every transaction, for package\n+    // size purposes.\n+    CTxMemPool::setEntries all_ancestors;\n+    for (const Workspace& ws : tx_workspaces) {\n+        all_ancestors.insert(ws.m_ancestors.begin(), ws.m_ancestors.end());\n+    }\n \n-        // Store transaction in memory\n-        pool.addUnchecked(entry, setAncestors, validForFeeEstimation);\n+    if (total_count + all_ancestors.size() > m_limit_ancestors) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor count limit [package: %u limit: %u]\", total_count + all_ancestors.size(), m_limit_ancestors));\n+    }\n \n-        // trim mempool and check if tx was trimmed\n-        if (!bypass_limits) {\n-            LimitMempoolSize(pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n-            if (!pool.exists(hash))\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    // Check the package limits for every ancestor, assuming the whole package\n+    // descends from each.\n+    size_t ancestor_size = total_size;\n+    for (auto tx_iter : all_ancestors) {\n+        if (tx_iter->GetSizeWithDescendants() + total_size > m_limit_descendant_size) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendant_size));\n+        }\n+        if (tx_iter->GetCountWithDescendants() + total_count > m_limit_descendants) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendants));\n         }\n+        ancestor_size += tx_iter->GetTxSize();\n     }\n \n-    GetMainSignals().TransactionAddedToMempool(ptx);\n+    // In case we have no in-mempool ancestors, we must check the transaction\n+    // package itself.\n+    if (total_size > m_limit_descendant_size) {",
      "path": "src/validation.cpp",
      "position": 223,
      "original_position": 946,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": null,
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Might as well do this test before looping over all_ancestors",
      "created_at": "2019-07-25T02:30:42Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r307092986",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307092986"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1123,
      "original_line": 1123,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307100725",
      "pull_request_review_id": 266360368,
      "id": 307100725,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwNzEwMDcyNQ==",
      "diff_hunk": "@@ -508,348 +628,532 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         }\n     }\n \n-    {\n-        CCoinsView dummy;\n-        CCoinsViewCache view(&dummy);\n-\n-        LockPoints lp;\n-        CCoinsViewMemPool viewMemPool(pcoinsTip.get(), pool);\n-        view.SetBackend(viewMemPool);\n+    LockPoints lp;\n+    m_view.SetBackend(m_viewmempool);\n \n-        // do all inputs exist?\n-        for (const CTxIn& txin : tx.vin) {\n-            if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n-                coins_to_uncache.push_back(txin.prevout);\n-            }\n-\n-            // Note: this call may add txin.prevout to the coins cache\n-            // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n-            // later (via coins_to_uncache) if this tx turns out to be invalid.\n-            if (!view.HaveCoin(txin.prevout)) {\n-                // Are inputs missing because we already have the tx?\n-                for (size_t out = 0; out < tx.vout.size(); out++) {\n-                    // Optimistically just do efficient check of cache for outputs\n-                    if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n-                        return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n-                    }\n-                }\n-                // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n-                if (pfMissingInputs) {\n-                    *pfMissingInputs = true;\n+    // do all inputs exist?\n+    for (const CTxIn& txin : tx.vin) {\n+        if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n+            coins_to_uncache.push_back(txin.prevout);\n+        }\n+\n+        // Note: this call may add txin.prevout to the coins cache\n+        // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n+        // later (via coins_to_uncache) if this tx turns out to be invalid.\n+        if (!m_view.HaveCoin(txin.prevout)) {\n+            // Are inputs missing because we already have the tx?\n+            for (size_t out = 0; out < tx.vout.size(); out++) {\n+                // Optimistically just do efficient check of cache for outputs\n+                if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n+                    return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n                 }\n-                return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n             }\n+            // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n+            if (pfMissingInputs) {\n+                *pfMissingInputs = true;\n+            }\n+            return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n         }\n+    }\n \n-        // Bring the best block into scope\n-        view.GetBestBlock();\n+    // Bring the best block into scope\n+    m_view.GetBestBlock();\n \n-        // we have all inputs cached now, so switch back to dummy, so we don't need to keep lock on mempool\n-        view.SetBackend(dummy);\n+    // we have all inputs cached now, so switch back to dummy (to protect\n+    // against bugs where we pull more inputs from disk that miss being added\n+    // to coins_to_uncache)\n+    m_view.SetBackend(m_dummy);\n \n-        // Only accept BIP68 sequence locked transactions that can be mined in the next\n-        // block; we don't want our mempool filled up with transactions that can't\n-        // be mined yet.\n-        // Must keep pool.cs for this unless we change CheckSequenceLocks to take a\n-        // CoinsViewCache instead of create its own\n-        if (!CheckSequenceLocks(pool, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n-            return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n+    // Only accept BIP68 sequence locked transactions that can be mined in the next\n+    // block; we don't want our mempool filled up with transactions that can't\n+    // be mined yet.\n+    if (!CheckSequenceLocks(m_view, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n+        return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n \n-        CAmount nFees = 0;\n-        if (!Consensus::CheckTxInputs(tx, state, view, GetSpendHeight(view), nFees)) {\n-            return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n-        }\n+    CAmount nFees = 0;\n+    if (!Consensus::CheckTxInputs(tx, state, m_view, GetSpendHeight(m_view), nFees)) {\n+        return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n+    }\n \n-        // Check for non-standard pay-to-script-hash in inputs\n-        if (fRequireStandard && !AreInputsStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n+    // Check for non-standard pay-to-script-hash in inputs\n+    if (fRequireStandard && !AreInputsStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n \n-        // Check for non-standard witness in P2WSH\n-        if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n+    // Check for non-standard witness in P2WSH\n+    if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n \n-        int64_t nSigOpsCost = GetTransactionSigOpCost(tx, view, STANDARD_SCRIPT_VERIFY_FLAGS);\n+    int64_t nSigOpsCost = GetTransactionSigOpCost(tx, m_view, STANDARD_SCRIPT_VERIFY_FLAGS);\n \n-        // nModifiedFees includes any fee deltas from PrioritiseTransaction\n-        CAmount nModifiedFees = nFees;\n-        pool.ApplyDelta(hash, nModifiedFees);\n+    // nModifiedFees includes any fee deltas from PrioritiseTransaction\n+    nModifiedFees = nFees;\n+    m_pool.ApplyDelta(hash, nModifiedFees);\n \n-        // Keep track of transactions that spend a coinbase, which we re-scan\n-        // during reorgs to ensure COINBASE_MATURITY is still met.\n-        bool fSpendsCoinbase = false;\n-        for (const CTxIn &txin : tx.vin) {\n-            const Coin &coin = view.AccessCoin(txin.prevout);\n-            if (coin.IsCoinBase()) {\n-                fSpendsCoinbase = true;\n-                break;\n-            }\n+    // Keep track of transactions that spend a coinbase, which we re-scan\n+    // during reorgs to ensure COINBASE_MATURITY is still met.\n+    bool fSpendsCoinbase = false;\n+    for (const CTxIn &txin : tx.vin) {\n+        const Coin &coin = m_view.AccessCoin(txin.prevout);\n+        if (coin.IsCoinBase()) {\n+            fSpendsCoinbase = true;\n+            break;\n         }\n+    }\n \n-        CTxMemPoolEntry entry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n-                              fSpendsCoinbase, nSigOpsCost, lp);\n-        unsigned int nSize = entry.GetTxSize();\n+    entry.reset(new CTxMemPoolEntry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n+            fSpendsCoinbase, nSigOpsCost, lp));\n+    unsigned int nSize = entry->GetTxSize();\n \n-        if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n+    if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n                 strprintf(\"%d\", nSigOpsCost));\n \n-        CAmount mempoolRejectFee = pool.GetMinFee(gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000).GetFee(nSize);\n-        if (!bypass_limits && mempoolRejectFee > 0 && nModifiedFees < mempoolRejectFee) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool min fee not met\", strprintf(\"%d < %d\", nModifiedFees, mempoolRejectFee));\n-        }\n-\n-        // No transactions are allowed below minRelayTxFee except from disconnected blocks\n-        if (!bypass_limits && nModifiedFees < ::minRelayTxFee.GetFee(nSize)) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"min relay fee not met\", strprintf(\"%d < %d\", nModifiedFees, ::minRelayTxFee.GetFee(nSize)));\n-        }\n+    // No transactions are allowed below minRelayTxFee/mempool min fee except\n+    // from disconnected blocks\n+    if (!bypass_limits && !CheckFeeRate(nSize, nModifiedFees, state)) return false;\n \n-        if (nAbsurdFee && nFees > nAbsurdFee)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n+    if (nAbsurdFee && nFees > nAbsurdFee)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n                 REJECT_HIGHFEE, \"absurdly-high-fee\",\n                 strprintf(\"%d > %d\", nFees, nAbsurdFee));\n \n-        // Calculate in-mempool ancestors, up to a limit.\n-        CTxMemPool::setEntries setAncestors;\n-        size_t nLimitAncestors = gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT);\n-        size_t nLimitAncestorSize = gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000;\n-        size_t nLimitDescendants = gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT);\n-        size_t nLimitDescendantSize = gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000;\n-        std::string errString;\n-        if (!pool.CalculateMemPoolAncestors(entry, setAncestors, nLimitAncestors, nLimitAncestorSize, nLimitDescendants, nLimitDescendantSize, errString)) {\n-            setAncestors.clear();\n-            // If the new transaction is relatively small (up to 40k weight)\n-            // and has at most one ancestor (ie ancestor limit of 2, including\n-            // the new transaction), allow it if its parent has exactly the\n-            // descendant limit descendants.\n-            //\n-            // This allows protocols which rely on distrusting counterparties\n-            // being able to broadcast descendants of an unconfirmed transaction\n-            // to be secure by simply only having two immediately-spendable\n-            // outputs - one for each counterparty. For more info on the uses for\n-            // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n-            if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n-                    !pool.CalculateMemPoolAncestors(entry, setAncestors, 2, nLimitAncestorSize, nLimitDescendants + 1, nLimitDescendantSize + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n-            }\n-        }\n-\n-        // A transaction that spends outputs that would be replaced by it is invalid. Now\n-        // that we have the set of all ancestors we can detect this\n-        // pathological case by making sure setConflicts and setAncestors don't\n-        // intersect.\n-        for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    // Calculate in-mempool ancestors, up to a limit.\n+    std::string errString;\n+    if (!m_pool.CalculateMemPoolAncestors(*entry, setAncestors, m_limit_ancestors, m_limit_ancestor_size, m_limit_descendants, m_limit_descendant_size, errString)) {\n+        setAncestors.clear();\n+        // If the new transaction is relatively small (up to 40k weight)\n+        // and has at most one ancestor (ie ancestor limit of 2, including\n+        // the new transaction), allow it if its parent has exactly the\n+        // descendant limit descendants.\n+        //\n+        // This allows protocols which rely on distrusting counterparties\n+        // being able to broadcast descendants of an unconfirmed transaction\n+        // to be secure by simply only having two immediately-spendable\n+        // outputs - one for each counterparty. For more info on the uses for\n+        // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n+        if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n+                !m_pool.CalculateMemPoolAncestors(*entry, setAncestors, 2, m_limit_ancestor_size, m_limit_descendants + 1, m_limit_descendant_size + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n+        }\n+    }\n+\n+    // A transaction that spends outputs that would be replaced by it is invalid. Now\n+    // that we have the set of all ancestors we can detect this\n+    // pathological case by making sure setConflicts and setAncestors don't\n+    // intersect.\n+    for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    {\n+        const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n+        if (setConflicts.count(hashAncestor))\n         {\n-            const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n-            if (setConflicts.count(hashAncestor))\n-            {\n-                return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n-                                 strprintf(\"%s spends conflicting transaction %s\",\n-                                           hash.ToString(),\n-                                           hashAncestor.ToString()));\n-            }\n+            return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n+                    strprintf(\"%s spends conflicting transaction %s\",\n+                        hash.ToString(),\n+                        hashAncestor.ToString()));\n         }\n+    }\n \n-        // Check if it's economically rational to mine this transaction rather\n-        // than the ones it replaces.\n-        CAmount nConflictingFees = 0;\n-        size_t nConflictingSize = 0;\n-        uint64_t nConflictingCount = 0;\n-        CTxMemPool::setEntries allConflicting;\n-\n-        // If we don't hold the lock allConflicting might be incomplete; the\n-        // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n-        // mempool consistency for us.\n-        const bool fReplacementTransaction = setConflicts.size();\n-        if (fReplacementTransaction)\n-        {\n-            CFeeRate newFeeRate(nModifiedFees, nSize);\n-            std::set<uint256> setConflictsParents;\n-            const int maxDescendantsToVisit = 100;\n-            const CTxMemPool::setEntries setIterConflicting = pool.GetIterSet(setConflicts);\n-            for (const auto& mi : setIterConflicting) {\n-                // Don't allow the replacement to reduce the feerate of the\n-                // mempool.\n-                //\n-                // We usually don't want to accept replacements with lower\n-                // feerates than what they replaced as that would lower the\n-                // feerate of the next block. Requiring that the feerate always\n-                // be increased is also an easy-to-reason about way to prevent\n-                // DoS attacks via replacements.\n-                //\n-                // We only consider the feerates of transactions being directly\n-                // replaced, not their indirect descendants. While that does\n-                // mean high feerate children are ignored when deciding whether\n-                // or not to replace, we do require the replacement to pay more\n-                // overall fees too, mitigating most cases.\n-                CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n-                if (newFeeRate <= oldFeeRate)\n-                {\n-                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                            strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n-                                  hash.ToString(),\n-                                  newFeeRate.ToString(),\n-                                  oldFeeRate.ToString()));\n-                }\n-\n-                for (const CTxIn &txin : mi->GetTx().vin)\n-                {\n-                    setConflictsParents.insert(txin.prevout.hash);\n-                }\n+    // Check if it's economically rational to mine this transaction rather\n+    // than the ones it replaces.\n+    nConflictingFees = 0;\n+    nConflictingSize = 0;\n+    uint64_t nConflictingCount = 0;\n \n-                nConflictingCount += mi->GetCountWithDescendants();\n-            }\n-            // This potentially overestimates the number of actual descendants\n-            // but we just want to be conservative to avoid doing too much\n-            // work.\n-            if (nConflictingCount <= maxDescendantsToVisit) {\n-                // If not too many to replace, then calculate the set of\n-                // transactions that would have to be evicted\n-                for (CTxMemPool::txiter it : setIterConflicting) {\n-                    pool.CalculateDescendants(it, allConflicting);\n-                }\n-                for (CTxMemPool::txiter it : allConflicting) {\n-                    nConflictingFees += it->GetModifiedFee();\n-                    nConflictingSize += it->GetTxSize();\n-                }\n-            } else {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n-                        strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+    // If we don't hold the lock allConflicting might be incomplete; the\n+    // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n+    // mempool consistency for us.\n+    fReplacementTransaction = setConflicts.size();\n+    if (fReplacementTransaction)\n+    {\n+        CFeeRate newFeeRate(nModifiedFees, nSize);\n+        std::set<uint256> setConflictsParents;\n+        const int maxDescendantsToVisit = 100;\n+        const CTxMemPool::setEntries setIterConflicting = m_pool.GetIterSet(setConflicts);\n+        for (const auto& mi : setIterConflicting) {\n+            // Don't allow the replacement to reduce the feerate of the\n+            // mempool.\n+            //\n+            // We usually don't want to accept replacements with lower\n+            // feerates than what they replaced as that would lower the\n+            // feerate of the next block. Requiring that the feerate always\n+            // be increased is also an easy-to-reason about way to prevent\n+            // DoS attacks via replacements.\n+            //\n+            // We only consider the feerates of transactions being directly\n+            // replaced, not their indirect descendants. While that does\n+            // mean high feerate children are ignored when deciding whether\n+            // or not to replace, we do require the replacement to pay more\n+            // overall fees too, mitigating most cases.\n+            CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n+            if (newFeeRate <= oldFeeRate)\n+            {\n+                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                        strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n                             hash.ToString(),\n-                            nConflictingCount,\n-                            maxDescendantsToVisit));\n+                            newFeeRate.ToString(),\n+                            oldFeeRate.ToString()));\n             }\n \n-            for (unsigned int j = 0; j < tx.vin.size(); j++)\n+            for (const CTxIn &txin : mi->GetTx().vin)\n             {\n-                // We don't want to accept replacements that require low\n-                // feerate junk to be mined first. Ideally we'd keep track of\n-                // the ancestor feerates and make the decision based on that,\n-                // but for now requiring all new inputs to be confirmed works.\n-                if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n-                {\n-                    // Rather than check the UTXO set - potentially expensive -\n-                    // it's cheaper to just check if the new input refers to a\n-                    // tx that's in the mempool.\n-                    if (pool.exists(tx.vin[j].prevout.hash)) {\n-                        return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n-                                         strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n-                                                  hash.ToString(), j));\n-                    }\n-                }\n+                setConflictsParents.insert(txin.prevout.hash);\n             }\n \n-            // The replacement must pay greater fees than the transactions it\n-            // replaces - if we did the bandwidth used by those conflicting\n-            // transactions would not be paid for.\n-            if (nModifiedFees < nConflictingFees)\n-            {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                                 strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n-                                          hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n+            nConflictingCount += mi->GetCountWithDescendants();\n+        }\n+        // This potentially overestimates the number of actual descendants\n+        // but we just want to be conservative to avoid doing too much\n+        // work.\n+        if (nConflictingCount <= maxDescendantsToVisit) {\n+            // If not too many to replace, then calculate the set of\n+            // transactions that would have to be evicted\n+            for (CTxMemPool::txiter it : setIterConflicting) {\n+                m_pool.CalculateDescendants(it, allConflicting);\n             }\n+            for (CTxMemPool::txiter it : allConflicting) {\n+                nConflictingFees += it->GetModifiedFee();\n+                nConflictingSize += it->GetTxSize();\n+            }\n+        } else {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n+                    strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+                        hash.ToString(),\n+                        nConflictingCount,\n+                        maxDescendantsToVisit));\n+        }\n \n-            // Finally in addition to paying more fees than the conflicts the\n-            // new transaction must pay for its own bandwidth.\n-            CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n-            if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        for (unsigned int j = 0; j < tx.vin.size(); j++)\n+        {\n+            // We don't want to accept replacements that require low\n+            // feerate junk to be mined first. Ideally we'd keep track of\n+            // the ancestor feerates and make the decision based on that,\n+            // but for now requiring all new inputs to be confirmed works.\n+            if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n             {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                        strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n-                              hash.ToString(),\n-                              FormatMoney(nDeltaFees),\n-                              FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n+                // Rather than check the UTXO set - potentially expensive -\n+                // it's cheaper to just check if the new input refers to a\n+                // tx that's in the mempool.\n+                if (m_pool.exists(tx.vin[j].prevout.hash)) {\n+                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n+                            strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n+                                hash.ToString(), j));\n+                }\n             }\n         }\n \n-        constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n-\n-        // Check against previous transactions\n-        // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n-        PrecomputedTransactionData txdata(tx);\n-        if (!CheckInputs(tx, state, view, true, scriptVerifyFlags, true, false, txdata)) {\n-            // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n-            // need to turn both off, and compare against just turning off CLEANSTACK\n-            // to see if the failure is specifically due to witness validation.\n-            CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n-            if (!tx.HasWitness() && CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n-                !CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n-                // Only the witness is missing, so the transaction itself may be fine.\n-                state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n-                        state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n-            }\n-            assert(IsTransactionReason(state.GetReason()));\n-            return false; // state filled in by CheckInputs\n+        // The replacement must pay greater fees than the transactions it\n+        // replaces - if we did the bandwidth used by those conflicting\n+        // transactions would not be paid for.\n+        if (nModifiedFees < nConflictingFees)\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n+                        hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n         }\n \n-        // Check again against the current block tip's script verification\n-        // flags to cache our script execution flags. This is, of course,\n-        // useless if the next block has different script flags from the\n-        // previous one, but because the cache tracks script flags for us it\n-        // will auto-invalidate and we'll just have a few blocks of extra\n-        // misses on soft-fork activation.\n-        //\n-        // This is also useful in case of bugs in the standard flags that cause\n-        // transactions to pass as valid when they're actually invalid. For\n-        // instance the STRICTENC flag was incorrectly allowing certain\n-        // CHECKSIG NOT scripts to pass, even though they were invalid.\n-        //\n-        // There is a similar check in CreateNewBlock() to prevent creating\n-        // invalid blocks (using TestBlockValidity), however allowing such\n-        // transactions into the mempool can be exploited as a DoS attack.\n-        unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n-        if (!CheckInputsFromMempoolAndCache(tx, state, view, pool, currentBlockScriptVerifyFlags, true, txdata)) {\n-            return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n-                    __func__, hash.ToString(), FormatStateMessage(state));\n+        // Finally in addition to paying more fees than the conflicts the\n+        // new transaction must pay for its own bandwidth.\n+        CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n+        if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n+                        hash.ToString(),\n+                        FormatMoney(nDeltaFees),\n+                        FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n         }\n+    }\n+    return true;\n+}\n \n-        if (test_accept) {\n-            // Tx was accepted, but not added\n-            return true;\n+bool MemPoolAccept::PolicyScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+\n+    CValidationState &state = args.m_state;\n+\n+    constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n+\n+    // Check against previous transactions\n+    // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n+    if (!CheckInputs(tx, state, m_view, true, scriptVerifyFlags, true, false, txdata)) {\n+        // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n+        // need to turn both off, and compare against just turning off CLEANSTACK\n+        // to see if the failure is specifically due to witness validation.\n+        CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n+        if (!tx.HasWitness() && CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n+                !CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n+            // Only the witness is missing, so the transaction itself may be fine.\n+            state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n+                    state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n         }\n+        assert(IsTransactionReason(state.GetReason()));\n+        return false; // state filled in by CheckInputs\n+    }\n \n-        // Remove conflicting transactions from the mempool\n-        for (CTxMemPool::txiter it : allConflicting)\n-        {\n-            LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n-                    it->GetTx().GetHash().ToString(),\n-                    hash.ToString(),\n-                    FormatMoney(nModifiedFees - nConflictingFees),\n-                    (int)nSize - (int)nConflictingSize);\n-            if (plTxnReplaced)\n-                plTxnReplaced->push_back(it->GetSharedTx());\n+    return true;\n+}\n+\n+bool MemPoolAccept::ConsensusScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+\n+    CValidationState &state = args.m_state;\n+    const CChainParams& chainparams = args.m_chainparams;\n+\n+    // Check again against the current block tip's script verification\n+    // flags to cache our script execution flags. This is, of course,\n+    // useless if the next block has different script flags from the\n+    // previous one, but because the cache tracks script flags for us it\n+    // will auto-invalidate and we'll just have a few blocks of extra\n+    // misses on soft-fork activation.\n+    //\n+    // This is also useful in case of bugs in the standard flags that cause\n+    // transactions to pass as valid when they're actually invalid. For\n+    // instance the STRICTENC flag was incorrectly allowing certain\n+    // CHECKSIG NOT scripts to pass, even though they were invalid.\n+    //\n+    // There is a similar check in CreateNewBlock() to prevent creating\n+    // invalid blocks (using TestBlockValidity), however allowing such\n+    // transactions into the mempool can be exploited as a DoS attack.\n+    unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n+    if (!CheckInputsFromMempoolAndCache(tx, state, m_view, m_pool, currentBlockScriptVerifyFlags, true, txdata)) {\n+        return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n+                __func__, hash.ToString(), FormatStateMessage(state));\n+    }\n+\n+    return true;\n+}\n+\n+bool MemPoolAccept::Finalize(ATMPArgs& args, Workspace& ws)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+    CValidationState &state = args.m_state;\n+    const bool bypass_limits = args.m_bypass_limits;\n+\n+    CTxMemPool::setEntries& allConflicting = ws.m_all_conflicting;\n+    CTxMemPool::setEntries& setAncestors = ws.m_ancestors;\n+    const CAmount& nModifiedFees = ws.m_modified_fees;\n+    const CAmount& nConflictingFees = ws.m_conflicting_fees;\n+    const size_t& nConflictingSize = ws.m_conflicting_size;\n+    const bool fReplacementTransaction = ws.m_replacement_transaction;\n+    std::unique_ptr<CTxMemPoolEntry>& entry = ws.m_entry;\n+\n+    // Remove conflicting transactions from the mempool\n+    for (CTxMemPool::txiter it : allConflicting)\n+    {\n+        LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n+                it->GetTx().GetHash().ToString(),\n+                hash.ToString(),\n+                FormatMoney(nModifiedFees - nConflictingFees),\n+                (int)entry->GetTxSize() - (int)nConflictingSize);\n+        if (args.m_replaced_transactions)\n+            args.m_replaced_transactions->push_back(it->GetSharedTx());\n+    }\n+    m_pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+\n+    // This transaction should only count for fee estimation if:\n+    // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n+    // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n+    // - the node is not behind\n+    // - the transaction is not dependent on any other transactions in the mempool\n+    bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && m_pool.HasNoInputsOf(tx);\n+\n+    // Store transaction in memory\n+    m_pool.addUnchecked(*entry, setAncestors, validForFeeEstimation);\n+\n+    // trim mempool and check if tx was trimmed\n+    if (!bypass_limits) {\n+        LimitMempoolSize(m_pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n+        if (!m_pool.exists(hash))\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    }\n+    return true;\n+}\n+\n+bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+\n+    Workspace workspace(ptx);\n+\n+    if (!PreChecks(args, workspace)) return false;\n+\n+    // Only compute the precomputed transaction data if we need to verify\n+    // scripts (ie, other policy checks pass)\n+    PrecomputedTransactionData txdata(*ptx);\n+\n+    if (!PolicyScriptChecks(args, workspace, txdata)) return false;\n+\n+    if (!ConsensusScriptChecks(args, workspace, txdata)) return false;\n+\n+    // Tx was accepted, but not added\n+    if (args.m_test_accept) return true;\n+\n+    if (!Finalize(args, workspace)) return false;\n+\n+    GetMainSignals().TransactionAddedToMempool(ptx);\n+\n+    return true;\n+}\n+\n+\n+bool MemPoolAccept::AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args)",
      "path": "src/validation.cpp",
      "position": null,
      "original_position": 853,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": null,
      "user": {
        "login": "ajtowns",
        "id": 127186,
        "node_id": "MDQ6VXNlcjEyNzE4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ajtowns",
        "html_url": "https://github.com/ajtowns",
        "followers_url": "https://api.github.com/users/ajtowns/followers",
        "following_url": "https://api.github.com/users/ajtowns/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ajtowns/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ajtowns/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
        "organizations_url": "https://api.github.com/users/ajtowns/orgs",
        "repos_url": "https://api.github.com/users/ajtowns/repos",
        "events_url": "https://api.github.com/users/ajtowns/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ajtowns/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "I think once this is more baked, it'd be good to pull sections of this out into their own private MemPoolAccept:: methods so the overall logic in this function is as clear as the logic in AcceptSingleTransaction",
      "created_at": "2019-07-25T03:22:18Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r307100725",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/307100725"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1004,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/308396410",
      "pull_request_review_id": 267988978,
      "id": 308396410,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwODM5NjQxMA==",
      "diff_hunk": "@@ -326,7 +330,8 @@ bool TestLockPointValidity(const LockPoints* lp) EXCLUSIVE_LOCKS_REQUIRED(cs_mai\n  *\n  * See consensus/consensus.h for flag definitions.\n  */\n-bool CheckSequenceLocks(const CTxMemPool& pool, const CTransaction& tx, int flags, LockPoints* lp = nullptr, bool useExistingLockPoints = false) EXCLUSIVE_LOCKS_REQUIRED(cs_main);\n+bool CheckSequenceLocks(const CTxMemPool &pool, const CTransaction& tx, int flags, LockPoints* lp = nullptr, bool useExistingLockPoints = false) EXCLUSIVE_LOCKS_REQUIRED(cs_main);\n+bool CheckSequenceLocks(CCoinsViewCache& view, const CTransaction& tx, int flags, LockPoints* lp = nullptr, bool useExistingLockPoints = false) EXCLUSIVE_LOCKS_REQUIRED(cs_main);",
      "path": "src/validation.h",
      "position": null,
      "original_position": 17,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": 307082337,
      "user": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Fixed.",
      "created_at": "2019-07-29T19:23:28Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r308396410",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/308396410"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 334,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/308396557",
      "pull_request_review_id": 267989140,
      "id": 308396557,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwODM5NjU1Nw==",
      "diff_hunk": "@@ -2551,33 +2558,80 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n                 recentRejects->insert(tx.GetHash());\n             }\n         } else {\n-            assert(IsTransactionReason(state.GetReason()));\n-            if (!tx.HasWitness() && state.GetReason() != ValidationInvalidReason::TX_WITNESS_MUTATED) {\n-                // Do not use rejection cache for witness transactions or\n-                // witness-stripped transactions, as they can have been malleated.\n-                // See https://github.com/bitcoin/bitcoin/issues/8279 for details.\n-                assert(recentRejects);\n-                recentRejects->insert(tx.GetHash());\n-                if (RecursiveDynamicUsage(*ptx) < 100000) {\n-                    AddToCompactExtraTransactions(ptx);\n+            // If this tx didn't make it in due to feerate, and there is a tx\n+            // in the orphan pool -- then maybe that tx is only missing this\n+            // one parent.\n+            // Try to process the pair as a package.\n+            bool added_as_package = false;\n+            if (state.GetRejectCode() == REJECT_INSUFFICIENTFEE) {\n+                LOCK(g_cs_orphans);",
      "path": "src/net_processing.cpp",
      "position": null,
      "original_position": 56,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": 307082891,
      "user": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Fixed.",
      "created_at": "2019-07-29T19:23:48Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r308396557",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/308396557"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 2567,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/308396598",
      "pull_request_review_id": 267989190,
      "id": 308396598,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwODM5NjU5OA==",
      "diff_hunk": "@@ -422,21 +428,136 @@ static bool CheckInputsFromMempoolAndCache(const CTransaction& tx, CValidationSt\n     return CheckInputs(tx, state, view, true, flags, cacheSigStore, true, txdata);\n }\n \n-/**\n- * @param[out] coins_to_uncache   Return any outpoints which were not previously present in the\n- *                                coins cache, but were added as a result of validating the tx\n- *                                for mempool acceptance. This allows the caller to optionally\n- *                                remove the cache additions if the associated transaction ends\n- *                                up being rejected by the mempool.\n- */\n-static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool& pool, CValidationState& state, const CTransactionRef& ptx,\n-                              bool* pfMissingInputs, int64_t nAcceptTime, std::list<CTransactionRef>* plTxnReplaced,\n-                              bool bypass_limits, const CAmount& nAbsurdFee, std::vector<COutPoint>& coins_to_uncache, bool test_accept) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n+namespace {\n+\n+class MemPoolAccept\n {\n-    const CTransaction& tx = *ptx;\n-    const uint256 hash = tx.GetHash();\n-    AssertLockHeld(cs_main);\n-    LOCK(pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+public:\n+    MemPoolAccept(CTxMemPool& mempool) : m_pool(mempool), m_view(&m_dummy), m_viewmempool(pcoinsTip.get(), m_pool),\n+        m_limit_ancestors(gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT)),\n+        m_limit_ancestor_size(gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000),\n+        m_limit_descendants(gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT)),\n+        m_limit_descendant_size(gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000) {}\n+\n+    // We put the arguments we're handed into a struct, so we can pass them\n+    // around easier.\n+    struct ATMPArgs {\n+        const CChainParams& m_chainparams;\n+        CValidationState &m_state;\n+        bool* m_missing_inputs;\n+        const int64_t m_accept_time;\n+        std::list<CTransactionRef>* m_replaced_transactions;\n+        const bool m_bypass_limits;\n+        const CAmount& m_absurd_fee;\n+        /*\n+         * Return any outpoints which were not previously present in the coins\n+         * cache, but were added as a result of validating the tx for mempool\n+         * acceptance. This allows the caller to optionally remove the cache\n+         * additions if the associated transaction ends up being rejected by\n+         * the mempool.\n+         */\n+        std::vector<COutPoint>& m_coins_to_uncache;\n+        const bool m_test_accept;\n+    };\n+\n+    // Single transaction acceptance\n+    bool AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args) EXCLUSIVE_LOCKS_REQUIRED(cs_main);\n+\n+    // Multiple transaction acceptance\n+    bool AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args) EXCLUSIVE_LOCKS_REQUIRED(cs_main);",
      "path": "src/validation.cpp",
      "position": null,
      "original_position": 96,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": 307084354,
      "user": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Fixed.",
      "created_at": "2019-07-29T19:23:54Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r308396598",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/308396598"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 467,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/308396657",
      "pull_request_review_id": 267989256,
      "id": 308396657,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwODM5NjY1Nw==",
      "diff_hunk": "@@ -508,348 +628,532 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         }\n     }\n \n-    {\n-        CCoinsView dummy;\n-        CCoinsViewCache view(&dummy);\n-\n-        LockPoints lp;\n-        CCoinsViewMemPool viewMemPool(pcoinsTip.get(), pool);\n-        view.SetBackend(viewMemPool);\n+    LockPoints lp;\n+    m_view.SetBackend(m_viewmempool);\n \n-        // do all inputs exist?\n-        for (const CTxIn& txin : tx.vin) {\n-            if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n-                coins_to_uncache.push_back(txin.prevout);\n-            }\n-\n-            // Note: this call may add txin.prevout to the coins cache\n-            // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n-            // later (via coins_to_uncache) if this tx turns out to be invalid.\n-            if (!view.HaveCoin(txin.prevout)) {\n-                // Are inputs missing because we already have the tx?\n-                for (size_t out = 0; out < tx.vout.size(); out++) {\n-                    // Optimistically just do efficient check of cache for outputs\n-                    if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n-                        return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n-                    }\n-                }\n-                // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n-                if (pfMissingInputs) {\n-                    *pfMissingInputs = true;\n+    // do all inputs exist?\n+    for (const CTxIn& txin : tx.vin) {\n+        if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n+            coins_to_uncache.push_back(txin.prevout);\n+        }\n+\n+        // Note: this call may add txin.prevout to the coins cache\n+        // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n+        // later (via coins_to_uncache) if this tx turns out to be invalid.\n+        if (!m_view.HaveCoin(txin.prevout)) {\n+            // Are inputs missing because we already have the tx?\n+            for (size_t out = 0; out < tx.vout.size(); out++) {\n+                // Optimistically just do efficient check of cache for outputs\n+                if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n+                    return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n                 }\n-                return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n             }\n+            // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n+            if (pfMissingInputs) {\n+                *pfMissingInputs = true;\n+            }\n+            return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n         }\n+    }\n \n-        // Bring the best block into scope\n-        view.GetBestBlock();\n+    // Bring the best block into scope\n+    m_view.GetBestBlock();\n \n-        // we have all inputs cached now, so switch back to dummy, so we don't need to keep lock on mempool\n-        view.SetBackend(dummy);\n+    // we have all inputs cached now, so switch back to dummy (to protect\n+    // against bugs where we pull more inputs from disk that miss being added\n+    // to coins_to_uncache)\n+    m_view.SetBackend(m_dummy);\n \n-        // Only accept BIP68 sequence locked transactions that can be mined in the next\n-        // block; we don't want our mempool filled up with transactions that can't\n-        // be mined yet.\n-        // Must keep pool.cs for this unless we change CheckSequenceLocks to take a\n-        // CoinsViewCache instead of create its own\n-        if (!CheckSequenceLocks(pool, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n-            return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n+    // Only accept BIP68 sequence locked transactions that can be mined in the next\n+    // block; we don't want our mempool filled up with transactions that can't\n+    // be mined yet.\n+    if (!CheckSequenceLocks(m_view, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n+        return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n \n-        CAmount nFees = 0;\n-        if (!Consensus::CheckTxInputs(tx, state, view, GetSpendHeight(view), nFees)) {\n-            return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n-        }\n+    CAmount nFees = 0;\n+    if (!Consensus::CheckTxInputs(tx, state, m_view, GetSpendHeight(m_view), nFees)) {\n+        return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n+    }\n \n-        // Check for non-standard pay-to-script-hash in inputs\n-        if (fRequireStandard && !AreInputsStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n+    // Check for non-standard pay-to-script-hash in inputs\n+    if (fRequireStandard && !AreInputsStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n \n-        // Check for non-standard witness in P2WSH\n-        if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n+    // Check for non-standard witness in P2WSH\n+    if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n \n-        int64_t nSigOpsCost = GetTransactionSigOpCost(tx, view, STANDARD_SCRIPT_VERIFY_FLAGS);\n+    int64_t nSigOpsCost = GetTransactionSigOpCost(tx, m_view, STANDARD_SCRIPT_VERIFY_FLAGS);\n \n-        // nModifiedFees includes any fee deltas from PrioritiseTransaction\n-        CAmount nModifiedFees = nFees;\n-        pool.ApplyDelta(hash, nModifiedFees);\n+    // nModifiedFees includes any fee deltas from PrioritiseTransaction\n+    nModifiedFees = nFees;\n+    m_pool.ApplyDelta(hash, nModifiedFees);\n \n-        // Keep track of transactions that spend a coinbase, which we re-scan\n-        // during reorgs to ensure COINBASE_MATURITY is still met.\n-        bool fSpendsCoinbase = false;\n-        for (const CTxIn &txin : tx.vin) {\n-            const Coin &coin = view.AccessCoin(txin.prevout);\n-            if (coin.IsCoinBase()) {\n-                fSpendsCoinbase = true;\n-                break;\n-            }\n+    // Keep track of transactions that spend a coinbase, which we re-scan\n+    // during reorgs to ensure COINBASE_MATURITY is still met.\n+    bool fSpendsCoinbase = false;\n+    for (const CTxIn &txin : tx.vin) {\n+        const Coin &coin = m_view.AccessCoin(txin.prevout);\n+        if (coin.IsCoinBase()) {\n+            fSpendsCoinbase = true;\n+            break;\n         }\n+    }\n \n-        CTxMemPoolEntry entry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n-                              fSpendsCoinbase, nSigOpsCost, lp);\n-        unsigned int nSize = entry.GetTxSize();\n+    entry.reset(new CTxMemPoolEntry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n+            fSpendsCoinbase, nSigOpsCost, lp));\n+    unsigned int nSize = entry->GetTxSize();\n \n-        if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n+    if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n                 strprintf(\"%d\", nSigOpsCost));\n \n-        CAmount mempoolRejectFee = pool.GetMinFee(gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000).GetFee(nSize);\n-        if (!bypass_limits && mempoolRejectFee > 0 && nModifiedFees < mempoolRejectFee) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool min fee not met\", strprintf(\"%d < %d\", nModifiedFees, mempoolRejectFee));\n-        }\n-\n-        // No transactions are allowed below minRelayTxFee except from disconnected blocks\n-        if (!bypass_limits && nModifiedFees < ::minRelayTxFee.GetFee(nSize)) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"min relay fee not met\", strprintf(\"%d < %d\", nModifiedFees, ::minRelayTxFee.GetFee(nSize)));\n-        }\n+    // No transactions are allowed below minRelayTxFee/mempool min fee except\n+    // from disconnected blocks\n+    if (!bypass_limits && !CheckFeeRate(nSize, nModifiedFees, state)) return false;\n \n-        if (nAbsurdFee && nFees > nAbsurdFee)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n+    if (nAbsurdFee && nFees > nAbsurdFee)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n                 REJECT_HIGHFEE, \"absurdly-high-fee\",\n                 strprintf(\"%d > %d\", nFees, nAbsurdFee));\n \n-        // Calculate in-mempool ancestors, up to a limit.\n-        CTxMemPool::setEntries setAncestors;\n-        size_t nLimitAncestors = gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT);\n-        size_t nLimitAncestorSize = gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000;\n-        size_t nLimitDescendants = gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT);\n-        size_t nLimitDescendantSize = gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000;\n-        std::string errString;\n-        if (!pool.CalculateMemPoolAncestors(entry, setAncestors, nLimitAncestors, nLimitAncestorSize, nLimitDescendants, nLimitDescendantSize, errString)) {\n-            setAncestors.clear();\n-            // If the new transaction is relatively small (up to 40k weight)\n-            // and has at most one ancestor (ie ancestor limit of 2, including\n-            // the new transaction), allow it if its parent has exactly the\n-            // descendant limit descendants.\n-            //\n-            // This allows protocols which rely on distrusting counterparties\n-            // being able to broadcast descendants of an unconfirmed transaction\n-            // to be secure by simply only having two immediately-spendable\n-            // outputs - one for each counterparty. For more info on the uses for\n-            // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n-            if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n-                    !pool.CalculateMemPoolAncestors(entry, setAncestors, 2, nLimitAncestorSize, nLimitDescendants + 1, nLimitDescendantSize + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n-            }\n-        }\n-\n-        // A transaction that spends outputs that would be replaced by it is invalid. Now\n-        // that we have the set of all ancestors we can detect this\n-        // pathological case by making sure setConflicts and setAncestors don't\n-        // intersect.\n-        for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    // Calculate in-mempool ancestors, up to a limit.\n+    std::string errString;\n+    if (!m_pool.CalculateMemPoolAncestors(*entry, setAncestors, m_limit_ancestors, m_limit_ancestor_size, m_limit_descendants, m_limit_descendant_size, errString)) {\n+        setAncestors.clear();\n+        // If the new transaction is relatively small (up to 40k weight)\n+        // and has at most one ancestor (ie ancestor limit of 2, including\n+        // the new transaction), allow it if its parent has exactly the\n+        // descendant limit descendants.\n+        //\n+        // This allows protocols which rely on distrusting counterparties\n+        // being able to broadcast descendants of an unconfirmed transaction\n+        // to be secure by simply only having two immediately-spendable\n+        // outputs - one for each counterparty. For more info on the uses for\n+        // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n+        if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n+                !m_pool.CalculateMemPoolAncestors(*entry, setAncestors, 2, m_limit_ancestor_size, m_limit_descendants + 1, m_limit_descendant_size + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n+        }\n+    }\n+\n+    // A transaction that spends outputs that would be replaced by it is invalid. Now\n+    // that we have the set of all ancestors we can detect this\n+    // pathological case by making sure setConflicts and setAncestors don't\n+    // intersect.\n+    for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    {\n+        const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n+        if (setConflicts.count(hashAncestor))\n         {\n-            const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n-            if (setConflicts.count(hashAncestor))\n-            {\n-                return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n-                                 strprintf(\"%s spends conflicting transaction %s\",\n-                                           hash.ToString(),\n-                                           hashAncestor.ToString()));\n-            }\n+            return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n+                    strprintf(\"%s spends conflicting transaction %s\",\n+                        hash.ToString(),\n+                        hashAncestor.ToString()));\n         }\n+    }\n \n-        // Check if it's economically rational to mine this transaction rather\n-        // than the ones it replaces.\n-        CAmount nConflictingFees = 0;\n-        size_t nConflictingSize = 0;\n-        uint64_t nConflictingCount = 0;\n-        CTxMemPool::setEntries allConflicting;\n-\n-        // If we don't hold the lock allConflicting might be incomplete; the\n-        // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n-        // mempool consistency for us.\n-        const bool fReplacementTransaction = setConflicts.size();\n-        if (fReplacementTransaction)\n-        {\n-            CFeeRate newFeeRate(nModifiedFees, nSize);\n-            std::set<uint256> setConflictsParents;\n-            const int maxDescendantsToVisit = 100;\n-            const CTxMemPool::setEntries setIterConflicting = pool.GetIterSet(setConflicts);\n-            for (const auto& mi : setIterConflicting) {\n-                // Don't allow the replacement to reduce the feerate of the\n-                // mempool.\n-                //\n-                // We usually don't want to accept replacements with lower\n-                // feerates than what they replaced as that would lower the\n-                // feerate of the next block. Requiring that the feerate always\n-                // be increased is also an easy-to-reason about way to prevent\n-                // DoS attacks via replacements.\n-                //\n-                // We only consider the feerates of transactions being directly\n-                // replaced, not their indirect descendants. While that does\n-                // mean high feerate children are ignored when deciding whether\n-                // or not to replace, we do require the replacement to pay more\n-                // overall fees too, mitigating most cases.\n-                CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n-                if (newFeeRate <= oldFeeRate)\n-                {\n-                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                            strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n-                                  hash.ToString(),\n-                                  newFeeRate.ToString(),\n-                                  oldFeeRate.ToString()));\n-                }\n-\n-                for (const CTxIn &txin : mi->GetTx().vin)\n-                {\n-                    setConflictsParents.insert(txin.prevout.hash);\n-                }\n+    // Check if it's economically rational to mine this transaction rather\n+    // than the ones it replaces.\n+    nConflictingFees = 0;\n+    nConflictingSize = 0;\n+    uint64_t nConflictingCount = 0;\n \n-                nConflictingCount += mi->GetCountWithDescendants();\n-            }\n-            // This potentially overestimates the number of actual descendants\n-            // but we just want to be conservative to avoid doing too much\n-            // work.\n-            if (nConflictingCount <= maxDescendantsToVisit) {\n-                // If not too many to replace, then calculate the set of\n-                // transactions that would have to be evicted\n-                for (CTxMemPool::txiter it : setIterConflicting) {\n-                    pool.CalculateDescendants(it, allConflicting);\n-                }\n-                for (CTxMemPool::txiter it : allConflicting) {\n-                    nConflictingFees += it->GetModifiedFee();\n-                    nConflictingSize += it->GetTxSize();\n-                }\n-            } else {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n-                        strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+    // If we don't hold the lock allConflicting might be incomplete; the\n+    // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n+    // mempool consistency for us.\n+    fReplacementTransaction = setConflicts.size();\n+    if (fReplacementTransaction)\n+    {\n+        CFeeRate newFeeRate(nModifiedFees, nSize);\n+        std::set<uint256> setConflictsParents;\n+        const int maxDescendantsToVisit = 100;\n+        const CTxMemPool::setEntries setIterConflicting = m_pool.GetIterSet(setConflicts);\n+        for (const auto& mi : setIterConflicting) {\n+            // Don't allow the replacement to reduce the feerate of the\n+            // mempool.\n+            //\n+            // We usually don't want to accept replacements with lower\n+            // feerates than what they replaced as that would lower the\n+            // feerate of the next block. Requiring that the feerate always\n+            // be increased is also an easy-to-reason about way to prevent\n+            // DoS attacks via replacements.\n+            //\n+            // We only consider the feerates of transactions being directly\n+            // replaced, not their indirect descendants. While that does\n+            // mean high feerate children are ignored when deciding whether\n+            // or not to replace, we do require the replacement to pay more\n+            // overall fees too, mitigating most cases.\n+            CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n+            if (newFeeRate <= oldFeeRate)\n+            {\n+                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                        strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n                             hash.ToString(),\n-                            nConflictingCount,\n-                            maxDescendantsToVisit));\n+                            newFeeRate.ToString(),\n+                            oldFeeRate.ToString()));\n             }\n \n-            for (unsigned int j = 0; j < tx.vin.size(); j++)\n+            for (const CTxIn &txin : mi->GetTx().vin)\n             {\n-                // We don't want to accept replacements that require low\n-                // feerate junk to be mined first. Ideally we'd keep track of\n-                // the ancestor feerates and make the decision based on that,\n-                // but for now requiring all new inputs to be confirmed works.\n-                if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n-                {\n-                    // Rather than check the UTXO set - potentially expensive -\n-                    // it's cheaper to just check if the new input refers to a\n-                    // tx that's in the mempool.\n-                    if (pool.exists(tx.vin[j].prevout.hash)) {\n-                        return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n-                                         strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n-                                                  hash.ToString(), j));\n-                    }\n-                }\n+                setConflictsParents.insert(txin.prevout.hash);\n             }\n \n-            // The replacement must pay greater fees than the transactions it\n-            // replaces - if we did the bandwidth used by those conflicting\n-            // transactions would not be paid for.\n-            if (nModifiedFees < nConflictingFees)\n-            {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                                 strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n-                                          hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n+            nConflictingCount += mi->GetCountWithDescendants();\n+        }\n+        // This potentially overestimates the number of actual descendants\n+        // but we just want to be conservative to avoid doing too much\n+        // work.\n+        if (nConflictingCount <= maxDescendantsToVisit) {\n+            // If not too many to replace, then calculate the set of\n+            // transactions that would have to be evicted\n+            for (CTxMemPool::txiter it : setIterConflicting) {\n+                m_pool.CalculateDescendants(it, allConflicting);\n             }\n+            for (CTxMemPool::txiter it : allConflicting) {\n+                nConflictingFees += it->GetModifiedFee();\n+                nConflictingSize += it->GetTxSize();\n+            }\n+        } else {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n+                    strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+                        hash.ToString(),\n+                        nConflictingCount,\n+                        maxDescendantsToVisit));\n+        }\n \n-            // Finally in addition to paying more fees than the conflicts the\n-            // new transaction must pay for its own bandwidth.\n-            CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n-            if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        for (unsigned int j = 0; j < tx.vin.size(); j++)\n+        {\n+            // We don't want to accept replacements that require low\n+            // feerate junk to be mined first. Ideally we'd keep track of\n+            // the ancestor feerates and make the decision based on that,\n+            // but for now requiring all new inputs to be confirmed works.\n+            if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n             {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                        strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n-                              hash.ToString(),\n-                              FormatMoney(nDeltaFees),\n-                              FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n+                // Rather than check the UTXO set - potentially expensive -\n+                // it's cheaper to just check if the new input refers to a\n+                // tx that's in the mempool.\n+                if (m_pool.exists(tx.vin[j].prevout.hash)) {\n+                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n+                            strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n+                                hash.ToString(), j));\n+                }\n             }\n         }\n \n-        constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n-\n-        // Check against previous transactions\n-        // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n-        PrecomputedTransactionData txdata(tx);\n-        if (!CheckInputs(tx, state, view, true, scriptVerifyFlags, true, false, txdata)) {\n-            // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n-            // need to turn both off, and compare against just turning off CLEANSTACK\n-            // to see if the failure is specifically due to witness validation.\n-            CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n-            if (!tx.HasWitness() && CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n-                !CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n-                // Only the witness is missing, so the transaction itself may be fine.\n-                state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n-                        state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n-            }\n-            assert(IsTransactionReason(state.GetReason()));\n-            return false; // state filled in by CheckInputs\n+        // The replacement must pay greater fees than the transactions it\n+        // replaces - if we did the bandwidth used by those conflicting\n+        // transactions would not be paid for.\n+        if (nModifiedFees < nConflictingFees)\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n+                        hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n         }\n \n-        // Check again against the current block tip's script verification\n-        // flags to cache our script execution flags. This is, of course,\n-        // useless if the next block has different script flags from the\n-        // previous one, but because the cache tracks script flags for us it\n-        // will auto-invalidate and we'll just have a few blocks of extra\n-        // misses on soft-fork activation.\n-        //\n-        // This is also useful in case of bugs in the standard flags that cause\n-        // transactions to pass as valid when they're actually invalid. For\n-        // instance the STRICTENC flag was incorrectly allowing certain\n-        // CHECKSIG NOT scripts to pass, even though they were invalid.\n-        //\n-        // There is a similar check in CreateNewBlock() to prevent creating\n-        // invalid blocks (using TestBlockValidity), however allowing such\n-        // transactions into the mempool can be exploited as a DoS attack.\n-        unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n-        if (!CheckInputsFromMempoolAndCache(tx, state, view, pool, currentBlockScriptVerifyFlags, true, txdata)) {\n-            return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n-                    __func__, hash.ToString(), FormatStateMessage(state));\n+        // Finally in addition to paying more fees than the conflicts the\n+        // new transaction must pay for its own bandwidth.\n+        CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n+        if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n+                        hash.ToString(),\n+                        FormatMoney(nDeltaFees),\n+                        FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n         }\n+    }\n+    return true;\n+}\n \n-        if (test_accept) {\n-            // Tx was accepted, but not added\n-            return true;\n+bool MemPoolAccept::PolicyScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+\n+    CValidationState &state = args.m_state;\n+\n+    constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n+\n+    // Check against previous transactions\n+    // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n+    if (!CheckInputs(tx, state, m_view, true, scriptVerifyFlags, true, false, txdata)) {\n+        // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n+        // need to turn both off, and compare against just turning off CLEANSTACK\n+        // to see if the failure is specifically due to witness validation.\n+        CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n+        if (!tx.HasWitness() && CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n+                !CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n+            // Only the witness is missing, so the transaction itself may be fine.\n+            state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n+                    state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n         }\n+        assert(IsTransactionReason(state.GetReason()));\n+        return false; // state filled in by CheckInputs\n+    }\n \n-        // Remove conflicting transactions from the mempool\n-        for (CTxMemPool::txiter it : allConflicting)\n-        {\n-            LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n-                    it->GetTx().GetHash().ToString(),\n-                    hash.ToString(),\n-                    FormatMoney(nModifiedFees - nConflictingFees),\n-                    (int)nSize - (int)nConflictingSize);\n-            if (plTxnReplaced)\n-                plTxnReplaced->push_back(it->GetSharedTx());\n+    return true;\n+}\n+\n+bool MemPoolAccept::ConsensusScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+\n+    CValidationState &state = args.m_state;\n+    const CChainParams& chainparams = args.m_chainparams;\n+\n+    // Check again against the current block tip's script verification\n+    // flags to cache our script execution flags. This is, of course,\n+    // useless if the next block has different script flags from the\n+    // previous one, but because the cache tracks script flags for us it\n+    // will auto-invalidate and we'll just have a few blocks of extra\n+    // misses on soft-fork activation.\n+    //\n+    // This is also useful in case of bugs in the standard flags that cause\n+    // transactions to pass as valid when they're actually invalid. For\n+    // instance the STRICTENC flag was incorrectly allowing certain\n+    // CHECKSIG NOT scripts to pass, even though they were invalid.\n+    //\n+    // There is a similar check in CreateNewBlock() to prevent creating\n+    // invalid blocks (using TestBlockValidity), however allowing such\n+    // transactions into the mempool can be exploited as a DoS attack.\n+    unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n+    if (!CheckInputsFromMempoolAndCache(tx, state, m_view, m_pool, currentBlockScriptVerifyFlags, true, txdata)) {\n+        return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n+                __func__, hash.ToString(), FormatStateMessage(state));\n+    }\n+\n+    return true;\n+}\n+\n+bool MemPoolAccept::Finalize(ATMPArgs& args, Workspace& ws)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+    CValidationState &state = args.m_state;\n+    const bool bypass_limits = args.m_bypass_limits;\n+\n+    CTxMemPool::setEntries& allConflicting = ws.m_all_conflicting;\n+    CTxMemPool::setEntries& setAncestors = ws.m_ancestors;\n+    const CAmount& nModifiedFees = ws.m_modified_fees;\n+    const CAmount& nConflictingFees = ws.m_conflicting_fees;\n+    const size_t& nConflictingSize = ws.m_conflicting_size;\n+    const bool fReplacementTransaction = ws.m_replacement_transaction;\n+    std::unique_ptr<CTxMemPoolEntry>& entry = ws.m_entry;\n+\n+    // Remove conflicting transactions from the mempool\n+    for (CTxMemPool::txiter it : allConflicting)\n+    {\n+        LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n+                it->GetTx().GetHash().ToString(),\n+                hash.ToString(),\n+                FormatMoney(nModifiedFees - nConflictingFees),\n+                (int)entry->GetTxSize() - (int)nConflictingSize);\n+        if (args.m_replaced_transactions)\n+            args.m_replaced_transactions->push_back(it->GetSharedTx());\n+    }\n+    m_pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+\n+    // This transaction should only count for fee estimation if:\n+    // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n+    // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n+    // - the node is not behind\n+    // - the transaction is not dependent on any other transactions in the mempool\n+    bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && m_pool.HasNoInputsOf(tx);\n+\n+    // Store transaction in memory\n+    m_pool.addUnchecked(*entry, setAncestors, validForFeeEstimation);\n+\n+    // trim mempool and check if tx was trimmed\n+    if (!bypass_limits) {\n+        LimitMempoolSize(m_pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n+        if (!m_pool.exists(hash))\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    }\n+    return true;\n+}\n+\n+bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+\n+    Workspace workspace(ptx);\n+\n+    if (!PreChecks(args, workspace)) return false;\n+\n+    // Only compute the precomputed transaction data if we need to verify\n+    // scripts (ie, other policy checks pass)\n+    PrecomputedTransactionData txdata(*ptx);\n+\n+    if (!PolicyScriptChecks(args, workspace, txdata)) return false;\n+\n+    if (!ConsensusScriptChecks(args, workspace, txdata)) return false;\n+\n+    // Tx was accepted, but not added\n+    if (args.m_test_accept) return true;\n+\n+    if (!Finalize(args, workspace)) return false;\n+\n+    GetMainSignals().TransactionAddedToMempool(ptx);\n+\n+    return true;\n+}\n+\n+\n+bool MemPoolAccept::AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    // We will disable the individual transaction fee-rate checks for all\n+    // parents of the final transaction.\n+    ATMPArgs args_bypass_limits { args.m_chainparams, args.m_state, args.m_missing_inputs, args.m_accept_time, args.m_replaced_transactions, /*m_bypass_limits*/ true, args.m_absurd_fee, args.m_coins_to_uncache, args.m_test_accept };",
      "path": "src/validation.cpp",
      "position": null,
      "original_position": 860,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": 307087216,
      "user": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Looks good, done.",
      "created_at": "2019-07-29T19:24:02Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r308396657",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/308396657"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1011,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/308396715",
      "pull_request_review_id": 267989320,
      "id": 308396715,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMwODM5NjcxNQ==",
      "diff_hunk": "@@ -508,348 +628,532 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         }\n     }\n \n-    {\n-        CCoinsView dummy;\n-        CCoinsViewCache view(&dummy);\n-\n-        LockPoints lp;\n-        CCoinsViewMemPool viewMemPool(pcoinsTip.get(), pool);\n-        view.SetBackend(viewMemPool);\n+    LockPoints lp;\n+    m_view.SetBackend(m_viewmempool);\n \n-        // do all inputs exist?\n-        for (const CTxIn& txin : tx.vin) {\n-            if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n-                coins_to_uncache.push_back(txin.prevout);\n-            }\n-\n-            // Note: this call may add txin.prevout to the coins cache\n-            // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n-            // later (via coins_to_uncache) if this tx turns out to be invalid.\n-            if (!view.HaveCoin(txin.prevout)) {\n-                // Are inputs missing because we already have the tx?\n-                for (size_t out = 0; out < tx.vout.size(); out++) {\n-                    // Optimistically just do efficient check of cache for outputs\n-                    if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n-                        return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n-                    }\n-                }\n-                // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n-                if (pfMissingInputs) {\n-                    *pfMissingInputs = true;\n+    // do all inputs exist?\n+    for (const CTxIn& txin : tx.vin) {\n+        if (!pcoinsTip->HaveCoinInCache(txin.prevout)) {\n+            coins_to_uncache.push_back(txin.prevout);\n+        }\n+\n+        // Note: this call may add txin.prevout to the coins cache\n+        // (pcoinsTip.cacheCoins) by way of FetchCoin(). It should be removed\n+        // later (via coins_to_uncache) if this tx turns out to be invalid.\n+        if (!m_view.HaveCoin(txin.prevout)) {\n+            // Are inputs missing because we already have the tx?\n+            for (size_t out = 0; out < tx.vout.size(); out++) {\n+                // Optimistically just do efficient check of cache for outputs\n+                if (pcoinsTip->HaveCoinInCache(COutPoint(hash, out))) {\n+                    return state.Invalid(ValidationInvalidReason::TX_CONFLICT, false, REJECT_DUPLICATE, \"txn-already-known\");\n                 }\n-                return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n             }\n+            // Otherwise assume this might be an orphan tx for which we just haven't seen parents yet\n+            if (pfMissingInputs) {\n+                *pfMissingInputs = true;\n+            }\n+            return false; // fMissingInputs and !state.IsInvalid() is used to detect this condition, don't set state.Invalid()\n         }\n+    }\n \n-        // Bring the best block into scope\n-        view.GetBestBlock();\n+    // Bring the best block into scope\n+    m_view.GetBestBlock();\n \n-        // we have all inputs cached now, so switch back to dummy, so we don't need to keep lock on mempool\n-        view.SetBackend(dummy);\n+    // we have all inputs cached now, so switch back to dummy (to protect\n+    // against bugs where we pull more inputs from disk that miss being added\n+    // to coins_to_uncache)\n+    m_view.SetBackend(m_dummy);\n \n-        // Only accept BIP68 sequence locked transactions that can be mined in the next\n-        // block; we don't want our mempool filled up with transactions that can't\n-        // be mined yet.\n-        // Must keep pool.cs for this unless we change CheckSequenceLocks to take a\n-        // CoinsViewCache instead of create its own\n-        if (!CheckSequenceLocks(pool, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n-            return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n+    // Only accept BIP68 sequence locked transactions that can be mined in the next\n+    // block; we don't want our mempool filled up with transactions that can't\n+    // be mined yet.\n+    if (!CheckSequenceLocks(m_view, tx, STANDARD_LOCKTIME_VERIFY_FLAGS, &lp))\n+        return state.Invalid(ValidationInvalidReason::TX_PREMATURE_SPEND, false, REJECT_NONSTANDARD, \"non-BIP68-final\");\n \n-        CAmount nFees = 0;\n-        if (!Consensus::CheckTxInputs(tx, state, view, GetSpendHeight(view), nFees)) {\n-            return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n-        }\n+    CAmount nFees = 0;\n+    if (!Consensus::CheckTxInputs(tx, state, m_view, GetSpendHeight(m_view), nFees)) {\n+        return error(\"%s: Consensus::CheckTxInputs: %s, %s\", __func__, tx.GetHash().ToString(), FormatStateMessage(state));\n+    }\n \n-        // Check for non-standard pay-to-script-hash in inputs\n-        if (fRequireStandard && !AreInputsStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n+    // Check for non-standard pay-to-script-hash in inputs\n+    if (fRequireStandard && !AreInputsStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-nonstandard-inputs\");\n \n-        // Check for non-standard witness in P2WSH\n-        if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, view))\n-            return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n+    // Check for non-standard witness in P2WSH\n+    if (tx.HasWitness() && fRequireStandard && !IsWitnessStandard(tx, m_view))\n+        return state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false, REJECT_NONSTANDARD, \"bad-witness-nonstandard\");\n \n-        int64_t nSigOpsCost = GetTransactionSigOpCost(tx, view, STANDARD_SCRIPT_VERIFY_FLAGS);\n+    int64_t nSigOpsCost = GetTransactionSigOpCost(tx, m_view, STANDARD_SCRIPT_VERIFY_FLAGS);\n \n-        // nModifiedFees includes any fee deltas from PrioritiseTransaction\n-        CAmount nModifiedFees = nFees;\n-        pool.ApplyDelta(hash, nModifiedFees);\n+    // nModifiedFees includes any fee deltas from PrioritiseTransaction\n+    nModifiedFees = nFees;\n+    m_pool.ApplyDelta(hash, nModifiedFees);\n \n-        // Keep track of transactions that spend a coinbase, which we re-scan\n-        // during reorgs to ensure COINBASE_MATURITY is still met.\n-        bool fSpendsCoinbase = false;\n-        for (const CTxIn &txin : tx.vin) {\n-            const Coin &coin = view.AccessCoin(txin.prevout);\n-            if (coin.IsCoinBase()) {\n-                fSpendsCoinbase = true;\n-                break;\n-            }\n+    // Keep track of transactions that spend a coinbase, which we re-scan\n+    // during reorgs to ensure COINBASE_MATURITY is still met.\n+    bool fSpendsCoinbase = false;\n+    for (const CTxIn &txin : tx.vin) {\n+        const Coin &coin = m_view.AccessCoin(txin.prevout);\n+        if (coin.IsCoinBase()) {\n+            fSpendsCoinbase = true;\n+            break;\n         }\n+    }\n \n-        CTxMemPoolEntry entry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n-                              fSpendsCoinbase, nSigOpsCost, lp);\n-        unsigned int nSize = entry.GetTxSize();\n+    entry.reset(new CTxMemPoolEntry(ptx, nFees, nAcceptTime, ::ChainActive().Height(),\n+            fSpendsCoinbase, nSigOpsCost, lp));\n+    unsigned int nSize = entry->GetTxSize();\n \n-        if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n+    if (nSigOpsCost > MAX_STANDARD_TX_SIGOPS_COST)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n                 strprintf(\"%d\", nSigOpsCost));\n \n-        CAmount mempoolRejectFee = pool.GetMinFee(gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000).GetFee(nSize);\n-        if (!bypass_limits && mempoolRejectFee > 0 && nModifiedFees < mempoolRejectFee) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool min fee not met\", strprintf(\"%d < %d\", nModifiedFees, mempoolRejectFee));\n-        }\n-\n-        // No transactions are allowed below minRelayTxFee except from disconnected blocks\n-        if (!bypass_limits && nModifiedFees < ::minRelayTxFee.GetFee(nSize)) {\n-            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"min relay fee not met\", strprintf(\"%d < %d\", nModifiedFees, ::minRelayTxFee.GetFee(nSize)));\n-        }\n+    // No transactions are allowed below minRelayTxFee/mempool min fee except\n+    // from disconnected blocks\n+    if (!bypass_limits && !CheckFeeRate(nSize, nModifiedFees, state)) return false;\n \n-        if (nAbsurdFee && nFees > nAbsurdFee)\n-            return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n+    if (nAbsurdFee && nFees > nAbsurdFee)\n+        return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false,\n                 REJECT_HIGHFEE, \"absurdly-high-fee\",\n                 strprintf(\"%d > %d\", nFees, nAbsurdFee));\n \n-        // Calculate in-mempool ancestors, up to a limit.\n-        CTxMemPool::setEntries setAncestors;\n-        size_t nLimitAncestors = gArgs.GetArg(\"-limitancestorcount\", DEFAULT_ANCESTOR_LIMIT);\n-        size_t nLimitAncestorSize = gArgs.GetArg(\"-limitancestorsize\", DEFAULT_ANCESTOR_SIZE_LIMIT)*1000;\n-        size_t nLimitDescendants = gArgs.GetArg(\"-limitdescendantcount\", DEFAULT_DESCENDANT_LIMIT);\n-        size_t nLimitDescendantSize = gArgs.GetArg(\"-limitdescendantsize\", DEFAULT_DESCENDANT_SIZE_LIMIT)*1000;\n-        std::string errString;\n-        if (!pool.CalculateMemPoolAncestors(entry, setAncestors, nLimitAncestors, nLimitAncestorSize, nLimitDescendants, nLimitDescendantSize, errString)) {\n-            setAncestors.clear();\n-            // If the new transaction is relatively small (up to 40k weight)\n-            // and has at most one ancestor (ie ancestor limit of 2, including\n-            // the new transaction), allow it if its parent has exactly the\n-            // descendant limit descendants.\n-            //\n-            // This allows protocols which rely on distrusting counterparties\n-            // being able to broadcast descendants of an unconfirmed transaction\n-            // to be secure by simply only having two immediately-spendable\n-            // outputs - one for each counterparty. For more info on the uses for\n-            // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n-            if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n-                    !pool.CalculateMemPoolAncestors(entry, setAncestors, 2, nLimitAncestorSize, nLimitDescendants + 1, nLimitDescendantSize + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n-            }\n-        }\n-\n-        // A transaction that spends outputs that would be replaced by it is invalid. Now\n-        // that we have the set of all ancestors we can detect this\n-        // pathological case by making sure setConflicts and setAncestors don't\n-        // intersect.\n-        for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    // Calculate in-mempool ancestors, up to a limit.\n+    std::string errString;\n+    if (!m_pool.CalculateMemPoolAncestors(*entry, setAncestors, m_limit_ancestors, m_limit_ancestor_size, m_limit_descendants, m_limit_descendant_size, errString)) {\n+        setAncestors.clear();\n+        // If the new transaction is relatively small (up to 40k weight)\n+        // and has at most one ancestor (ie ancestor limit of 2, including\n+        // the new transaction), allow it if its parent has exactly the\n+        // descendant limit descendants.\n+        //\n+        // This allows protocols which rely on distrusting counterparties\n+        // being able to broadcast descendants of an unconfirmed transaction\n+        // to be secure by simply only having two immediately-spendable\n+        // outputs - one for each counterparty. For more info on the uses for\n+        // this, see https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016518.html\n+        if (nSize >  EXTRA_DESCENDANT_TX_SIZE_LIMIT ||\n+                !m_pool.CalculateMemPoolAncestors(*entry, setAncestors, 2, m_limit_ancestor_size, m_limit_descendants + 1, m_limit_descendant_size + EXTRA_DESCENDANT_TX_SIZE_LIMIT, errString)) {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-mempool-chain\", errString);\n+        }\n+    }\n+\n+    // A transaction that spends outputs that would be replaced by it is invalid. Now\n+    // that we have the set of all ancestors we can detect this\n+    // pathological case by making sure setConflicts and setAncestors don't\n+    // intersect.\n+    for (CTxMemPool::txiter ancestorIt : setAncestors)\n+    {\n+        const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n+        if (setConflicts.count(hashAncestor))\n         {\n-            const uint256 &hashAncestor = ancestorIt->GetTx().GetHash();\n-            if (setConflicts.count(hashAncestor))\n-            {\n-                return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n-                                 strprintf(\"%s spends conflicting transaction %s\",\n-                                           hash.ToString(),\n-                                           hashAncestor.ToString()));\n-            }\n+            return state.Invalid(ValidationInvalidReason::CONSENSUS, false, REJECT_INVALID, \"bad-txns-spends-conflicting-tx\",\n+                    strprintf(\"%s spends conflicting transaction %s\",\n+                        hash.ToString(),\n+                        hashAncestor.ToString()));\n         }\n+    }\n \n-        // Check if it's economically rational to mine this transaction rather\n-        // than the ones it replaces.\n-        CAmount nConflictingFees = 0;\n-        size_t nConflictingSize = 0;\n-        uint64_t nConflictingCount = 0;\n-        CTxMemPool::setEntries allConflicting;\n-\n-        // If we don't hold the lock allConflicting might be incomplete; the\n-        // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n-        // mempool consistency for us.\n-        const bool fReplacementTransaction = setConflicts.size();\n-        if (fReplacementTransaction)\n-        {\n-            CFeeRate newFeeRate(nModifiedFees, nSize);\n-            std::set<uint256> setConflictsParents;\n-            const int maxDescendantsToVisit = 100;\n-            const CTxMemPool::setEntries setIterConflicting = pool.GetIterSet(setConflicts);\n-            for (const auto& mi : setIterConflicting) {\n-                // Don't allow the replacement to reduce the feerate of the\n-                // mempool.\n-                //\n-                // We usually don't want to accept replacements with lower\n-                // feerates than what they replaced as that would lower the\n-                // feerate of the next block. Requiring that the feerate always\n-                // be increased is also an easy-to-reason about way to prevent\n-                // DoS attacks via replacements.\n-                //\n-                // We only consider the feerates of transactions being directly\n-                // replaced, not their indirect descendants. While that does\n-                // mean high feerate children are ignored when deciding whether\n-                // or not to replace, we do require the replacement to pay more\n-                // overall fees too, mitigating most cases.\n-                CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n-                if (newFeeRate <= oldFeeRate)\n-                {\n-                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                            strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n-                                  hash.ToString(),\n-                                  newFeeRate.ToString(),\n-                                  oldFeeRate.ToString()));\n-                }\n-\n-                for (const CTxIn &txin : mi->GetTx().vin)\n-                {\n-                    setConflictsParents.insert(txin.prevout.hash);\n-                }\n+    // Check if it's economically rational to mine this transaction rather\n+    // than the ones it replaces.\n+    nConflictingFees = 0;\n+    nConflictingSize = 0;\n+    uint64_t nConflictingCount = 0;\n \n-                nConflictingCount += mi->GetCountWithDescendants();\n-            }\n-            // This potentially overestimates the number of actual descendants\n-            // but we just want to be conservative to avoid doing too much\n-            // work.\n-            if (nConflictingCount <= maxDescendantsToVisit) {\n-                // If not too many to replace, then calculate the set of\n-                // transactions that would have to be evicted\n-                for (CTxMemPool::txiter it : setIterConflicting) {\n-                    pool.CalculateDescendants(it, allConflicting);\n-                }\n-                for (CTxMemPool::txiter it : allConflicting) {\n-                    nConflictingFees += it->GetModifiedFee();\n-                    nConflictingSize += it->GetTxSize();\n-                }\n-            } else {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n-                        strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+    // If we don't hold the lock allConflicting might be incomplete; the\n+    // subsequent RemoveStaged() and addUnchecked() calls don't guarantee\n+    // mempool consistency for us.\n+    fReplacementTransaction = setConflicts.size();\n+    if (fReplacementTransaction)\n+    {\n+        CFeeRate newFeeRate(nModifiedFees, nSize);\n+        std::set<uint256> setConflictsParents;\n+        const int maxDescendantsToVisit = 100;\n+        const CTxMemPool::setEntries setIterConflicting = m_pool.GetIterSet(setConflicts);\n+        for (const auto& mi : setIterConflicting) {\n+            // Don't allow the replacement to reduce the feerate of the\n+            // mempool.\n+            //\n+            // We usually don't want to accept replacements with lower\n+            // feerates than what they replaced as that would lower the\n+            // feerate of the next block. Requiring that the feerate always\n+            // be increased is also an easy-to-reason about way to prevent\n+            // DoS attacks via replacements.\n+            //\n+            // We only consider the feerates of transactions being directly\n+            // replaced, not their indirect descendants. While that does\n+            // mean high feerate children are ignored when deciding whether\n+            // or not to replace, we do require the replacement to pay more\n+            // overall fees too, mitigating most cases.\n+            CFeeRate oldFeeRate(mi->GetModifiedFee(), mi->GetTxSize());\n+            if (newFeeRate <= oldFeeRate)\n+            {\n+                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                        strprintf(\"rejecting replacement %s; new feerate %s <= old feerate %s\",\n                             hash.ToString(),\n-                            nConflictingCount,\n-                            maxDescendantsToVisit));\n+                            newFeeRate.ToString(),\n+                            oldFeeRate.ToString()));\n             }\n \n-            for (unsigned int j = 0; j < tx.vin.size(); j++)\n+            for (const CTxIn &txin : mi->GetTx().vin)\n             {\n-                // We don't want to accept replacements that require low\n-                // feerate junk to be mined first. Ideally we'd keep track of\n-                // the ancestor feerates and make the decision based on that,\n-                // but for now requiring all new inputs to be confirmed works.\n-                if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n-                {\n-                    // Rather than check the UTXO set - potentially expensive -\n-                    // it's cheaper to just check if the new input refers to a\n-                    // tx that's in the mempool.\n-                    if (pool.exists(tx.vin[j].prevout.hash)) {\n-                        return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n-                                         strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n-                                                  hash.ToString(), j));\n-                    }\n-                }\n+                setConflictsParents.insert(txin.prevout.hash);\n             }\n \n-            // The replacement must pay greater fees than the transactions it\n-            // replaces - if we did the bandwidth used by those conflicting\n-            // transactions would not be paid for.\n-            if (nModifiedFees < nConflictingFees)\n-            {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                                 strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n-                                          hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n+            nConflictingCount += mi->GetCountWithDescendants();\n+        }\n+        // This potentially overestimates the number of actual descendants\n+        // but we just want to be conservative to avoid doing too much\n+        // work.\n+        if (nConflictingCount <= maxDescendantsToVisit) {\n+            // If not too many to replace, then calculate the set of\n+            // transactions that would have to be evicted\n+            for (CTxMemPool::txiter it : setIterConflicting) {\n+                m_pool.CalculateDescendants(it, allConflicting);\n             }\n+            for (CTxMemPool::txiter it : allConflicting) {\n+                nConflictingFees += it->GetModifiedFee();\n+                nConflictingSize += it->GetTxSize();\n+            }\n+        } else {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too many potential replacements\",\n+                    strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n+                        hash.ToString(),\n+                        nConflictingCount,\n+                        maxDescendantsToVisit));\n+        }\n \n-            // Finally in addition to paying more fees than the conflicts the\n-            // new transaction must pay for its own bandwidth.\n-            CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n-            if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        for (unsigned int j = 0; j < tx.vin.size(); j++)\n+        {\n+            // We don't want to accept replacements that require low\n+            // feerate junk to be mined first. Ideally we'd keep track of\n+            // the ancestor feerates and make the decision based on that,\n+            // but for now requiring all new inputs to be confirmed works.\n+            if (!setConflictsParents.count(tx.vin[j].prevout.hash))\n             {\n-                return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n-                        strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n-                              hash.ToString(),\n-                              FormatMoney(nDeltaFees),\n-                              FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n+                // Rather than check the UTXO set - potentially expensive -\n+                // it's cheaper to just check if the new input refers to a\n+                // tx that's in the mempool.\n+                if (m_pool.exists(tx.vin[j].prevout.hash)) {\n+                    return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"replacement-adds-unconfirmed\",\n+                            strprintf(\"replacement %s adds unconfirmed input, idx %d\",\n+                                hash.ToString(), j));\n+                }\n             }\n         }\n \n-        constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n-\n-        // Check against previous transactions\n-        // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n-        PrecomputedTransactionData txdata(tx);\n-        if (!CheckInputs(tx, state, view, true, scriptVerifyFlags, true, false, txdata)) {\n-            // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n-            // need to turn both off, and compare against just turning off CLEANSTACK\n-            // to see if the failure is specifically due to witness validation.\n-            CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n-            if (!tx.HasWitness() && CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n-                !CheckInputs(tx, stateDummy, view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n-                // Only the witness is missing, so the transaction itself may be fine.\n-                state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n-                        state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n-            }\n-            assert(IsTransactionReason(state.GetReason()));\n-            return false; // state filled in by CheckInputs\n+        // The replacement must pay greater fees than the transactions it\n+        // replaces - if we did the bandwidth used by those conflicting\n+        // transactions would not be paid for.\n+        if (nModifiedFees < nConflictingFees)\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, less fees than conflicting txs; %s < %s\",\n+                        hash.ToString(), FormatMoney(nModifiedFees), FormatMoney(nConflictingFees)));\n         }\n \n-        // Check again against the current block tip's script verification\n-        // flags to cache our script execution flags. This is, of course,\n-        // useless if the next block has different script flags from the\n-        // previous one, but because the cache tracks script flags for us it\n-        // will auto-invalidate and we'll just have a few blocks of extra\n-        // misses on soft-fork activation.\n-        //\n-        // This is also useful in case of bugs in the standard flags that cause\n-        // transactions to pass as valid when they're actually invalid. For\n-        // instance the STRICTENC flag was incorrectly allowing certain\n-        // CHECKSIG NOT scripts to pass, even though they were invalid.\n-        //\n-        // There is a similar check in CreateNewBlock() to prevent creating\n-        // invalid blocks (using TestBlockValidity), however allowing such\n-        // transactions into the mempool can be exploited as a DoS attack.\n-        unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n-        if (!CheckInputsFromMempoolAndCache(tx, state, view, pool, currentBlockScriptVerifyFlags, true, txdata)) {\n-            return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n-                    __func__, hash.ToString(), FormatStateMessage(state));\n+        // Finally in addition to paying more fees than the conflicts the\n+        // new transaction must pay for its own bandwidth.\n+        CAmount nDeltaFees = nModifiedFees - nConflictingFees;\n+        if (nDeltaFees < ::incrementalRelayFee.GetFee(nSize))\n+        {\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"insufficient fee\",\n+                    strprintf(\"rejecting replacement %s, not enough additional fees to relay; %s < %s\",\n+                        hash.ToString(),\n+                        FormatMoney(nDeltaFees),\n+                        FormatMoney(::incrementalRelayFee.GetFee(nSize))));\n         }\n+    }\n+    return true;\n+}\n \n-        if (test_accept) {\n-            // Tx was accepted, but not added\n-            return true;\n+bool MemPoolAccept::PolicyScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+\n+    CValidationState &state = args.m_state;\n+\n+    constexpr unsigned int scriptVerifyFlags = STANDARD_SCRIPT_VERIFY_FLAGS;\n+\n+    // Check against previous transactions\n+    // This is done last to help prevent CPU exhaustion denial-of-service attacks.\n+    if (!CheckInputs(tx, state, m_view, true, scriptVerifyFlags, true, false, txdata)) {\n+        // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\n+        // need to turn both off, and compare against just turning off CLEANSTACK\n+        // to see if the failure is specifically due to witness validation.\n+        CValidationState stateDummy; // Want reported failures to be from first CheckInputs\n+        if (!tx.HasWitness() && CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, txdata) &&\n+                !CheckInputs(tx, stateDummy, m_view, true, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, txdata)) {\n+            // Only the witness is missing, so the transaction itself may be fine.\n+            state.Invalid(ValidationInvalidReason::TX_WITNESS_MUTATED, false,\n+                    state.GetRejectCode(), state.GetRejectReason(), state.GetDebugMessage());\n         }\n+        assert(IsTransactionReason(state.GetReason()));\n+        return false; // state filled in by CheckInputs\n+    }\n \n-        // Remove conflicting transactions from the mempool\n-        for (CTxMemPool::txiter it : allConflicting)\n-        {\n-            LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n-                    it->GetTx().GetHash().ToString(),\n-                    hash.ToString(),\n-                    FormatMoney(nModifiedFees - nConflictingFees),\n-                    (int)nSize - (int)nConflictingSize);\n-            if (plTxnReplaced)\n-                plTxnReplaced->push_back(it->GetSharedTx());\n+    return true;\n+}\n+\n+bool MemPoolAccept::ConsensusScriptChecks(ATMPArgs& args, Workspace& ws, PrecomputedTransactionData& txdata)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+\n+    CValidationState &state = args.m_state;\n+    const CChainParams& chainparams = args.m_chainparams;\n+\n+    // Check again against the current block tip's script verification\n+    // flags to cache our script execution flags. This is, of course,\n+    // useless if the next block has different script flags from the\n+    // previous one, but because the cache tracks script flags for us it\n+    // will auto-invalidate and we'll just have a few blocks of extra\n+    // misses on soft-fork activation.\n+    //\n+    // This is also useful in case of bugs in the standard flags that cause\n+    // transactions to pass as valid when they're actually invalid. For\n+    // instance the STRICTENC flag was incorrectly allowing certain\n+    // CHECKSIG NOT scripts to pass, even though they were invalid.\n+    //\n+    // There is a similar check in CreateNewBlock() to prevent creating\n+    // invalid blocks (using TestBlockValidity), however allowing such\n+    // transactions into the mempool can be exploited as a DoS attack.\n+    unsigned int currentBlockScriptVerifyFlags = GetBlockScriptFlags(::ChainActive().Tip(), chainparams.GetConsensus());\n+    if (!CheckInputsFromMempoolAndCache(tx, state, m_view, m_pool, currentBlockScriptVerifyFlags, true, txdata)) {\n+        return error(\"%s: BUG! PLEASE REPORT THIS! CheckInputs failed against latest-block but not STANDARD flags %s, %s\",\n+                __func__, hash.ToString(), FormatStateMessage(state));\n+    }\n+\n+    return true;\n+}\n+\n+bool MemPoolAccept::Finalize(ATMPArgs& args, Workspace& ws)\n+{\n+    const CTransaction& tx = *ws.m_ptx;\n+    const uint256& hash = ws.m_hash;\n+    CValidationState &state = args.m_state;\n+    const bool bypass_limits = args.m_bypass_limits;\n+\n+    CTxMemPool::setEntries& allConflicting = ws.m_all_conflicting;\n+    CTxMemPool::setEntries& setAncestors = ws.m_ancestors;\n+    const CAmount& nModifiedFees = ws.m_modified_fees;\n+    const CAmount& nConflictingFees = ws.m_conflicting_fees;\n+    const size_t& nConflictingSize = ws.m_conflicting_size;\n+    const bool fReplacementTransaction = ws.m_replacement_transaction;\n+    std::unique_ptr<CTxMemPoolEntry>& entry = ws.m_entry;\n+\n+    // Remove conflicting transactions from the mempool\n+    for (CTxMemPool::txiter it : allConflicting)\n+    {\n+        LogPrint(BCLog::MEMPOOL, \"replacing tx %s with %s for %s BTC additional fees, %d delta bytes\\n\",\n+                it->GetTx().GetHash().ToString(),\n+                hash.ToString(),\n+                FormatMoney(nModifiedFees - nConflictingFees),\n+                (int)entry->GetTxSize() - (int)nConflictingSize);\n+        if (args.m_replaced_transactions)\n+            args.m_replaced_transactions->push_back(it->GetSharedTx());\n+    }\n+    m_pool.RemoveStaged(allConflicting, false, MemPoolRemovalReason::REPLACED);\n+\n+    // This transaction should only count for fee estimation if:\n+    // - it isn't a BIP 125 replacement transaction (may not be widely supported)\n+    // - it's not being re-added during a reorg which bypasses typical mempool fee limits\n+    // - the node is not behind\n+    // - the transaction is not dependent on any other transactions in the mempool\n+    bool validForFeeEstimation = !fReplacementTransaction && !bypass_limits && IsCurrentForFeeEstimation() && m_pool.HasNoInputsOf(tx);\n+\n+    // Store transaction in memory\n+    m_pool.addUnchecked(*entry, setAncestors, validForFeeEstimation);\n+\n+    // trim mempool and check if tx was trimmed\n+    if (!bypass_limits) {\n+        LimitMempoolSize(m_pool, gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000, gArgs.GetArg(\"-mempoolexpiry\", DEFAULT_MEMPOOL_EXPIRY) * 60 * 60);\n+        if (!m_pool.exists(hash))\n+            return state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_INSUFFICIENTFEE, \"mempool full\");\n+    }\n+    return true;\n+}\n+\n+bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs); // mempool \"read lock\" (held through GetMainSignals().TransactionAddedToMempool())\n+\n+    Workspace workspace(ptx);\n+\n+    if (!PreChecks(args, workspace)) return false;\n+\n+    // Only compute the precomputed transaction data if we need to verify\n+    // scripts (ie, other policy checks pass)\n+    PrecomputedTransactionData txdata(*ptx);\n+\n+    if (!PolicyScriptChecks(args, workspace, txdata)) return false;\n+\n+    if (!ConsensusScriptChecks(args, workspace, txdata)) return false;\n+\n+    // Tx was accepted, but not added\n+    if (args.m_test_accept) return true;\n+\n+    if (!Finalize(args, workspace)) return false;\n+\n+    GetMainSignals().TransactionAddedToMempool(ptx);\n+\n+    return true;\n+}\n+\n+\n+bool MemPoolAccept::AcceptMultipleTransactions(std::list<CTransactionRef> tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    // We will disable the individual transaction fee-rate checks for all\n+    // parents of the final transaction.\n+    ATMPArgs args_bypass_limits { args.m_chainparams, args.m_state, args.m_missing_inputs, args.m_accept_time, args.m_replaced_transactions, /*m_bypass_limits*/ true, args.m_absurd_fee, args.m_coins_to_uncache, args.m_test_accept };\n+    std::list<Workspace> tx_workspaces;\n+\n+    for (const CTransactionRef& ptx : tx_list) {\n+        tx_workspaces.emplace_back(Workspace(ptx));",
      "path": "src/validation.cpp",
      "position": null,
      "original_position": 864,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "149930d74686c58f1addc2367c467a71aff90033",
      "in_reply_to_id": 307087452,
      "user": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Agreed.",
      "created_at": "2019-07-29T19:24:08Z",
      "updated_at": "2020-01-09T03:56:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r308396715",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/308396715"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1015,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/329457822",
      "pull_request_review_id": 294815427,
      "id": 329457822,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMyOTQ1NzgyMg==",
      "diff_hunk": "@@ -751,8 +751,12 @@ class CTxMemPool\n  */\n class CCoinsViewMemPool : public CCoinsViewBacked\n {\n+public:\n+    void AddPotentialTransaction(const CTransactionRef& ptx) { package_tx.emplace(ptx->GetHash(), ptx); }",
      "path": "src/txmempool.h",
      "position": 5,
      "original_position": 5,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "cd8f11aaaa7dd27f95af3d4cb85ff7c7607e76f9",
      "in_reply_to_id": null,
      "user": {
        "login": "NicolasDorier",
        "id": 3020646,
        "node_id": "MDQ6VXNlcjMwMjA2NDY=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3020646?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/NicolasDorier",
        "html_url": "https://github.com/NicolasDorier",
        "followers_url": "https://api.github.com/users/NicolasDorier/followers",
        "following_url": "https://api.github.com/users/NicolasDorier/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/NicolasDorier/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/NicolasDorier/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/NicolasDorier/subscriptions",
        "organizations_url": "https://api.github.com/users/NicolasDorier/orgs",
        "repos_url": "https://api.github.com/users/NicolasDorier/repos",
        "events_url": "https://api.github.com/users/NicolasDorier/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/NicolasDorier/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "As far as I see, in the current code code paths, the max number of elements in `package_tx` is two.\r\nBut maybe there should be a hard limit, even if high, at this level just in case?",
      "created_at": "2019-09-30T08:21:36Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r329457822",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/329457822"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 756,
      "original_line": 756,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/330106204",
      "pull_request_review_id": 295669946,
      "id": 330106204,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMzMDEwNjIwNA==",
      "diff_hunk": "@@ -1046,6 +1055,146 @@ bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs\n     return true;\n }\n \n+\n+bool MemPoolAccept::AcceptMultipleTransactions(const std::list<CTransactionRef>& tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    std::list<Workspace> tx_workspaces;\n+\n+    for (const CTransactionRef& ptx : tx_list) {\n+        // The last transaction must be validated for making it past the fee\n+        // checks on its own, to prevent packages from including low-fee,\n+        // unnecessary children that are attached to higher fee parents.\n+        tx_workspaces.emplace_back(Workspace(ptx, ptx != tx_list.back()));\n+        Workspace &ws = tx_workspaces.back();\n+\n+        if (!PreChecks(args, ws)) return false;\n+\n+        // For now, do not allow replacements in package transactions. If we\n+        // relax this, we would need to check that no child transaction depends\n+        // on any in-mempool transaction that conflicts with any package\n+        // transaction.\n+        if (!ws.m_conflicts.empty()) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"rbf-disallowed-in-package\", strprintf(\"mempool conflicts with tx %s\", ptx->GetHash().ToString()));\n+        }\n+        // Add this transaction to our coinsview, so that subsequent\n+        // transactions in this package will have their inputs available.\n+        m_viewmempool.AddPotentialTransaction(ptx);\n+    }\n+\n+    // Check overall package feerate\n+    size_t total_size=0;\n+    CAmount total_fee=0;\n+    uint64_t total_count = tx_list.size();\n+    for (const Workspace& ws : tx_workspaces) {\n+        total_size += ws.m_entry->GetTxSize();\n+        total_fee += ws.m_modified_fees;\n+    }\n+    if (!CheckFeeRate(total_size, total_fee, args.m_state)) return false;\n+\n+    // The ancestor/descendant limit calculations in PreChecks() will be overly\n+    // permissive, because not all ancestors will be known as we descend down\n+    // the package. Thus the ancestor checks done by\n+    // CalculateMemPoolAncestors() will be incomplete. If any ancestor or\n+    // descendant limit is violated in one of those checks, however, we know\n+    // the package will not be accepted when we include all ancestors, as the\n+    // ancestor/descendant size/counts only go up as we add more ancestors to\n+    // each transaction.\n+    // We will end up needing to recalculate setAncestors for each transaction\n+    // prior to calling Finalize, but we should do the correct package-size\n+    // calculations before we call ScriptChecks(), to avoid CPU-DoS.\n+\n+    // For now, do something conservative -- assume that the union of ancestors\n+    // of each transaction is an ancestor of every transaction, for package\n+    // size purposes.\n+    CTxMemPool::setEntries all_ancestors;\n+    for (const Workspace& ws : tx_workspaces) {\n+        all_ancestors.insert(ws.m_ancestors.begin(), ws.m_ancestors.end());\n+    }\n+\n+    if (total_count + all_ancestors.size() > m_limit_ancestors) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor count limit [package: %u limit: %u]\", total_count + all_ancestors.size(), m_limit_ancestors));\n+    }\n+\n+    // Check the package limits for every ancestor, assuming the whole package\n+    // descends from each.\n+    size_t ancestor_size = total_size;\n+    for (auto tx_iter : all_ancestors) {\n+        if (tx_iter->GetSizeWithDescendants() + total_size > m_limit_descendant_size) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendant_size));\n+        }\n+        if (tx_iter->GetCountWithDescendants() + total_count > m_limit_descendants) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendants));\n+        }\n+        ancestor_size += tx_iter->GetTxSize();\n+    }\n+\n+    // In case we have no in-mempool ancestors, we must check the transaction\n+    // package itself.\n+    if (total_size > m_limit_descendant_size) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_list.front()->GetHash().ToString(), m_limit_descendant_size));\n+    }\n+    if (ancestor_size > m_limit_ancestor_size) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor size limit for tx %s [limit: %u]\", tx_list.back()->GetHash().ToString(), m_limit_ancestor_size));\n+    }\n+\n+    // Make sure all transactions are ancestors of the last one.\n+    // For now, just check that the last transaction has all prior transactions\n+    // as direct inputs. We can relax this in the future for bigger packages.\n+    std::set<uint256> last_tx_parents;\n+    for (auto input : tx_list.back()->vin) {\n+        last_tx_parents.insert(input.prevout.hash);\n+    }\n+    for (auto ptx : tx_list) {\n+        if (ptx == tx_list.back()) break;\n+        if (last_tx_parents.count(ptx->GetHash()) == 0) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"non-standard-package-chain\", \"only direct parents are allowed in package\");\n+        }\n+    }\n+\n+    // Do the script checks after all policy checks are done\n+    std::vector<PrecomputedTransactionData> txdata;\n+    txdata.reserve(tx_list.size());\n+    for (auto wit = tx_workspaces.begin(); wit != tx_workspaces.end(); ++wit) {\n+        txdata.emplace_back(*wit->m_ptx);\n+        if (!PolicyScriptChecks(args, *wit, txdata.back())) return false;\n+    }\n+\n+    // This package should be accepted except possibly for failing in\n+    // TrimToSize(), which we can't exercise without actually adding to the\n+    // mempool and seeing what would happen. Note that we are not adding\n+    // these transactions to the script cache, unlike in the single-tx case.\n+    if (args.m_test_accept) return true;\n+\n+    // Add everything to the mempool, and make sure the last transaction makes\n+    // it in.\n+    size_t i=0;\n+    for (auto wit = tx_workspaces.begin(); wit != tx_workspaces.end(); ++wit, ++i) {\n+        // Recheck the scripts with consensus flags and cache script execution\n+        // success. We have to wait until all the inputs are in the mempool or\n+        // in the utxo set (for now) before we can invoke this. This should\n+        // not fail unless there's a logic bug in our script validation, but if\n+        // it somehow were to fail on some child tx, we would potentially be\n+        // allowing parents into the mempool with this logic.\n+        if (!ConsensusScriptChecks(args, *wit, txdata[i])) return false;\n+\n+        // Recalculate ancestors for every transaction after the first, because\n+        // previously the ancestor sets were missing package transactions that\n+        // were not yet in the mempool at the time PreChecks() was called.\n+        if (wit != tx_workspaces.begin()) {\n+            wit->m_ancestors.clear();\n+            std::string dummy_string;\n+            // Don't worry about the return value here; it must pass based on\n+            // the checks above. TODO: assert on passing?\n+            m_pool.CalculateMemPoolAncestors(*(wit->m_entry), wit->m_ancestors, m_limit_ancestors, m_limit_ancestor_size, m_limit_descendants, m_limit_descendant_size, dummy_string);",
      "path": "src/validation.cpp",
      "position": 278,
      "original_position": 264,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "92cc72905ab15f4474b055da95f5a45b7e8b90c8",
      "in_reply_to_id": null,
      "user": {
        "login": "etscrivner",
        "id": 69561,
        "node_id": "MDQ6VXNlcjY5NTYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/69561?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/etscrivner",
        "html_url": "https://github.com/etscrivner",
        "followers_url": "https://api.github.com/users/etscrivner/followers",
        "following_url": "https://api.github.com/users/etscrivner/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/etscrivner/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/etscrivner/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/etscrivner/subscriptions",
        "organizations_url": "https://api.github.com/users/etscrivner/orgs",
        "repos_url": "https://api.github.com/users/etscrivner/repos",
        "events_url": "https://api.github.com/users/etscrivner/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/etscrivner/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "This is probably also a good spot for a `DCHECK` just to ensure that the assumption - \"this must pass based on the checks above\" - holds here.",
      "created_at": "2019-10-01T14:57:05Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r330106204",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/330106204"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1178,
      "original_line": 1178,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/330552914",
      "pull_request_review_id": 296243224,
      "id": 330552914,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMzMDU1MjkxNA==",
      "diff_hunk": "@@ -0,0 +1,113 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test processing of two-transaction packages\"\"\"\n+\n+from decimal import Decimal\n+from test_framework.messages import FromHex, CTransaction, msg_witness_tx\n+from test_framework.mininode import P2PInterface\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+# P2PInterface is a class containing callbacks to be executed when a P2P\n+# message is received from the node-under-test. Subclass P2PInterface and\n+# override the on_*() methods if you need custom behaviour.\n+class BaseNode(P2PInterface):\n+    def __init__(self):\n+        \"\"\"Initialize the P2PInterface\n+\n+        Used to initialize custom properties for the Node that aren't\n+        included by default in the base class. Be aware that the P2PInterface\n+        base class already stores a counter for each P2P message type and the\n+        last received message of each type, which should be sufficient for the\n+        needs of most tests.\n+\n+        Call super().__init__() first for standard initialization and then\n+        initialize custom properties.\"\"\"\n+        super().__init__()\n+        # Stores a dictionary of all blocks received\n+\n+    def on_block(self, message):\n+        \"\"\"Override the standard on_block callback\n+\n+        Store the hash of a received block in the dictionary.\"\"\"\n+        message.block.calc_sha256()\n+        self.block_receive_map[message.block.sha256] += 1\n+\n+    def on_inv(self, message):\n+        \"\"\"Override the standard on_inv callback\"\"\"\n+        pass\n+\n+\n+class PackageRelay(BitcoinTestFramework):\n+    # Each functional test is a subclass of the BitcoinTestFramework class.\n+\n+    # Override the set_test_params(), skip_test_if_missing_module(), add_options(), setup_chain(), setup_network()\n+    # and setup_nodes() methods to customize the test setup as required.\n+\n+    def set_test_params(self):\n+        \"\"\"Override test parameters for your individual test.\n+\n+        This method must be overridden and num_nodes must be explicitly set.\"\"\"\n+        self.setup_clean_chain = True\n+        self.num_nodes = 2\n+        self.extra_args = [[], [\"-minrelaytxfee=0\", \"-mintxfee=0.00000001\"]]\n+\n+\n+    # Use skip_test_if_missing_module() to skip the test if your test requires certain modules to be present.\n+    # This test uses generate which requires wallet to be compiled\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+\n+    def run_test(self):\n+        \"\"\"Main test logic\"\"\"\n+\n+        # Create P2P connections will wait for a verack to make sure the connection is fully up\n+        self.nodes[0].add_p2p_connection(BaseNode())\n+\n+        self.nodes[1].generate(101)\n+        self.sync_all(self.nodes[0:2])\n+\n+        # On node1, generate a 0-fee transaction, and then a 2-satoshi-per-byte",
      "path": "test/functional/feature_package_relay.py",
      "position": null,
      "original_position": 72,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "cd8f11aaaa7dd27f95af3d4cb85ff7c7607e76f9",
      "in_reply_to_id": null,
      "user": {
        "login": "pinheadmz",
        "id": 2084648,
        "node_id": "MDQ6VXNlcjIwODQ2NDg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2084648?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/pinheadmz",
        "html_url": "https://github.com/pinheadmz",
        "followers_url": "https://api.github.com/users/pinheadmz/followers",
        "following_url": "https://api.github.com/users/pinheadmz/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/pinheadmz/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/pinheadmz/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/pinheadmz/subscriptions",
        "organizations_url": "https://api.github.com/users/pinheadmz/orgs",
        "repos_url": "https://api.github.com/users/pinheadmz/repos",
        "events_url": "https://api.github.com/users/pinheadmz/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/pinheadmz/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "I might be misunderstanding, but it looks like the _first_ tx fee rate is set to 2 sat/kB (actual total fee on this tx comes out to a single sat) and the second tx fee rate is set to 50000 (actual total fee ~0.000083)?",
      "created_at": "2019-10-02T13:37:22Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r330552914",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/330552914"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 72,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/330645988",
      "pull_request_review_id": 296364219,
      "id": 330645988,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMzMDY0NTk4OA==",
      "diff_hunk": "@@ -2572,33 +2579,79 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n                 recentRejects->insert(tx.GetHash());\n             }\n         } else {\n-            assert(IsTransactionReason(state.GetReason()));\n-            if (!tx.HasWitness() && state.GetReason() != ValidationInvalidReason::TX_WITNESS_MUTATED) {\n-                // Do not use rejection cache for witness transactions or\n-                // witness-stripped transactions, as they can have been malleated.\n-                // See https://github.com/bitcoin/bitcoin/issues/8279 for details.\n-                assert(recentRejects);\n-                recentRejects->insert(tx.GetHash());\n-                if (RecursiveDynamicUsage(*ptx) < 100000) {\n-                    AddToCompactExtraTransactions(ptx);\n+            // If this tx didn't make it in due to feerate, and there is a tx\n+            // in the orphan pool -- then maybe that tx is only missing this\n+            // one parent.\n+            // Try to process the pair as a package.\n+            bool added_as_package = false;\n+            if (state.GetRejectCode() == REJECT_INSUFFICIENTFEE) {",
      "path": "src/net_processing.cpp",
      "position": null,
      "original_position": 57,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "cd8f11aaaa7dd27f95af3d4cb85ff7c7607e76f9",
      "in_reply_to_id": null,
      "user": {
        "login": "fjahr",
        "id": 1322187,
        "node_id": "MDQ6VXNlcjEzMjIxODc=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1322187?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fjahr",
        "html_url": "https://github.com/fjahr",
        "followers_url": "https://api.github.com/users/fjahr/followers",
        "following_url": "https://api.github.com/users/fjahr/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fjahr/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fjahr/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fjahr/subscriptions",
        "organizations_url": "https://api.github.com/users/fjahr/orgs",
        "repos_url": "https://api.github.com/users/fjahr/repos",
        "events_url": "https://api.github.com/users/fjahr/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fjahr/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Maybe also add a check for `g_orphan_list.size() > 0` here? But I am not experienced with the orphan pool so it may be fair to leave it out if the orphan pool is populated 99% of the time.",
      "created_at": "2019-10-02T16:22:52Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r330645988",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/330645988"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 2587,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/330675635",
      "pull_request_review_id": 296401552,
      "id": 330675635,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDMzMDY3NTYzNQ==",
      "diff_hunk": "@@ -0,0 +1,113 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test processing of two-transaction packages\"\"\"\n+\n+from decimal import Decimal\n+from test_framework.messages import FromHex, CTransaction, msg_witness_tx\n+from test_framework.mininode import P2PInterface\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+# P2PInterface is a class containing callbacks to be executed when a P2P\n+# message is received from the node-under-test. Subclass P2PInterface and\n+# override the on_*() methods if you need custom behaviour.\n+class BaseNode(P2PInterface):\n+    def __init__(self):\n+        \"\"\"Initialize the P2PInterface\n+\n+        Used to initialize custom properties for the Node that aren't\n+        included by default in the base class. Be aware that the P2PInterface\n+        base class already stores a counter for each P2P message type and the\n+        last received message of each type, which should be sufficient for the\n+        needs of most tests.\n+\n+        Call super().__init__() first for standard initialization and then\n+        initialize custom properties.\"\"\"\n+        super().__init__()\n+        # Stores a dictionary of all blocks received\n+\n+    def on_block(self, message):\n+        \"\"\"Override the standard on_block callback\n+\n+        Store the hash of a received block in the dictionary.\"\"\"\n+        message.block.calc_sha256()\n+        self.block_receive_map[message.block.sha256] += 1\n+\n+    def on_inv(self, message):\n+        \"\"\"Override the standard on_inv callback\"\"\"\n+        pass\n+\n+\n+class PackageRelay(BitcoinTestFramework):\n+    # Each functional test is a subclass of the BitcoinTestFramework class.\n+\n+    # Override the set_test_params(), skip_test_if_missing_module(), add_options(), setup_chain(), setup_network()\n+    # and setup_nodes() methods to customize the test setup as required.\n+\n+    def set_test_params(self):\n+        \"\"\"Override test parameters for your individual test.\n+\n+        This method must be overridden and num_nodes must be explicitly set.\"\"\"\n+        self.setup_clean_chain = True\n+        self.num_nodes = 2\n+        self.extra_args = [[], [\"-minrelaytxfee=0\", \"-mintxfee=0.00000001\"]]\n+\n+\n+    # Use skip_test_if_missing_module() to skip the test if your test requires certain modules to be present.\n+    # This test uses generate which requires wallet to be compiled\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+\n+    def run_test(self):\n+        \"\"\"Main test logic\"\"\"\n+\n+        # Create P2P connections will wait for a verack to make sure the connection is fully up\n+        self.nodes[0].add_p2p_connection(BaseNode())\n+\n+        self.nodes[1].generate(101)\n+        self.sync_all(self.nodes[0:2])\n+\n+        # On node1, generate a 0-fee transaction, and then a 2-satoshi-per-byte\n+        # transaction\n+        utxos = self.nodes[1].listunspent()\n+        assert len(utxos) == 1\n+\n+        self.nodes[1].settxfee(Decimal(\"0.00000002\"))\n+        txid = self.nodes[1].sendtoaddress(self.nodes[0].getnewaddress(), 1)\n+        raw_tx = self.nodes[1].gettransaction(txid)['hex']\n+\n+        # TODO: rewrite this to test the exception raised\n+        # Deliver the 0-fee transaction and observe it doesn't get into the mempool of node0.\n+        try:\n+            self.nodes[0].sendrawtransaction(raw_tx)\n+        except:\n+            pass\n+        assert txid not in self.nodes[0].getrawmempool()\n+\n+        self.nodes[1].settxfee(Decimal(\"0.0005\"))\n+        txid2 = self.nodes[1].sendtoaddress(self.nodes[0].getnewaddress(), 1)\n+        raw_tx2 = self.nodes[1].gettransaction(txid2)['hex']\n+\n+        assert txid in self.nodes[1].getrawmempool()\n+        assert txid2 in self.nodes[1].getrawmempool()\n+\n+        assert txid2 not in self.nodes[0].getrawmempool()\n+\n+        self.nodes[0].generate(1) # Clear out the reject filter\n+\n+        # Delivering tx2 should result it being in the orphan pool, and then\n+        # delivering tx should cause both to be accepted.\n+        p2p = self.nodes[0].add_p2p_connection(BaseNode())",
      "path": "test/functional/feature_package_relay.py",
      "position": null,
      "original_position": 102,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "cd8f11aaaa7dd27f95af3d4cb85ff7c7607e76f9",
      "in_reply_to_id": null,
      "user": {
        "login": "pinheadmz",
        "id": 2084648,
        "node_id": "MDQ6VXNlcjIwODQ2NDg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2084648?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/pinheadmz",
        "html_url": "https://github.com/pinheadmz",
        "followers_url": "https://api.github.com/users/pinheadmz/followers",
        "following_url": "https://api.github.com/users/pinheadmz/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/pinheadmz/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/pinheadmz/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/pinheadmz/subscriptions",
        "organizations_url": "https://api.github.com/users/pinheadmz/orgs",
        "repos_url": "https://api.github.com/users/pinheadmz/repos",
        "events_url": "https://api.github.com/users/pinheadmz/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/pinheadmz/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Couldn't this `p2p` variable be defined up on line 67?",
      "created_at": "2019-10-02T17:26:42Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r330675635",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/330675635"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 102,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341397607",
      "pull_request_review_id": 310223329,
      "id": 341397607,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTM5NzYwNw==",
      "diff_hunk": "@@ -311,6 +308,14 @@ bool CheckSequenceLocks(const CTxMemPool& pool, const CTransaction& tx, int flag\n     return EvaluateSequenceLocks(index, lockPair);\n }\n \n+bool CheckSequenceLocks(const CTxMemPool& pool, const CTransaction& tx, int flags, LockPoints* lp, bool useExistingLockPoints)",
      "path": "src/validation.cpp",
      "position": 32,
      "original_position": 32,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "92cc72905ab15f4474b055da95f5a45b7e8b90c8",
      "in_reply_to_id": null,
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "I think the new wrapper doesn't do what the removed comment intended? Can't we pass `coins_cache` defined above instead of defining a new one, would work too in `removeForReorg` ? Also isn't this a behavior change as coin is fetched from UTXO set instead from mempool?\r\n\r\nThis change is may worth its own commit.",
      "created_at": "2019-10-31T22:53:00Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r341397607",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341397607"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 307,
      "original_line": 307,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341398695",
      "pull_request_review_id": 310223329,
      "id": 341398695,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTM5ODY5NQ==",
      "diff_hunk": "@@ -239,10 +239,9 @@ bool TestLockPointValidity(const LockPoints* lp)\n     return true;\n }\n \n-bool CheckSequenceLocks(const CTxMemPool& pool, const CTransaction& tx, int flags, LockPoints* lp, bool useExistingLockPoints)\n+static bool CheckSequenceLocks(CCoinsViewCache &view, const CTransaction& tx, int flags, LockPoints* lp, bool useExistingLockPoints=false) EXCLUSIVE_LOCKS_REQUIRED(cs_main)",
      "path": "src/validation.cpp",
      "position": 5,
      "original_position": 5,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "92cc72905ab15f4474b055da95f5a45b7e8b90c8",
      "in_reply_to_id": null,
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "`EXCLUSIVE_LOCKS_REQUIRED(pool.cs, cs_main)`? (wrapper and `AcceptMultipleTransactions` too)",
      "created_at": "2019-10-31T22:58:05Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r341398695",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341398695"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 238,
      "original_line": 238,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341399951",
      "pull_request_review_id": 310223329,
      "id": 341399951,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTM5OTk1MQ==",
      "diff_hunk": "@@ -709,8 +718,8 @@ bool MemPoolAccept::PreChecks(ATMPArgs& args, Workspace& ws)\n         return state.Invalid(ValidationInvalidReason::TX_NOT_STANDARD, false, REJECT_NONSTANDARD, \"bad-txns-too-many-sigops\",\n                 strprintf(\"%d\", nSigOpsCost));\n \n-    // No transactions are allowed below minRelayTxFee except from disconnected\n-    // blocks\n+    // No transactions are allowed below minRelayTxFee/mempool min fee except\n+    // from disconnected blocks",
      "path": "src/validation.cpp",
      "position": 119,
      "original_position": 105,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "92cc72905ab15f4474b055da95f5a45b7e8b90c8",
      "in_reply_to_id": null,
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "\"or being CPFP'ed by another tx\" ",
      "created_at": "2019-10-31T23:03:52Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r341399951",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341399951"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 711,
      "original_line": 711,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341404029",
      "pull_request_review_id": 310223329,
      "id": 341404029,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTQwNDAyOQ==",
      "diff_hunk": "@@ -751,8 +751,12 @@ class CTxMemPool\n  */\n class CCoinsViewMemPool : public CCoinsViewBacked\n {\n+public:\n+    void AddPotentialTransaction(const CTransactionRef& ptx) { package_tx.emplace(ptx->GetHash(), ptx); }\n+\n protected:\n     const CTxMemPool& mempool;\n+    std::map<uint256, const CTransactionRef> package_tx;",
      "path": "src/txmempool.h",
      "position": 9,
      "original_position": 9,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "92cc72905ab15f4474b055da95f5a45b7e8b90c8",
      "in_reply_to_id": null,
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Could have a better name like `package_pool` just to underscore we have multiple pending txn. I didn't get the rational at first read, I think you can explain given we have mempool locked and can't write until we have the whole set of tx, we need this temporary buffer to find outpoints of package txn after first row of parents. If this to work assuming topological ordering it should be documented?",
      "created_at": "2019-10-31T23:23:41Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r341404029",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341404029"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 760,
      "original_line": 760,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341408958",
      "pull_request_review_id": 310223329,
      "id": 341408958,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTQwODk1OA==",
      "diff_hunk": "@@ -1046,6 +1055,146 @@ bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs\n     return true;\n }\n \n+\n+bool MemPoolAccept::AcceptMultipleTransactions(const std::list<CTransactionRef>& tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    std::list<Workspace> tx_workspaces;\n+\n+    for (const CTransactionRef& ptx : tx_list) {\n+        // The last transaction must be validated for making it past the fee\n+        // checks on its own, to prevent packages from including low-fee,\n+        // unnecessary children that are attached to higher fee parents.\n+        tx_workspaces.emplace_back(Workspace(ptx, ptx != tx_list.back()));\n+        Workspace &ws = tx_workspaces.back();\n+\n+        if (!PreChecks(args, ws)) return false;\n+\n+        // For now, do not allow replacements in package transactions. If we\n+        // relax this, we would need to check that no child transaction depends",
      "path": "src/validation.cpp",
      "position": 163,
      "original_position": 149,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "92cc72905ab15f4474b055da95f5a45b7e8b90c8",
      "in_reply_to_id": null,
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "+1 for conflicts isolation for now. But IMO we may have to solve child conflicts in a way or another if people start to use one CPFP to bump multiple multi-party txn, like Alice broadcast commitment tx 1 + CPFP child tx, txn get into mempool, now she have to broadcast commitment tx 2 but doesn't have another UTXO available and can't CPFP output as going beyond carve-out relaxation..",
      "created_at": "2019-10-31T23:48:52Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r341408958",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341408958"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1063,
      "original_line": 1063,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341416526",
      "pull_request_review_id": 310223329,
      "id": 341416526,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTQxNjUyNg==",
      "diff_hunk": "@@ -1046,6 +1055,146 @@ bool MemPoolAccept::AcceptSingleTransaction(const CTransactionRef& ptx, ATMPArgs\n     return true;\n }\n \n+\n+bool MemPoolAccept::AcceptMultipleTransactions(const std::list<CTransactionRef>& tx_list, ATMPArgs& args)\n+{\n+    AssertLockHeld(cs_main);\n+    LOCK(m_pool.cs);\n+\n+    std::list<Workspace> tx_workspaces;\n+\n+    for (const CTransactionRef& ptx : tx_list) {\n+        // The last transaction must be validated for making it past the fee\n+        // checks on its own, to prevent packages from including low-fee,\n+        // unnecessary children that are attached to higher fee parents.\n+        tx_workspaces.emplace_back(Workspace(ptx, ptx != tx_list.back()));\n+        Workspace &ws = tx_workspaces.back();\n+\n+        if (!PreChecks(args, ws)) return false;\n+\n+        // For now, do not allow replacements in package transactions. If we\n+        // relax this, we would need to check that no child transaction depends\n+        // on any in-mempool transaction that conflicts with any package\n+        // transaction.\n+        if (!ws.m_conflicts.empty()) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"rbf-disallowed-in-package\", strprintf(\"mempool conflicts with tx %s\", ptx->GetHash().ToString()));\n+        }\n+        // Add this transaction to our coinsview, so that subsequent\n+        // transactions in this package will have their inputs available.\n+        m_viewmempool.AddPotentialTransaction(ptx);\n+    }\n+\n+    // Check overall package feerate\n+    size_t total_size=0;\n+    CAmount total_fee=0;\n+    uint64_t total_count = tx_list.size();\n+    for (const Workspace& ws : tx_workspaces) {\n+        total_size += ws.m_entry->GetTxSize();\n+        total_fee += ws.m_modified_fees;\n+    }\n+    if (!CheckFeeRate(total_size, total_fee, args.m_state)) return false;\n+\n+    // The ancestor/descendant limit calculations in PreChecks() will be overly\n+    // permissive, because not all ancestors will be known as we descend down\n+    // the package. Thus the ancestor checks done by\n+    // CalculateMemPoolAncestors() will be incomplete. If any ancestor or\n+    // descendant limit is violated in one of those checks, however, we know\n+    // the package will not be accepted when we include all ancestors, as the\n+    // ancestor/descendant size/counts only go up as we add more ancestors to\n+    // each transaction.\n+    // We will end up needing to recalculate setAncestors for each transaction\n+    // prior to calling Finalize, but we should do the correct package-size\n+    // calculations before we call ScriptChecks(), to avoid CPU-DoS.\n+\n+    // For now, do something conservative -- assume that the union of ancestors\n+    // of each transaction is an ancestor of every transaction, for package\n+    // size purposes.\n+    CTxMemPool::setEntries all_ancestors;\n+    for (const Workspace& ws : tx_workspaces) {\n+        all_ancestors.insert(ws.m_ancestors.begin(), ws.m_ancestors.end());\n+    }\n+\n+    if (total_count + all_ancestors.size() > m_limit_ancestors) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor count limit [package: %u limit: %u]\", total_count + all_ancestors.size(), m_limit_ancestors));\n+    }\n+\n+    // Check the package limits for every ancestor, assuming the whole package\n+    // descends from each.\n+    size_t ancestor_size = total_size;\n+    for (auto tx_iter : all_ancestors) {\n+        if (tx_iter->GetSizeWithDescendants() + total_size > m_limit_descendant_size) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendant_size));\n+        }\n+        if (tx_iter->GetCountWithDescendants() + total_count > m_limit_descendants) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_iter->GetTx().GetHash().ToString(), m_limit_descendants));\n+        }\n+        ancestor_size += tx_iter->GetTxSize();\n+    }\n+\n+    // In case we have no in-mempool ancestors, we must check the transaction\n+    // package itself.\n+    if (total_size > m_limit_descendant_size) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds descendant size limit for tx %s [limit: %u]\", tx_list.front()->GetHash().ToString(), m_limit_descendant_size));\n+    }\n+    if (ancestor_size > m_limit_ancestor_size) {\n+        return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"too-long-package-mempool-chain\", strprintf(\"exceeds ancestor size limit for tx %s [limit: %u]\", tx_list.back()->GetHash().ToString(), m_limit_ancestor_size));\n+    }\n+\n+    // Make sure all transactions are ancestors of the last one.\n+    // For now, just check that the last transaction has all prior transactions\n+    // as direct inputs. We can relax this in the future for bigger packages.\n+    std::set<uint256> last_tx_parents;\n+    for (auto input : tx_list.back()->vin) {\n+        last_tx_parents.insert(input.prevout.hash);\n+    }\n+    for (auto ptx : tx_list) {\n+        if (ptx == tx_list.back()) break;\n+        if (last_tx_parents.count(ptx->GetHash()) == 0) {\n+            return args.m_state.Invalid(ValidationInvalidReason::TX_MEMPOOL_POLICY, false, REJECT_NONSTANDARD, \"non-standard-package-chain\", \"only direct parents are allowed in package\");\n+        }\n+    }\n+\n+    // Do the script checks after all policy checks are done\n+    std::vector<PrecomputedTransactionData> txdata;\n+    txdata.reserve(tx_list.size());\n+    for (auto wit = tx_workspaces.begin(); wit != tx_workspaces.end(); ++wit) {\n+        txdata.emplace_back(*wit->m_ptx);\n+        if (!PolicyScriptChecks(args, *wit, txdata.back())) return false;\n+    }\n+\n+    // This package should be accepted except possibly for failing in\n+    // TrimToSize(), which we can't exercise without actually adding to the\n+    // mempool and seeing what would happen. Note that we are not adding\n+    // these transactions to the script cache, unlike in the single-tx case.",
      "path": "src/validation.cpp",
      "position": 255,
      "original_position": 241,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "92cc72905ab15f4474b055da95f5a45b7e8b90c8",
      "in_reply_to_id": null,
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Rational?",
      "created_at": "2019-11-01T00:35:46Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r341416526",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341416526"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1155,
      "original_line": 1155,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341658477",
      "pull_request_review_id": 310569770,
      "id": 341658477,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTY1ODQ3Nw==",
      "diff_hunk": "@@ -748,6 +748,20 @@ void RequestTx(CNodeState* state, const uint256& txid, std::chrono::microseconds\n     peer_download_state.m_tx_process_time.emplace(process_time, txid);\n }\n \n+// Add to a peer's orphan_work_set after processing a given transaction.\n+void UpdateOrphanWorkSet(const CTransaction& tx, CNode *peer) EXCLUSIVE_LOCKS_REQUIRED(g_cs_orphans)",
      "path": "src/net_processing.cpp",
      "position": 5,
      "original_position": 5,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "1dd7de23f2336e458487f33453c4f7ac8c1a9bef",
      "in_reply_to_id": null,
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "Can be reused too in ProcessOrphanTx",
      "created_at": "2019-11-01T16:50:35Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r341658477",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341658477"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 746,
      "original_line": 746,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341676157",
      "pull_request_review_id": 310569770,
      "id": 341676157,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTY3NjE1Nw==",
      "diff_hunk": "@@ -2572,33 +2579,79 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n                 recentRejects->insert(tx.GetHash());\n             }\n         } else {\n-            assert(IsTransactionReason(state.GetReason()));\n-            if (!tx.HasWitness() && state.GetReason() != ValidationInvalidReason::TX_WITNESS_MUTATED) {\n-                // Do not use rejection cache for witness transactions or\n-                // witness-stripped transactions, as they can have been malleated.\n-                // See https://github.com/bitcoin/bitcoin/issues/8279 for details.\n-                assert(recentRejects);\n-                recentRejects->insert(tx.GetHash());\n-                if (RecursiveDynamicUsage(*ptx) < 100000) {\n-                    AddToCompactExtraTransactions(ptx);\n+            // If this tx didn't make it in due to feerate, and there is a tx\n+            // in the orphan pool -- then maybe that tx is only missing this\n+            // one parent.\n+            // Try to process the pair as a package.\n+            bool added_as_package = false;\n+            if (state.GetRejectCode() == REJECT_INSUFFICIENTFEE) {\n+                std::list<std::map<uint256, COrphanTx>::iterator> orphans_missing_this_tx;\n+                for (size_t i=0; i<tx.vout.size(); ++i) {\n+                    auto it = mapOrphanTransactionsByPrev.find(COutPoint(tx.GetHash(), i));\n+                    if (it != mapOrphanTransactionsByPrev.end()) {\n+                        for (auto orphan_iter : it->second) orphans_missing_this_tx.push_back(orphan_iter);\n+                    }\n+                }\n+                if (!orphans_missing_this_tx.empty()) {\n+                    const COrphanTx &orphan_tx = orphans_missing_this_tx.front()->second;",
      "path": "src/net_processing.cpp",
      "position": 72,
      "original_position": 66,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "1dd7de23f2336e458487f33453c4f7ac8c1a9bef",
      "in_reply_to_id": null,
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "If I broadcast a second CPFP due to to the first one being still too low but this one still being in the orphan pool, you need to iter and try with the whole set not only picking up the first transaction ? That would be a DoS vector bounded by the size of the orphan pool, and maybe it can be mitigate by caching the package already-tried.",
      "created_at": "2019-11-01T17:33:17Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r341676157",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341676157"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 2582,
      "original_line": 2582,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341690775",
      "pull_request_review_id": 310569770,
      "id": 341690775,
      "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM0MTY5MDc3NQ==",
      "diff_hunk": "@@ -2572,33 +2579,79 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n                 recentRejects->insert(tx.GetHash());\n             }\n         } else {\n-            assert(IsTransactionReason(state.GetReason()));\n-            if (!tx.HasWitness() && state.GetReason() != ValidationInvalidReason::TX_WITNESS_MUTATED) {\n-                // Do not use rejection cache for witness transactions or\n-                // witness-stripped transactions, as they can have been malleated.\n-                // See https://github.com/bitcoin/bitcoin/issues/8279 for details.\n-                assert(recentRejects);\n-                recentRejects->insert(tx.GetHash());\n-                if (RecursiveDynamicUsage(*ptx) < 100000) {\n-                    AddToCompactExtraTransactions(ptx);\n+            // If this tx didn't make it in due to feerate, and there is a tx\n+            // in the orphan pool -- then maybe that tx is only missing this\n+            // one parent.\n+            // Try to process the pair as a package.\n+            bool added_as_package = false;\n+            if (state.GetRejectCode() == REJECT_INSUFFICIENTFEE) {\n+                std::list<std::map<uint256, COrphanTx>::iterator> orphans_missing_this_tx;\n+                for (size_t i=0; i<tx.vout.size(); ++i) {\n+                    auto it = mapOrphanTransactionsByPrev.find(COutPoint(tx.GetHash(), i));\n+                    if (it != mapOrphanTransactionsByPrev.end()) {\n+                        for (auto orphan_iter : it->second) orphans_missing_this_tx.push_back(orphan_iter);\n+                    }\n+                }\n+                if (!orphans_missing_this_tx.empty()) {\n+                    const COrphanTx &orphan_tx = orphans_missing_this_tx.front()->second;\n+                    // Pick the first transaction, and process the pair. If it's\n+                    // missing other inputs, this will of course fail.\n+                    std::list<CTransactionRef> package;\n+                    package.push_back(ptx);\n+                    package.push_back(orphan_tx.tx);\n+                    CValidationState package_state;\n+                    if (AcceptPackageToMemoryPool(mempool, state, package, nullptr, &lRemovedTxn, 0 /* nAbsurdFee */, false /* test_accept */)) {\n+                        LogPrintf(\"package accepted!!\\n\"); // XXX: improve logging\n+                        added_as_package = true;\n+                        mempool.check(&::ChainstateActive().CoinsTip());\n+                        EraseOrphanTx(orphan_tx.tx->GetHash());\n+                        for (auto package_tx : package) RelayTransaction(package_tx->GetHash(), *connman);\n+                        for (auto package_tx : package) UpdateOrphanWorkSet(*package_tx, pfrom);\n+\n+                        pfrom->nLastTXTime = GetTime();\n+\n+                        for (auto package_tx : package) {\n+                            LogPrint(BCLog::MEMPOOL, \"AcceptToMemoryPool: peer=%d: accepted %s (poolsz %u txn, %u kB)\\n\",\n+                                    pfrom->GetId(),\n+                                    package_tx->GetHash().ToString(),\n+                                    mempool.size(), mempool.DynamicMemoryUsage() / 1000);\n+                        }\n+\n+                        // Recursively process any orphan transactions that depended on these\n+                        ProcessOrphanTx(connman, pfrom->orphan_work_set, lRemovedTxn);\n+                    }",
      "path": "src/net_processing.cpp",
      "position": 98,
      "original_position": 92,
      "commit_id": "6a3bdba0746efe9a38f560bb116a8425e0410cb7",
      "original_commit_id": "1dd7de23f2336e458487f33453c4f7ac8c1a9bef",
      "in_reply_to_id": null,
      "user": {
        "login": "ariard",
        "id": 23310655,
        "node_id": "MDQ6VXNlcjIzMzEwNjU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/23310655?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ariard",
        "html_url": "https://github.com/ariard",
        "followers_url": "https://api.github.com/users/ariard/followers",
        "following_url": "https://api.github.com/users/ariard/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ariard/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ariard/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ariard/subscriptions",
        "organizations_url": "https://api.github.com/users/ariard/orgs",
        "repos_url": "https://api.github.com/users/ariard/repos",
        "events_url": "https://api.github.com/users/ariard/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ariard/received_events",
        "type": "User",
        "site_admin": false
      },
      "body": "If package wasn't accepted (like a high-fee invalid orphan tx),  and if inputs are not missing, if orphan_tx is invalid we may punish peer, or at least erase it for not being standard or insufficient fee? ",
      "created_at": "2019-11-01T18:09:20Z",
      "updated_at": "2020-01-09T03:56:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/16401#discussion_r341690775",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/341690775"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/16401"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 2608,
      "original_line": 2608,
      "side": "RIGHT"
    }
  ]
}